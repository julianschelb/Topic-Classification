{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier: In Context Learing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.pyenv/versions/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "from utils.model import *\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\"kinder\"] # [\"cannabis\", \"energie\", \"kinder\"]\n",
    "models = [\n",
    "    {\n",
    "        \"name\": \"aya-101\",\n",
    "        \"model\": \"CohereForAI/aya-101\",\n",
    "        \"tokenizer_class\": \"AutoTokenizer\",\n",
    "        \"model_class\": \"AutoModelForSeq2SeqLM\"\n",
    "    },\n",
    "#    {\n",
    "#        \"name\": \"vicuna-13b\",\n",
    "#        \"model\": \"lmsys/vicuna-13b-v1.5\",\n",
    "#        \"tokenizer_class\": \"LlamaTokenizer\",\n",
    "#        \"model_class\": \"LlamaForCausalLM\"\n",
    "#    },\n",
    "    # {\n",
    "    #     \"name\": \"vicuna-7b\",\n",
    "    #     \"model\": \"lmsys/vicuna-7b-v1.5\",\n",
    "    #     \"tokenizer_class\": \"LlamaTokenizer\",\n",
    "    #     \"model_class\": \"LlamaForCausalLM\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"name\": \"FLAN-t5-base\",\n",
    "    #     \"model\": \"google/flan-t5-base\",\n",
    "    #     \"tokenizer_class\": \"AutoTokenizer\",\n",
    "    #     \"model_class\": \"AutoModelForSeq2SeqLM\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"name\": \"FLAN-t5-large\",\n",
    "    #     \"model\": \"google/flan-t5-large\",\n",
    "    #     \"tokenizer_class\": \"AutoTokenizer\",\n",
    "    #     \"model_class\": \"AutoModelForSeq2SeqLM\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"name\": \"FLAN-t5-xxl\",\n",
    "    #     \"model\": \"google/flan-t5-xxl\",\n",
    "    #     \"tokenizer_class\": \"AutoTokenizer\",\n",
    "    #     \"model_class\": \"AutoModelForSeq2SeqLM\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"name\": \"leo-hessianai-13b\",\n",
    "    #     \"model\": \"LeoLM/leo-hessianai-13b\",\n",
    "    #     \"tokenizer_class\": \"AutoTokenizer\",\n",
    "    #     \"model_class\": \"AutoModelForCausalLM\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"name\": \"leo-hessianai-7b\",\n",
    "    #     \"model\": \"LeoLM/leo-hessianai-7b\",\n",
    "    #     \"tokenizer_class\": \"AutoTokenizer\",\n",
    "    #     \"model_class\": \"AutoModelForCausalLM\"\n",
    "    # },\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curated Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_examples = {\n",
    "    \"cannabis\": {\n",
    "        \"positive_examples\": [\n",
    "            {\n",
    "                \"text\": \"Krieg sowie die Corona-Pandemie. Hinzu kommt die Bürokratie: In Deutschland braucht es im Schnitt rund 175 Tage, bis der komplette Gesetzgebungsprozess durchlaufen ist und ein Gesetz in Kraft tritt. Einige Experten halten Anfang 2024 für das früheste realistische Datum der Legalisierung. Lobbyisten gehen von einer Gesetzesänderung nicht vor dem vierten Quartal 2024 aus. Finanzminister Christian Lindner (FPD) hatte indes eine Einführung im Jahr 2023 in Aussicht gestellt. Wer wird Recht behalten? Auch innerhalb der Regierungskoalition wächst der Druck auf Gesundheitsminister Karl Lauterbach (SPD). Die für das Gesundheitsministerium zuständigen Haushaltspolitiker wollen Lauterbach zur raschen Umsetzung der Cannabis-Legalisierung bewegen - mit einem ungewöhnlichen Mittel: Durch Beschluss des Haushaltsausschusses sei ein Betrag von einer Million Euro für die Öffentlichkeitsarbeit des Ministeriums so lange gesperrt, bis das im Koalitionsvertrag vereinbarte Cannabiskontrollgesetz vorgelegt werde. Das sagte die Grünen-Bundestagsabgeordnete Paula Piechotta gegenüber RND \",\n",
    "                \"label\": 1\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"Die geplante Cannabis-Legalisierung in Deutschland könnte weitreichende positive Auswirkungen auf die Wirtschaft und das Gesundheitswesen haben. Experten prognostizieren eine signifikante Steigerung der Steuereinnahmen, ähnlich den Erfahrungen in Kanada und einigen US-Bundesstaaten, wo Cannabis bereits legalisiert wurde. Darüber hinaus erwarten Gesundheitsexperten eine Verbesserung in der Qualität und Sicherheit von Cannabisprodukten, da diese durch staatliche Stellen reguliert und überwacht werden. Dies könnte nicht nur den Schwarzmarkt eindämmen, sondern auch den Verbraucherschutz stärken. Zudem wird eine Entlastung der Justiz und Polizei vorhergesagt, da die Ressourcen, die bisher für die Verfolgung von Cannabis-Delikten aufgewendet wurden, nun für die Bekämpfung schwerwiegenderer Kriminalität eingesetzt werden können. Wirtschaftsanalysten sehen in der Legalisierung zudem das Potential für die Schaffung neuer Arbeitsplätze in Landwirtschaft, Einzelhandel und im Bereich der medizinischen Forschung. Die politische Debatte gewinnt an Fahrt, und viele Bürgerinnen und Bürger setzen hohe Erwartungen in die geplanten Reformen.\",\n",
    "                \"label\": 1\n",
    "            }\n",
    "        ],\n",
    "        \"negative_examples\": [\n",
    "            {\n",
    "                \"text\": \"News Ratgeber Reise Reise Völlig daneben: Wenn Touristen die Benimmregeln missachten Aktualisiert am 27.06.2023, 16:26 Uhr Das Foto des Bergsteigers Dawa Steven Sherpa zeigt das vierte Lager, das höchste am Mount Everest, das mit verlassenen Zelten übersät ist. © picture alliance/dpa/Dawa Steven Sherpa/Asian Trekking Lesedauer: 5 Min. Teilen Artikel teilen Urlauberinnen und Urlauber benehmen sich manchmal völlig daneben. Alkoholexzesse, Pöbeleien und Vermüllung sind nur einige der Dinge, mit denen sich Einheimische herumschlagen müssen. Jedes Land zieht jedoch eigene Konsequenzen aus dem Verhalten der Touristinnen und Touristen. Mehr zum Thema Reise Die indonesische Urlaubsinsel Bali machte zuletzt wochenlang Schlagzeilen - nicht mit Tempeltänzen und Traumstränden, sondern mit ungenierten Touristen.\",\n",
    "                \"label\": 0\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"Die Bundesregierung hat sich das Ziel gesetzt, bis 2045 klimaneutral zu sein. Dafür müssen die Treibhausgasemissionen um 65 Prozent gegenüber 1990 reduziert werden. Ein wichtiger Baustein ist die Energiewende. Sie soll dazu beitragen, dass Deutschland bis 2035 zu 100 Prozent aus erneuerbaren Energien versorgt wird. Dafür müssen die erneuerbaren Energien ausgebaut und die fossilen Energieträger reduziert werden. Die Energiewende ist ein Mammutprojekt, das viele Herausforderungen mit sich bringt. Dazu gehören der Ausbau der Stromnetze, die Speicherung von Energie und die Sektorenkopplung. Die Energiewende ist ein wichtiger Schritt, um den Klimawandel zu bekämpfen und die Umwelt zu schützen.\",\n",
    "                \"label\": 0\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    \"energie\": {\n",
    "        \"positive_examples\": [\n",
    "            {\n",
    "                \"text\": \"Die Bundesregierung hat sich das Ziel gesetzt, bis 2045 klimaneutral zu sein. Dafür müssen die Treibhausgasemissionen um 65 Prozent gegenüber 1990 reduziert werden. Ein wichtiger Baustein ist die Energiewende. Sie soll dazu beitragen, dass Deutschland bis 2035 zu 100 Prozent aus erneuerbaren Energien versorgt wird. Dafür müssen die erneuerbaren Energien ausgebaut und die fossilen Energieträger reduziert werden. Die Energiewende ist ein Mammutprojekt, das viele Herausforderungen mit sich bringt. Dazu gehören der Ausbau der Stromnetze, die Speicherung von Energie und die Sektorenkopplung. Die Energiewende ist ein wichtiger Schritt, um den Klimawandel zu bekämpfen und die Umwelt zu schützen.\",\n",
    "                \"label\": 1\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"In einem beispiellosen Schritt zur Förderung der Nachhaltigkeit und zur Bekämpfung des Klimawandels hat die Bundesregierung umfangreiche Investitionen in grüne Technologien angekündigt. Ziel ist es, die Abhängigkeit von fossilen Brennstoffen zu verringern und den Übergang zu einer grünen Wirtschaft zu beschleunigen. Besonderes Augenmerk liegt auf der Wind- und Solarenergie, deren Kapazitäten bis zum Jahr 2030 verdoppelt werden sollen. Darüber hinaus werden innovative Projekte im Bereich der Wasserstofftechnologie und der Elektromobilität gefördert, um die CO2-Emissionen im Verkehrssektor zu senken. Diese Maßnahmen sind Teil des umfassenden Plans der Bundesregierung, Deutschland bis 2045 zum ersten klimaneutralen Industrieland zu machen. Durch diese Vorreiterrolle im Bereich der erneuerbaren Energien setzt Deutschland nicht nur ein starkes internationales Zeichen im Kampf gegen den Klimawandel, sondern schafft auch zukunftssichere Arbeitsplätze und fördert die wirtschaftliche Innovation.\",\n",
    "                \"label\": 1\n",
    "            }\n",
    "        ],\n",
    "        \"negative_examples\": [\n",
    "            {\n",
    "                \"text\": \"News Ratgeber Reise Reise Völlig daneben: Wenn Touristen die Benimmregeln missachten Aktualisiert am 27.06.2023, 16:26 Uhr Das Foto des Bergsteigers Dawa Steven Sherpa zeigt das vierte Lager, das höchste am Mount Everest, das mit verlassenen Zelten übersät ist. © picture alliance/dpa/Dawa Steven Sherpa/Asian Trekking Lesedauer: 5 Min. Teilen Artikel teilen Urlauberinnen und Urlauber benehmen sich manchmal völlig daneben. Alkoholexzesse, Pöbeleien und Vermüllung sind nur einige der Dinge, mit denen sich Einheimische herumschlagen müssen. Jedes Land zieht jedoch eigene Konsequenzen aus dem Verhalten der Touristinnen und Touristen. Mehr zum Thema Reise Die indonesische Urlaubsinsel Bali machte zuletzt wochenlang Schlagzeilen - nicht mit Tempeltänzen und Traumstränden, sondern mit ungenierten Touristen.\",\n",
    "                \"label\": 0\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"Krieg sowie die Corona-Pandemie. Hinzu kommt die Bürokratie: In Deutschland braucht es im Schnitt rund 175 Tage, bis der komplette Gesetzgebungsprozess durchlaufen ist und ein Gesetz in Kraft tritt. Einige Experten halten Anfang 2024 für das früheste realistische Datum der Legalisierung. Lobbyisten gehen von einer Gesetzesänderung nicht vor dem vierten Quartal 2024 aus. Finanzminister Christian Lindner (FPD) hatte indes eine Einführung im Jahr 2023 in Aussicht gestellt. Wer wird Recht behalten? Auch innerhalb der Regierungskoalition wächst der Druck auf Gesundheitsminister Karl Lauterbach (SPD). Die für das Gesundheitsministerium zuständigen Haushaltspolitiker wollen Lauterbach zur raschen Umsetzung der Cannabis-Legalisierung bewegen - mit einem ungewöhnlichen Mittel: Durch Beschluss des Haushaltsausschusses sei ein Betrag von einer Million Euro für die Öffentlichkeitsarbeit des Ministeriums so lange gesperrt, bis das im Koalitionsvertrag vereinbarte Cannabiskontrollgesetz vorgelegt werde. Das sagte die Grünen-Bundestagsabgeordnete Paula Piechotta gegenüber RND \",\n",
    "                \"label\": 1\n",
    "            }\n",
    "        ],\n",
    "    },\n",
    "    \"kinder\": {\n",
    "        \"positive_examples\": [\n",
    "            {\n",
    "                \"text\": \"Jedes fünfte Kind in Deutschland gilt als arm. Eine der dringendsten Aufgaben der Politik ist es deshalb, Armutsrisiken zu verringern und gleiche Entwicklungs- und Teilhabechance für Kinder und Jugendliche zu schaffen. Rund 70 Prozent der Bevölkerung unterstützen nach einer aktuellen Umfrage des Instituts für Demoskopie Allensbach (IfD Allensbach) die Bekämpfung von Kinderarmut. Mehr als 65 Prozent wünschen sich, dass mehr für die Chancengerechtigkeit von Kindern unabhängig von der sozialen Herkunft getan wird. Auftrag aus dem Koalitionsvertrag Im Koalitionsvertrag ist der Auftrag zur Einführung einer Kindergrundsicherung verankert. Dieser gibt den Rahmen vor, um die Kindergrundsicherung auszugestalten. Im Koalitionsvertrag heißt es: Jedes Kind soll die gleichen Chancen haben. Diese Chancengleichheit ist aber noch lange nicht Realität. Wir wollen mehr Kinder aus der Armut holen, werden mit der Kindergrundsicherung bessere Chancen für Kinder und Jugendliche schaffen und konzentrieren uns auf die, die am meisten Unterstützung brauchen. Was soll die Kindergrundsicherung erreichen?\",\n",
    "                \"label\": 1\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"In einem bemerkenswerten Schritt zur Verbesserung der Lebensqualität und Zukunftschancen von Kindern in Deutschland hat die Bundesregierung die Einführung eines nationalen Aktionsplans gegen Kinderarmut beschlossen. Dieser Aktionsplan zielt darauf ab, Kindern unabhängig von ihrer sozialen und wirtschaftlichen Herkunft gleiche Chancen zu bieten. Er umfasst Maßnahmen wie verbesserten Zugang zu Bildung und Gesundheitsversorgung, kostenlose Mahlzeiten in Schulen und Kitas, sowie verstärkte finanzielle Unterstützung für Familien mit niedrigem Einkommen. Darüber hinaus wird ein besonderer Fokus auf die Förderung von Kindern in benachteiligten Regionen gelegt, um regionale Disparitäten zu verringern. Der Aktionsplan genießt breite Unterstützung in der Bevölkerung und wird als entscheidender Schritt gesehen, um die Kinderarmut in Deutschland signifikant zu reduzieren und allen Kindern eine gerechte Chance auf eine erfolgreiche Zukunft zu ermöglichen.\",\n",
    "                \"label\": 1\n",
    "            }\n",
    "        ],\n",
    "        \"negative_examples\": [\n",
    "            {\n",
    "                \"text\": \"News Ratgeber Reise Reise Völlig daneben: Wenn Touristen die Benimmregeln missachten Aktualisiert am 27.06.2023, 16:26 Uhr Das Foto des Bergsteigers Dawa Steven Sherpa zeigt das vierte Lager, das höchste am Mount Everest, das mit verlassenen Zelten übersät ist. © picture alliance/dpa/Dawa Steven Sherpa/Asian Trekking Lesedauer: 5 Min. Teilen Artikel teilen Urlauberinnen und Urlauber benehmen sich manchmal völlig daneben. Alkoholexzesse, Pöbeleien und Vermüllung sind nur einige der Dinge, mit denen sich Einheimische herumschlagen müssen. Jedes Land zieht jedoch eigene Konsequenzen aus dem Verhalten der Touristinnen und Touristen. Mehr zum Thema Reise Die indonesische Urlaubsinsel Bali machte zuletzt wochenlang Schlagzeilen - nicht mit Tempeltänzen und Traumstränden, sondern mit ungenierten Touristen.\",\n",
    "                \"label\": 0\n",
    "            },\n",
    "            {\n",
    "                \"text\": \"Die Bundesregierung hat sich das Ziel gesetzt, bis 2045 klimaneutral zu sein. Dafür müssen die Treibhausgasemissionen um 65 Prozent gegenüber 1990 reduziert werden. Ein wichtiger Baustein ist die Energiewende. Sie soll dazu beitragen, dass Deutschland bis 2035 zu 100 Prozent aus erneuerbaren Energien versorgt wird. Dafür müssen die erneuerbaren Energien ausgebaut und die fossilen Energieträger reduziert werden. Die Energiewende ist ein Mammutprojekt, das viele Herausforderungen mit sich bringt. Dazu gehören der Ausbau der Stromnetze, die Speicherung von Energie und die Sektorenkopplung. Die Energiewende ist ein wichtiger Schritt, um den Klimawandel zu bekämpfen und die Umwelt zu schützen.\",\n",
    "                \"label\": 1\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Prompt Template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_desciptions =  {\n",
    "    \"kinder\": {\n",
    "        \"name\": \"Child Support Act\",\n",
    "        \"description\": \"The Kindergrundsicherung (basic child support) policy aims to combat child poverty by providing a fixed amount, income-dependent supplement, and educational benefits.\",\n",
    "        \"keywords\": ['kinder', 'kindergr', 'paus', 'familie', 'bundestag.de', 'arbeitsagentur.de', 'kindergrundsicherung',  'kindergeld', 'kindersicherung', 'kinderzuschlag', 'gesetz']\n",
    "    },\n",
    "    \"cannabis\": {\n",
    "        \"name\": \"Cannabis Control Act)\",\n",
    "        \"description\": \"The CanG 2023 (Cannabisgesetz, Cannabis Control Act) will legalize the private cultivation of cannabis by adults for personal use and collective non-commercial cultivation\",\n",
    "        \"keywords\": ['cannabis', 'canabis', 'cannabic', 'gras', 'cbd' , 'droge', 'hanf', 'thc', 'canbe', 'legal', 'legalisierung', 'gesetz', 'verein', 'entkriminali']\n",
    "    },\n",
    "    \"energie\":  {\n",
    "        \"name\": \"Renewable Energy Sources Act\",\n",
    "        \"description\": \"The EEG 2023 (Erneuerbare-Energien-Gesetz, Renewable Energy Sources Act) aims to increase the share of renewable energies in gross electricity consumption to at least 80% by 2030\",\n",
    "        \"keywords\": ['energie', 'eeg','grün','gruen','habeck', 'climate', 'strom','Waerme','wende','frderung', 'förderung', 'windkraft', 'windrad', 'photovoltaik',\n",
    "            \t'photovoltaic', 'solar', 'heizung', 'heiz', 'gesetz', 'erneuer', 'geothermie', 'pv', 'geg']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the following webpage text in German as topic releated or unrelated. Does it contain information about 'Cannabis Control Act)'? Please answer with 'Yes' or 'No' only.\n",
      "\n",
      "Topic description: The CanG 2023 (Cannabisgesetz, Cannabis Control Act) will legalize the private cultivation of cannabis by adults for personal use and collective non-commercial cultivation\n",
      "Topic keywords: cannabis, canabis, cannabic, gras, cbd, droge, hanf, thc, canbe, legal, legalisierung, gesetz, verein, entkriminali\n",
      "\n",
      "Examples:\n",
      "\n",
      "URL: '''google.de'''\n",
      "Text: '''Cannabis ist eine Droge.'''\n",
      "Answer: 'Yes'\n",
      "\n",
      "URL: '''example.com'''\n",
      "Text: '''Katzen sind Tiere.'''\n",
      "Answer: 'No'\n",
      "\n",
      "\n",
      "Webpage:\n",
      "URL: '''example.com'''\n",
      "Text: '''Lorem ipsum dolor sit amet, consectetur adipiscing elit.'''\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "PROMPT_TEMPLATE_ZERO_SHOT = \"\"\"Classify the following webpage text in {lang} as topic releated or unrelated. Does it contain information about '{topic}'? Please answer with 'Yes' or 'No' only.\n",
    "\n",
    "Topic description: {topic_desc}\n",
    "Topic keywords: {topic_keyw}\n",
    "\n",
    "URL: '''{url}'''\n",
    "Text: '''{webpage_text}'''\n",
    "Answer:\"\"\"\n",
    "\n",
    "PROMPT_TEMPLATE_EXAMPLES = \"\"\"\n",
    "Text: '''{text}'''\n",
    "Answer: '{label}'\n",
    "\"\"\"\n",
    "\n",
    "PROMPT_TEMPLATE_FEW_SHOT = \"\"\"Classify the following webpage text in {lang} as topic releated or unrelated. Does it contain information about '{topic}'? Please answer with 'Yes' or 'No' only.\n",
    "\n",
    "Topic description: {topic_desc}\n",
    "Topic keywords: {topic_keyw}\n",
    "\n",
    "Examples:\n",
    "{examples}\n",
    "\n",
    "Webpage:\n",
    "URL: '''{url}'''\n",
    "Text: '''{webpage_text}'''\n",
    "Answer:\"\"\"\n",
    "\n",
    "PROMPT_TEMPLATE_EXAMPLES = \"\"\"\n",
    "URL: '''{url}'''\n",
    "Text: '''{text}'''\n",
    "Answer: '{label}'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Example text\n",
    "example_list = [\n",
    "    {\n",
    "        \"text\": \"Cannabis ist eine Droge.\",\n",
    "        \"view_url\": \"google.de\",\n",
    "        \"label\": \"Yes\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"Katzen sind Tiere.\",\n",
    "        \"view_url\": \"example.com\",\n",
    "        \"label\": \"No\"\n",
    "    }\n",
    "]\n",
    "\n",
    "example_prompt_list = [PROMPT_TEMPLATE_EXAMPLES.format(text=example[\"text\"], url=example[\"view_url\"],  label=example[\"label\"]) for example in example_list]\n",
    "\n",
    "# print(\"Example prompt list:\")\n",
    "# print(\"\\n\".join(example_prompt_list))\n",
    "\n",
    "topic_desciption = topic_desciptions[\"cannabis\"]\n",
    "topic_name = topic_desciption.get(\"name\")\n",
    "topic_desc = topic_desciption.get(\"description\")\n",
    "topic_keyw = topic_desciption.get(\"keywords\")\n",
    "\n",
    "\n",
    "# Test the template with a dummy text\n",
    "prompt_test = PROMPT_TEMPLATE_FEW_SHOT.format(topic = topic_name, lang = 'German', url = \"example.com\",  topic_desc = topic_desc, topic_keyw = \", \".join(topic_keyw),  webpage_text='Lorem ipsum dolor sit amet, consectetur adipiscing elit.', examples=\"\".join(example_prompt_list))\n",
    "print(prompt_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameter for Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each parameter influences the text generation in a specific way. Below are the parameters along with a brief explanation:\n",
    "\n",
    "**`max_length`**:\n",
    "* Sets the maximum number of tokens in the generated text (default is 50).\n",
    "* Generation stops if the maximum length is reached before the model produces an EOS token.\n",
    "* A higher `max_length` allows for longer generated texts but may increase the time and computational resources required.\n",
    "\n",
    "**`min_length`**:\n",
    "* Sets the minimum number of tokens in the generated text (default is 10).\n",
    "* Generation continues until this minimum length is reached even if an EOS token is produced.\n",
    "\n",
    "**`num_beams`**:\n",
    "* In beam search, sets the number of \"beams\" or hypotheses to keep at each step (default is 4).\n",
    "* A higher number of beams increases the chances of finding a good output but also increases the computational cost.\n",
    "\n",
    "**`num_return_sequences`**:\n",
    "* Specifies the number of independently computed sequences to return (default is 3).\n",
    "* When using sampling, multiple different sequences are generated independently from each other.\n",
    "\n",
    "**`early_stopping`**:\n",
    "* Stops generation if the model produces the EOS (End Of Sentence) token, even if the predefined maximum length is not reached (default is True).\n",
    "* Useful when an EOS token signifies the logical end of a text (often represented as `</s>`).\n",
    "\n",
    "**`do_sample`**:\n",
    "* Tokens are selected probabilistically based on their likelihood scores (default is True).\n",
    "* Introduces randomness into the generation process for diverse outputs.\n",
    "* The level of randomness is controlled by the 'temperature' parameter.\n",
    "\n",
    "**`temperature`**:\n",
    "* Adjusts the probability distribution used for sampling the next token (default is 0.7).\n",
    "* Higher values make the generation more random, while lower values make it more deterministic.\n",
    "\n",
    "**`top_k`**:\n",
    "* Limits the number of tokens considered for sampling at each step to the top K most likely tokens (default is 50).\n",
    "* Can make the generation process faster and more focused.\n",
    "\n",
    "**`top_p`**:\n",
    "* Also known as nucleus sampling, sets a cumulative probability threshold (default is 0.95).\n",
    "* Tokens are sampled only from the smallest set whose cumulative probability exceeds this threshold.\n",
    "\n",
    "**`repetition_penalty`**:\n",
    "* Discourages the model from repeating the same token by modifying the token's score (default is 1.5).\n",
    "* Values greater than 1.0 penalize repetitions, and values less than 1.0 encourage repetitions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'do_sample': True,\n",
    "          'early_stopping': True,\n",
    "          'num_beams': 5,\n",
    "          'num_return_sequences': 5,\n",
    "          'max_new_tokens': 1024,\n",
    "          'min_new_tokens': 1,\n",
    "          'output_scores': True,\n",
    "          # 'repetition_penalty': 1.0,\n",
    "          'temperature': 0.6,\n",
    "          'top_k': 50,\n",
    "          'top_p': 1.0\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_prompt(article, template, template_example, topic, topic_desciptions, examples, lang='German'):\n",
    "    \"\"\" Compiles the prompt for the given article and model.\"\"\"\n",
    "\n",
    "\n",
    "    topic_desciption = topic_desciptions[topic]\n",
    "    topic_name = topic_desciption.get(\"name\")\n",
    "    topic_desc = topic_desciption.get(\"description\")\n",
    "    topic_keyw = topic_desciption.get(\"keywords\")\n",
    "    \n",
    "    # Get the text of the article\n",
    "    article_text = article.get(\"text\")\n",
    "    article_lang = article.get(\"lang\")\n",
    "    article_url = article.get(\"view_url\")\n",
    "    example_prompts = [template_example.format(text=example[\"text\"], url=example[\"view_url\"], label= \"Yes\" if example[\"label\"] == 1 else \"No\") for example in examples]\n",
    "    prompt = template.format(topic = topic_name, url = article_url,  topic_desc = topic_desc, topic_keyw = topic_keyw,\n",
    "                             lang = article_lang, webpage_text=article_text, examples=\"\".join(example_prompts))\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the following webpage text in de as topic releated or unrelated. Does it contain information about 'Cannabis Control Act)'? Please answer with 'Yes' or 'No' only.\n",
      "\n",
      "Topic description: The CanG 2023 (Cannabisgesetz, Cannabis Control Act) will legalize the private cultivation of cannabis by adults for personal use and collective non-commercial cultivation\n",
      "Topic keywords: ['cannabis', 'canabis', 'cannabic', 'gras', 'cbd', 'droge', 'hanf', 'thc', 'canbe', 'legal', 'legalisierung', 'gesetz', 'verein', 'entkriminali']\n",
      "\n",
      "Examples:\n",
      "\n",
      "URL: '''google.de'''\n",
      "Text: '''Cannabis ist eine Droge.'''\n",
      "Answer: 'No'\n",
      "\n",
      "URL: '''example.com'''\n",
      "Text: '''Katzen sind Tiere.'''\n",
      "Answer: 'No'\n",
      "\n",
      "\n",
      "Webpage:\n",
      "URL: '''test.com'''\n",
      "Text: '''Lorem Ipsum'''\n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "article = {\"view_url\": \"test.com\", \"text\": \"Lorem Ipsum\", \"lang\": \"de\"}\n",
    "exmaple_prompt = compile_prompt(article, PROMPT_TEMPLATE_FEW_SHOT, PROMPT_TEMPLATE_EXAMPLES, \"cannabis\", topic_desciptions, example_list, lang='German')\n",
    "print(exmaple_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_input_length(prompt):\n",
    "    \"\"\" Calculates the length of the input sequence for the model. \"\"\"\n",
    "\n",
    "    # Tokenize the prompt\n",
    "    tokenized_prompt = tokenizer(\n",
    "        prompt, return_tensors=\"pt\", add_special_tokens=False, truncation=False, padding=False)\n",
    "\n",
    "    # Calculate the length of the input sequence\n",
    "    input_length = tokenized_prompt.input_ids.size(1)\n",
    "\n",
    "    return input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answers(model, tokenizer, prompt, params, remove_input=True):\n",
    "    \"\"\"Generates answers from a language model for a given prompt.\"\"\"\n",
    "\n",
    "    # Encode the prompt and generate the answers\n",
    "    encoded_input = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    if encoded_input.size()[1] > tokenizer.model_max_length:\n",
    "        print(\"Input too long, truncating.\")\n",
    "        # encoded_input = encoded_input[:, :tokenizer.model_max_length]\n",
    "\n",
    "    generated_outputs = model.generate(encoded_input, **params)\n",
    "\n",
    "    # Decode and clean outputs\n",
    "    outputs = []\n",
    "    input_text_wo_st = tokenizer.decode(\n",
    "        encoded_input[0], skip_special_tokens=True)\n",
    "    for output in generated_outputs:\n",
    "        decoded_text = tokenizer.decode(output, skip_special_tokens=True)\n",
    "        cleaned_text = decoded_text.replace(input_text_wo_st, \"\").strip()\n",
    "        outputs.append(cleaned_text if remove_input else decoded_text)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_response(output_text):\n",
    "    \"\"\"Determines if the model's output signifies \"Yes\" (1) or \"No\" (0).\"\"\"\n",
    "    text = output_text.lower()\n",
    "    return 1 if \"yes\" in text else 0 if \"no\" in text else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(labels, preds):\n",
    "    \"\"\"\n",
    "    Calculates the accuracy, precision, recall, and F1 score for the given labels and predictions and returns them in a dictionary.\n",
    "    \"\"\"\n",
    "\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'precision': precision_score(labels, preds, average='binary'),\n",
    "        'recall': recall_score(labels, preds, average='binary'),\n",
    "        'f1': f1_score(labels, preds, average='binary'),\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_random_from_dataset(dataset, n=5, subset='test'):\n",
    "    \"\"\"\n",
    "    Samples n random examples from a specified subset of the dataset.\n",
    "    \"\"\"\n",
    "    n = min(n, len(dataset[subset]))\n",
    "    random_indices = random.sample(range(len(dataset[subset])), n)\n",
    "    sampled_dataset = dataset[subset].select(random_indices)\n",
    "    return sampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_details):\n",
    "    \"\"\"\n",
    "    Loads a model and its corresponding tokenizer based on the provided model details.\n",
    "    \"\"\"\n",
    "    model_name = model_details['model']\n",
    "    tokenizer_class = model_details['tokenizer_class']\n",
    "    model_class = model_details['model_class']\n",
    "    \n",
    "    # Cohere models and FLAN models\n",
    "    if tokenizer_class == \"AutoTokenizer\" and model_class == \"AutoModelForSeq2SeqLM\":\n",
    "        from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "            model_name, device_map=\"auto\", load_in_8bit=True)\n",
    "        \n",
    "    # Vicuna models\n",
    "    elif tokenizer_class == \"LlamaTokenizer\" and model_class == \"LlamaForCausalLM\":\n",
    "        from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "        tokenizer = LlamaTokenizer.from_pretrained(model_name)\n",
    "        model = LlamaForCausalLM.from_pretrained(model_name, device_map=\"auto\", load_in_8bit=True)\n",
    "        \n",
    "    #  LeoLM models  \n",
    "    elif tokenizer_class == \"AutoTokenizer\" and model_class == \"AutoModelForCausalLM\":\n",
    "        from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True, device_map=\"auto\", load_in_8bit=True)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(\"Model class not supported.\")\n",
    "        \n",
    "    return tokenizer, model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Different Sample Methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "\n",
    "################### Random Sampling ############################\n",
    "\n",
    "def sample_examples_random(dataset, k=2):\n",
    "    \"\"\"Samples k pairs of examples completely at random.\"\"\"\n",
    "    dataset_sampled = dataset.shuffle().select(range(k))\n",
    "    return [example for example in dataset_sampled]\n",
    "\n",
    "\n",
    "################### Random Sampling balanced ###################\n",
    "\n",
    "def sample_examples_random_balanced(dataset, k=2):\n",
    "    \"\"\"Samples k pairs of examples, each pair containing one positive and one negative example.\"\"\"\n",
    "    # Separate the dataset into positive and negative examples\n",
    "    positive_examples = [example for example in dataset if example['label'] == 1]\n",
    "    negative_examples = [example for example in dataset if example['label'] == 0]\n",
    "    \n",
    "    # Sample k examples from each subset\n",
    "    sampled_positive = sample(positive_examples, k)\n",
    "    sampled_negative = sample(negative_examples, k)\n",
    "    \n",
    "    # Alternate between positive and negative examples to create pairs\n",
    "    examples = []\n",
    "    for idx in range(k):\n",
    "        if idx % 2 == 0:\n",
    "            examples.append(sampled_positive[idx])\n",
    "        else:\n",
    "            examples.append(sampled_negative[idx])\n",
    "    \n",
    "    return examples\n",
    "\n",
    "\n",
    "################### KNN Sampling ############################\n",
    "\n",
    "def sample_examples_knn(model, index, query, dataset, k=2):\n",
    "    inferred_vector = model.encode(query, convert_to_tensor=True, show_progress_bar = False)\n",
    "    sims = index.get_nns_by_vector(inferred_vector, k, search_k=-1, include_distances=False)\n",
    "    return [dataset[idx] for idx in sims]\n",
    "\n",
    "################### Expert Sampling ############################\n",
    "\n",
    "def sample_from_expert(curated_examples, topic, k=2):\n",
    "    \n",
    "    curated_examples_topic = curated_examples[topic]\n",
    "    sampled_positive = sample(curated_examples_topic['positive_examples'], k)\n",
    "    sampled_negative = sample(curated_examples_topic['negative_examples'], k)\n",
    "    \n",
    "    # Alternate between positive and negative examples to create pairs\n",
    "    examples = []\n",
    "    for idx in range(k):\n",
    "        if idx % 2 == 0:\n",
    "            examples.append(sampled_positive[idx])\n",
    "        else:\n",
    "            examples.append(sampled_negative[idx])\n",
    "    \n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Answer Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic = \"cannabis\"\n",
    "# chunk_length = 496\n",
    "# model_details = models[0]\n",
    "# print(\"Model details: \", model_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load model\n",
    "# model_name = model_details['model']\n",
    "# print(f\"Loading model {model_name}\")\n",
    "\n",
    "# # Load model and tokenizer\n",
    "# tokenizer, model = load_model_and_tokenizer(model_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Max input length: \", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load dataset\n",
    "# print(f\"Loading dataset for {topic}\")\n",
    "# dataset = load_from_disk(f\"../data/tmp/processed_dataset_{topic}_buffed_chunkified_random_{chunk_length}\")\n",
    "# dataset['test'] = sample_random_from_dataset(dataset, n=10, subset='test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Encoder for KNN Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the transformer-based model\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "encoder = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode texts to embeddings\n",
    "def encode_to_embedding(example):\n",
    "    example['embeddings'] = encoder.encode(example['text'])\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The majority vote is: Apple\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def majority_voting(answers):\n",
    "    \"\"\"Apply majority voting to a list of arbitrary classification answers.\"\"\"\n",
    "    count = Counter(answers)\n",
    "    most_common = count.most_common(2)  # Get the two most common answers\n",
    "    \n",
    "    if len(most_common) > 1 and most_common[0][1] == most_common[1][1]:\n",
    "        return \"Tie\"\n",
    "    return most_common[0][0]\n",
    "\n",
    "# Example usage with arbitrary labels\n",
    "answers = [\"Apple\", \"Banana\", \"Apple\", \"Orange\"]\n",
    "print(f\"The majority vote is: {majority_voting(answers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get Answers:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k = 2\n",
    "# examples = sample_examples_random(dataset['train'], k) \n",
    "# examples = sample_examples_random_balanced(dataset['train'], k)\n",
    "# examples = sample_examples_knn(dataset['train'], k)\n",
    "# examples = sample_from_expert(curated_examples, topic, k)\n",
    "# sample_examples_knn(model, article_index, dataset[\"train\"][0][\"text\"], dataset[\"train\"], k)\n",
    "#print(\"Examples: \", examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate answers\n",
    "# answers = [] \n",
    "# for row in tqdm(dataset['test']): # ---------------------------------------------------\n",
    "#     examples = sample_examples_knn(encoder, article_index, row[\"text\"], dataset[\"train\"], k)\n",
    "#     prompt = compile_prompt(row, PROMPT_TEMPLATE_FEW_SHOT, PROMPT_TEMPLATE_EXAMPLES, topic, examples)\n",
    "#     answer = generate_answers(model, tokenizer, prompt, params)[0]\n",
    "#     #print(examples)\n",
    "#     print(30 * \"--\")\n",
    "#     #print(\"Prompt: \", prompt)\n",
    "#     #print(\"Text\", row[\"text\"])\n",
    "#     print(\"Answer: \", answer)\n",
    "#     print(\"Label: \", row['label'])\n",
    "#     answers.append(answer)\n",
    "\n",
    "# # Calculate metrics\n",
    "# metrics = calc_metrics(dataset['test']['label'], [parse_response(ans) for ans in answers])\n",
    "# print(f\"Metrics for {model_name}: {metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Sample Examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "chunk_length = 496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(f\"../data/tmp/processed_dataset_{topics[0]}_buffed_chunkified_random_{chunk_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_index = AnnoyIndex(encoder.get_sentence_embedding_dimension(), \"angular\")\n",
    "article_index.load(f'../data/indices/page_index_{topics[0]}.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function add_examples at 0x7f205cb6a8c0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Map: 100%|██████████| 268/268 [00:10<00:00, 26.40 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the function to process each example\n",
    "def add_examples(row):\n",
    "    examples = sample_examples_knn(encoder, article_index, row[\"text\"], dataset[\"train\"], k)\n",
    "    row[\"examples\"] = examples\n",
    "    return row\n",
    "    \n",
    "# Apply the function using the map method\n",
    "dataset['test'] = dataset['test'].map(add_examples, batched=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_index.unload()\n",
    "del article_index, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()  # Explicitly invoking garbage collection\n",
    "torch.cuda.empty_cache()  # Clear cache again after garbage collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = load_from_disk(f\"../data/tmp/processed_dataset_cannabis_buffed_chunkified_random_496\")\n",
    "# dataset['test'] = sample_random_from_dataset(dataset, n=10, subset='test')\n",
    "# tmp = dataset['test'].filter(lambda x: x['token_count'] > 200)\n",
    "# tmp[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU memory to avoid memory errors\n",
    "#model.cpu()\n",
    "#torch.cuda.empty_cache()\n",
    "#del model, tokenizer\n",
    "#gc.collect()  # Explicitly invoking garbage collection\n",
    "#torch.cuda.empty_cache()  # Clear cache again after garbage collection\n",
    "#time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model CohereForAI/aya-101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█| 11/11 [05:19<00:00, 29.08s\n",
      "100%|██████████████████████| 268/268 [05:04<00:00,  1.14s/it]\n",
      "Saving the dataset (1/1 shards): 100%|█| 2386/2386 [00:00<00:\n",
      "Saving the dataset (1/1 shards): 100%|█| 268/268 [00:00<00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for CohereForAI/aya-101: {'accuracy': 0.75, 'precision': 0.7204301075268817, 'recall': 0.6203703703703703, 'f1': 0.6666666666666666}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_results = defaultdict(dict)\n",
    "chunk_length = 496\n",
    "sampling_strategy = \"knn\"\n",
    "k = 2\n",
    "\n",
    "for model_details in models: #-------------------------------------------------------------\n",
    "\n",
    "    # Load model\n",
    "    model_name = model_details['model']\n",
    "    print(f\"Loading model {model_name}\")\n",
    "    tokenizer, model = load_model_and_tokenizer(model_details)\n",
    "    \n",
    "    for topic in [topics[0]]:  # ---------------------------------------------------------------\n",
    "    \n",
    "        # Iterate over pages in test split\n",
    "        answers = [] \n",
    "        for row in tqdm(dataset['test']): # ---------------------------------------------------\n",
    "\n",
    "            # Generate answers\n",
    "            prompt_template = PROMPT_TEMPLATE_FEW_SHOT if k > 0 else PROMPT_TEMPLATE_ZERO_SHOT\n",
    "            prompt = compile_prompt(row, prompt_template, PROMPT_TEMPLATE_EXAMPLES, topic, topic_desciptions, row['examples'])\n",
    "            answers.append(generate_answers(model, tokenizer, prompt, params))\n",
    "            \n",
    "    \n",
    "        # Add answers to the dataset\n",
    "        dataset['test'] = dataset['test'].add_column(\"answers\", answers)\n",
    "        dataset.save_to_disk(f\"../data/tmp/processed_dataset_{topic}_answers_{k}s_{model_name.split('/')[1]}_{sampling_strategy}\")\n",
    "        \n",
    "        # Calculate metrics\n",
    "        answers_after_voting = [majority_voting(ans) for ans in answers]\n",
    "        answers_parsed = [parse_response(ans) for ans in answers_after_voting]\n",
    "        metrics = calc_metrics(dataset['test']['label'], answers_parsed)\n",
    "        eval_results[model_name][topic] = metrics\n",
    "        print(f\"Metrics for {model_name}: {metrics}\")\n",
    "        \n",
    "    # Clear GPU memory to avoid memory errors\n",
    "    #model.cpu()\n",
    "    #torch.cuda.empty_cache()\n",
    "    #del model, tokenizer\n",
    "    #gc.collect()  # Explicitly invoking garbage collection\n",
    "    #torch.cuda.empty_cache()  # Clear cache again after garbage collection\n",
    "    #time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '64a0946e749484eec8576914',\n",
       " 'batch_id': 16,\n",
       " 'domain': 'n-tv.de',\n",
       " 'view_url': 'n-tv.de/panorama/Papst-schickt-beurlaubten-Gaenswein-nach-Freiburg-article24193350.html',\n",
       " 'lang': 'de',\n",
       " 'text': 'Sonntag, 02. Juli 2023 01:40 Uhr Frankfurt | 00:40 Uhr London | 19:40 Uhr New York | 08:40 Uhr Tokio Ressorts Das Beste Bilderserien Politik Meldungen Kommentare Pressestimmen Person der Woche Wieduwilts Woche Wirtschaft Meldungen Termine Startup Börse Auf einen Blick Aktien & Indizes Dax TecDax MDax SDax Gex HDax EuroStoxx50 Stoxx50 Dow Jones Nasdaq Nikkei Devisen Rohstoffe ntv Zertifikate ntv Fonds Fonds & ETF Anleihen ntv Altersvorsorge ntv Geldanlage-Check Börsen-Tag - Archiv Sport Live-Kalender Meldungen Kolumnen Collinas Erben Redelings Nachspielzeit Fußball-Zeitreise Fußball Kolumnen Testländerspiele WM 2023 Bundesliga 2. Bundesliga 3. Liga Bundesliga der Frauen DFB-Pokal Champions League Europa League Europa Conference League Nations League A Premier League Serie A Ligue 1 Primera Division Alle Ligen NFL Draft Motorsport Formel 1: Ticker Porsche Carrera Cup Anzeige Deutsche Rallye Meisterschaft Anzeige Tennis Handball Basketball Eishockey Sport-Tag - Archiv Gutscheine Anzeige Adidas Engelhorn Vans SportScheck 11teamsports Panorama Meldungen Unterhaltung Übersicht TV Filme und Serien Musik Bücher Hörbücher Schönes Wochenende ntv Kunst Gutscheine Anzeige Amazon Thalia bücher.de Saturn MMOGA Leben Übersicht Essen und Trinken Reise Gutscheine Anzeige Otto eBay h&m Expedia Blume2000 Technik Meldungen Spiele Gutscheine Anzeige notebooksbilliger.de Alternate MEDION deinhandy.de SAMSUNG Ratgeber Meldungen Tests Vergleichsrechner Anzeige Produktvergleiche Anzeige Jobbörse Anzeige Autoleasing Anzeige Unternehmen Anzeige Wissen Meldungen Frage & Antwort Fakten & Mythen Fundsache Blick in die Forschung Auto Meldungen Praxistest Gebrauchte Gutscheine Anzeige kfzteile24 A.T.U Reifendirekt Sixt Tirendo Autoleasing Anzeige Infografik Regionales Baden-Württemberg Bayern Berlin & Brandenburg Hamburg & SH Hessen MV NI & Bremen Nordrhein-Westfalen RP & Saarland Sachsen Sachsen-Anhalt Thüringen Alle Tage Der Tag - Archiv Börsen-Tag – Archiv Sport-Tag – Archiv Meinung Lotto spielen Anzeige Shopping & Service Anzeige Auslandsreport 01.07',\n",
       " 'text_length': 2058,\n",
       " 'word_count': 272,\n",
       " 'topic': 'kinder',\n",
       " 'category': 'news',\n",
       " 'good_for_training': 'True',\n",
       " 'good_for_augmentation': 'True',\n",
       " 'annotation_type': '04.urls-with-title',\n",
       " 'is_topic': False,\n",
       " 'label': 0,\n",
       " 'token_count': 440,\n",
       " 'chunk_id': 0,\n",
       " 'examples': [{'_id': '64a0946e749484eec856513d',\n",
       "   'annotation_type': '04.urls-with-title',\n",
       "   'batch_id': 16,\n",
       "   'category': 'news',\n",
       "   'chunk_id': 0,\n",
       "   'domain': 'n-tv.de',\n",
       "   'good_for_augmentation': 'True',\n",
       "   'good_for_training': 'True',\n",
       "   'is_topic': False,\n",
       "   'label': 0,\n",
       "   'lang': 'de',\n",
       "   'text': 'Sonntag, 02. Juli 2023 13:31 Uhr Frankfurt | 12:31 Uhr London | 07:31 Uhr New York | 20:31 Uhr Tokio Ressorts Das Beste Bilderserien Politik Meldungen Kommentare Pressestimmen Person der Woche Wieduwilts Woche Wirtschaft Meldungen Termine Startup Börse Auf einen Blick Aktien & Indizes Dax TecDax MDax SDax Gex HDax EuroStoxx50 Stoxx50 Dow Jones Nasdaq Nikkei Devisen Rohstoffe ntv Zertifikate ntv Fonds Fonds & ETF Anleihen ntv Altersvorsorge ntv Geldanlage-Check Börsen-Tag - Archiv Sport Live-Kalender Meldungen Kolumnen Collinas Erben Redelings Nachspielzeit Fußball-Zeitreise Fußball Kolumnen Testländerspiele WM 2023 Bundesliga 2. Bundesliga 3. Liga Bundesliga der Frauen DFB-Pokal Champions League Europa League Europa Conference League Nations League A Premier League Serie A Ligue 1 Primera Division Alle Ligen NFL Draft Motorsport Formel 1: Ticker Porsche Carrera Cup Anzeige Deutsche Rallye Meisterschaft Anzeige Tennis Handball Basketball Eishockey Sport-Tag - Archiv Gutscheine Anzeige Adidas Engelhorn Vans SportScheck 11teamsports Panorama Meldungen Unterhaltung Übersicht TV Filme und Serien Musik Bücher Hörbücher Schönes Wochenende ntv Kunst Gutscheine Anzeige Amazon Thalia bücher.de Saturn MMOGA Leben Übersicht Essen und Trinken Reise Gutscheine Anzeige Otto eBay h&m Expedia Blume2000 Technik Meldungen Spiele Gutscheine Anzeige notebooksbilliger.de Alternate MEDION deinhandy.de SAMSUNG Ratgeber Meldungen Tests Vergleichsrechner Anzeige Produktvergleiche Anzeige Jobbörse Anzeige Autoleasing Anzeige Unternehmen Anzeige Wissen Meldungen Frage & Antwort Fakten & Mythen Fundsache Blick in die Forschung Auto Meldungen Praxistest Gebrauchte Gutscheine Anzeige kfzteile24 A.T.U Reifendirekt Sixt Tirendo Autoleasing Anzeige Infografik Regionales Baden-Württemberg Bayern Berlin & Brandenburg Hamburg & SH Hessen MV NI & Bremen Nordrhein-Westfalen RP & Saarland Sachsen Sachsen-Anhalt Thüringen Alle Tage Der Tag - Archiv Börsen-Tag – Archiv Sport-Tag – Archiv Meinung Lotto spielen Anzeige Shopping & Service Anzeige Auslandsreport 01.07',\n",
       "   'text_length': 2058,\n",
       "   'token_count': 440,\n",
       "   'topic': 'kinder',\n",
       "   'view_url': 'www.n-tv.de/mediathek/videos/wissen/Strassenlaternen-hindern-Gluehwuermchen-am-Sex-article24192429.html',\n",
       "   'word_count': 272},\n",
       "  {'_id': '648c2adf8e8cadbd291551d6',\n",
       "   'annotation_type': '11.keyworded_urls',\n",
       "   'batch_id': 15,\n",
       "   'category': 'other',\n",
       "   'chunk_id': 5,\n",
       "   'domain': 'staedtetag.de',\n",
       "   'good_for_augmentation': 'True',\n",
       "   'good_for_training': 'True',\n",
       "   'is_topic': True,\n",
       "   'label': 1,\n",
       "   'lang': 'de',\n",
       "   'text': 'Städtetages an den neuen Bundestag und die neue Bundesregierung Mindestfinanzausstattung statt Nothaushalt Stabile Stadtfinanzen - nur mit Bund und Ländern Medienkommunikation in Krisensituationen Die Gewerbesteuer – eine gute Gemeindesteuer Stadtfinanzen Geschäftsbericht Geschäftsbericht 2023 Geschäftsbericht 2021 Geschäftsbericht 2019 Geschäftsbericht 2017 Geschäftsbericht 2015 Weitere Publikationen 2023 2022 2021 2020 2019 Archiv Europa News 2023 2022 Newsletter Alle Publikationen Presse Presse Aktuelle Äußerungen Pressemeldungen Interviews 2023 2022 2021 2020 2019 Archiv Pressekontakt Mediathek Porträts Stadtfinanzen 2019 - 2021 Stadtfinanzen 2022 Hauptversammlung 2019 Hauptversammlung 2021 Hauptversammlung 2023 Audios Videos des Deutschen Städtetages Aktuelle Äußerungen Volltextsuche',\n",
       "   'text_length': 799,\n",
       "   'token_count': 134,\n",
       "   'topic': 'kinder',\n",
       "   'view_url': 'www.staedtetag.de/positionen/beschluesse/kindergrundsicherung',\n",
       "   'word_count': 91}],\n",
       " 'answers': [\"'No'\", \"'No'\", \"'No'\", \"'No'\", \"'No'\"]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Output Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path to save the dictionary\n",
    "file_path = f\"eval_results_icl_{k}s_{sampling_strategy}.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save the dictionary to disk as JSON\n",
    "with open(file_path, \"w\") as file:\n",
    "    json.dump(eval_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the dictionary from the JSON file\n",
    "with open(file_path, \"r\") as file:\n",
    "    eval_results = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify all topics (assuming all models are evaluated on the same topics)\n",
    "topics = list(next(iter(eval_results.values())).keys())\n",
    "\n",
    "# Prepare headers for the table: each topic will have four metrics\n",
    "headers = [\"Model\"] + \\\n",
    "    [f\"{topic} {metric}\" for topic in topics for metric in [\n",
    "        \"Acc.\", \"Prec.\", \"Rec.\", \"F1\"]]\n",
    "\n",
    "# Prepare rows: one row per model, containing metrics for each topic\n",
    "rows = []\n",
    "for model_name_t, topics_metrics in eval_results.items():\n",
    "    row = [model_name_t]  # Start with the model name\n",
    "    for topic in topics:\n",
    "        metrics = topics_metrics.get(topic, {})\n",
    "        row.extend([metrics.get('accuracy', 0.0), metrics.get(\n",
    "            'precision', 0.0), metrics.get('recall', 0.0), metrics.get('f1', 0.0)])\n",
    "    rows.append(row)\n",
    "\n",
    "# Generate the HTML table\n",
    "table_html = tabulate(rows, headers=headers, tablefmt=\"html\",\n",
    "                      showindex=\"never\", floatfmt=\".3f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Model              </th><th style=\"text-align: right;\">  kinder Acc.</th><th style=\"text-align: right;\">  kinder Prec.</th><th style=\"text-align: right;\">  kinder Rec.</th><th style=\"text-align: right;\">  kinder F1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>CohereForAI/aya-101</td><td style=\"text-align: right;\">        0.750</td><td style=\"text-align: right;\">         0.720</td><td style=\"text-align: right;\">        0.620</td><td style=\"text-align: right;\">      0.667</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(table_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
