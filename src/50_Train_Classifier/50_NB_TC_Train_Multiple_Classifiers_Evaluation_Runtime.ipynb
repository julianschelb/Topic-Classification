{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Multiple Classifiers Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import load_dataset, load_from_disk, concatenate_datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Random Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed for random module\n",
    "random.seed(42)\n",
    "\n",
    "# Set a seed for numpy module\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set a seed for torch module\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING = \"random\" # \"random\", \"stratified\", \"clustered\", \"shared_domain\"\n",
    "SUFFIX = \"_extended\" #\"\", \"_holdout\", \"_extended\"\n",
    "SPLIT = \"test\" # \"train\", \"test\", \"holdout\", \"extende\n",
    "MAX_CONTENT_LENGTH = 384 # 496, 192\n",
    "OVERLAP = 64\n",
    "FEATURES = \"url_and_content\" # \"url\", \"content\", \"url_and_content\"\n",
    "FOLDER_DATA = \"data\"\n",
    "FOLDER_MODELS = \"models\"\n",
    "N = 5  # Number of times to run the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPICS = [\"cannabis\", \"kinder\", \"energie\"]\n",
    "#TOPICS = [\"cannabis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [\"distilbert/distilbert-base-multilingual-cased\",\n",
    "          \"google-bert/bert-base-multilingual-cased\", \n",
    "          \"FacebookAI/xlm-roberta-base\", \n",
    "          \"FacebookAI/xlm-roberta-large\", \n",
    "          \"dbmdz/bert-base-german-uncased\", \n",
    "          \"deepset/gelectra-large\",\n",
    "          \"deepset/gelectra-base\",\n",
    "          \"deepset/gbert-large\",\n",
    "          \"deepset/gbert-base\",\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_ID = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract URL-path:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'view_url': 'https://www.google.com/search?q=python+url+path',\n",
       " 'url_path': 'search?q=python+url+path'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import urlparse, urlunparse\n",
    "\n",
    "def extract_url_path(example):\n",
    "    view_url = example['view_url']\n",
    "    if \"://\" not in view_url:\n",
    "        view_url = \"http://\" + view_url  # Assume http if no protocol specified\n",
    "    parsed_url = urlparse(view_url)\n",
    "    new_url = urlunparse(('', '', parsed_url.path, parsed_url.params, parsed_url.query, parsed_url.fragment))\n",
    "    example['url_path'] = new_url.lstrip('/')  # Store the result in a new field\n",
    "    return example\n",
    "\n",
    "\n",
    "extract_url_path({\"view_url\": \"https://www.google.com/search?q=python+url+path\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "class TokenizedDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx]).clone().detach()\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "def get_predictions(tokenized_datasets, tokenizer, model, device, features, split=\"test\", batch_size=32):\n",
    "    \"\"\"Use the trained model to make predictions on the test set.\"\"\"\n",
    "    \n",
    "    # Tokenize the dataset\n",
    "    texts = []\n",
    "    urls = []\n",
    "    labels = []\n",
    "    \n",
    "    for row in tokenized_datasets[split]:\n",
    "        labels.append(row[\"label\"])\n",
    "        if features == \"content\":\n",
    "            texts.append(row[\"text\"])\n",
    "        elif features == \"url\":\n",
    "            urls.append(row[\"url_path\"])\n",
    "        elif features == \"url_and_content\":\n",
    "            urls.append(row[\"url_path\"])\n",
    "            texts.append(row[\"text\"])\n",
    "        else:\n",
    "            raise ValueError(\"Invalid value for FEATURES. Expected 'content', 'url', or 'url_and_content'.\")\n",
    "\n",
    "    if features == \"content\":\n",
    "        encodings = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    elif features == \"url\":\n",
    "        encodings = tokenizer(urls, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    elif features == \"url_and_content\":\n",
    "        encodings = tokenizer(urls, texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "    dataset = TokenizedDataset(encodings, labels)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    preds = []\n",
    "    probabilities = []\n",
    "    inference_times = []\n",
    "    \n",
    "    model.eval()  # Put the model in evaluation mode\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        # Move inputs to device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        start_time = time.time()\n",
    "        with torch.no_grad():\n",
    "            # Forward pass\n",
    "            outputs = model(**batch)\n",
    "            # Apply softmax to logits to get probabilities\n",
    "            predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            # Get the predicted class (the one with the highest probability)\n",
    "            predicted_classes = torch.argmax(predictions, dim=-1).cpu().numpy()\n",
    "        \n",
    "        end_time = time.time()\n",
    "        batch_inference_time = end_time - start_time\n",
    "        inference_times.extend([batch_inference_time / len(batch[\"labels\"])] * len(batch[\"labels\"]))  # Store time per sample\n",
    "        \n",
    "        # Store the predictions and probabilities\n",
    "        preds.extend(predicted_classes)\n",
    "        probabilities.extend(predictions[:, 1].cpu().numpy().tolist())  # Store the probability of the positive class\n",
    "    \n",
    "    # Calculate statistics\n",
    "    avg_time = np.mean(inference_times)\n",
    "    std_time = np.std(inference_times)\n",
    "    min_time = np.min(inference_times)\n",
    "    max_time = np.max(inference_times)\n",
    "    \n",
    "    return preds, labels, probabilities, avg_time, std_time, min_time, max_time, inference_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(labels, preds):\n",
    "    \"\"\"\n",
    "    Calculates the accuracy, precision, recall, and F1 score for the given labels and predictions and returns them in a dictionary.\n",
    "    \"\"\"\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'precision': precision_score(labels, preds, average='binary'),\n",
    "        'recall': recall_score(labels, preds, average='binary'),\n",
    "        'f1': f1_score(labels, preds, average='binary'),\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_random_from_dataset(dataset, n=5, subset='test'):\n",
    "    \"\"\"\n",
    "    Samples n random examples from a specified subset of the dataset.\n",
    "    \"\"\"\n",
    "    n = min(n, len(dataset[subset]))\n",
    "    random_indices = random.sample(range(len(dataset[subset])), n)\n",
    "    sampled_dataset = dataset[subset].select(random_indices)\n",
    "    return sampled_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get chunk level predictions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "eval_results = defaultdict(lambda: defaultdict(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###### Evaluating model distilbert/distilbert-base-multilingual-cased on cannabis ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/distilbert_distilbert-base-multilingual-cased_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:04<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for distilbert/distilbert-base-multilingual-cased on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.008373 seconds\n",
      "STD Inference Time per Sample: 0.002354 seconds\n",
      "Min Inference Time per Sample: 0.007752 seconds\n",
      "Max Inference Time per Sample: 0.017443 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/distilbert_distilbert-base-multilingual-cased_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for distilbert/distilbert-base-multilingual-cased on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.007763 seconds\n",
      "STD Inference Time per Sample: 0.000004 seconds\n",
      "Min Inference Time per Sample: 0.007756 seconds\n",
      "Max Inference Time per Sample: 0.007774 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/distilbert_distilbert-base-multilingual-cased_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for distilbert/distilbert-base-multilingual-cased on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.007759 seconds\n",
      "STD Inference Time per Sample: 0.000008 seconds\n",
      "Min Inference Time per Sample: 0.007744 seconds\n",
      "Max Inference Time per Sample: 0.007778 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/distilbert_distilbert-base-multilingual-cased_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for distilbert/distilbert-base-multilingual-cased on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.007771 seconds\n",
      "STD Inference Time per Sample: 0.000016 seconds\n",
      "Min Inference Time per Sample: 0.007753 seconds\n",
      "Max Inference Time per Sample: 0.007817 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/distilbert_distilbert-base-multilingual-cased_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for distilbert/distilbert-base-multilingual-cased on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.007772 seconds\n",
      "STD Inference Time per Sample: 0.000018 seconds\n",
      "Min Inference Time per Sample: 0.007753 seconds\n",
      "Max Inference Time per Sample: 0.007811 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model google-bert/bert-base-multilingual-cased on cannabis ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/google-bert_bert-base-multilingual-cased_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:07<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for google-bert/bert-base-multilingual-cased on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.015488 seconds\n",
      "STD Inference Time per Sample: 0.000036 seconds\n",
      "Min Inference Time per Sample: 0.015448 seconds\n",
      "Max Inference Time per Sample: 0.015616 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/google-bert_bert-base-multilingual-cased_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:07<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for google-bert/bert-base-multilingual-cased on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.015506 seconds\n",
      "STD Inference Time per Sample: 0.000039 seconds\n",
      "Min Inference Time per Sample: 0.015461 seconds\n",
      "Max Inference Time per Sample: 0.015590 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/google-bert_bert-base-multilingual-cased_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:07<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for google-bert/bert-base-multilingual-cased on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.015538 seconds\n",
      "STD Inference Time per Sample: 0.000037 seconds\n",
      "Min Inference Time per Sample: 0.015468 seconds\n",
      "Max Inference Time per Sample: 0.015612 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/google-bert_bert-base-multilingual-cased_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:07<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for google-bert/bert-base-multilingual-cased on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.015546 seconds\n",
      "STD Inference Time per Sample: 0.000031 seconds\n",
      "Min Inference Time per Sample: 0.015470 seconds\n",
      "Max Inference Time per Sample: 0.015611 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/google-bert_bert-base-multilingual-cased_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:07<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for google-bert/bert-base-multilingual-cased on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.015575 seconds\n",
      "STD Inference Time per Sample: 0.000037 seconds\n",
      "Min Inference Time per Sample: 0.015508 seconds\n",
      "Max Inference Time per Sample: 0.015639 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model FacebookAI/xlm-roberta-base on cannabis ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-base_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:08<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-base on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.016023 seconds\n",
      "STD Inference Time per Sample: 0.000253 seconds\n",
      "Min Inference Time per Sample: 0.015907 seconds\n",
      "Max Inference Time per Sample: 0.016987 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-base_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:08<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-base on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.015965 seconds\n",
      "STD Inference Time per Sample: 0.000029 seconds\n",
      "Min Inference Time per Sample: 0.015910 seconds\n",
      "Max Inference Time per Sample: 0.016035 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-base_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:08<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-base on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.015969 seconds\n",
      "STD Inference Time per Sample: 0.000031 seconds\n",
      "Min Inference Time per Sample: 0.015917 seconds\n",
      "Max Inference Time per Sample: 0.016036 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-base_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:08<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-base on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.015966 seconds\n",
      "STD Inference Time per Sample: 0.000040 seconds\n",
      "Min Inference Time per Sample: 0.015901 seconds\n",
      "Max Inference Time per Sample: 0.016062 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-base_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:08<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-base on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.015993 seconds\n",
      "STD Inference Time per Sample: 0.000099 seconds\n",
      "Min Inference Time per Sample: 0.015907 seconds\n",
      "Max Inference Time per Sample: 0.016349 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model FacebookAI/xlm-roberta-large on cannabis ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-large_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:26<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-large on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.052403 seconds\n",
      "STD Inference Time per Sample: 0.000137 seconds\n",
      "Min Inference Time per Sample: 0.052186 seconds\n",
      "Max Inference Time per Sample: 0.052785 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-large_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:26<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-large on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.052392 seconds\n",
      "STD Inference Time per Sample: 0.000119 seconds\n",
      "Min Inference Time per Sample: 0.052102 seconds\n",
      "Max Inference Time per Sample: 0.052624 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-large_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:26<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-large on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.052391 seconds\n",
      "STD Inference Time per Sample: 0.000104 seconds\n",
      "Min Inference Time per Sample: 0.052150 seconds\n",
      "Max Inference Time per Sample: 0.052662 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-large_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:26<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-large on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.052395 seconds\n",
      "STD Inference Time per Sample: 0.000106 seconds\n",
      "Min Inference Time per Sample: 0.052150 seconds\n",
      "Max Inference Time per Sample: 0.052623 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-large_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:26<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-large on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.052440 seconds\n",
      "STD Inference Time per Sample: 0.000133 seconds\n",
      "Min Inference Time per Sample: 0.052093 seconds\n",
      "Max Inference Time per Sample: 0.052610 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model dbmdz/bert-base-german-uncased on cannabis ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/dbmdz_bert-base-german-uncased_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:08<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for dbmdz/bert-base-german-uncased on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.016249 seconds\n",
      "STD Inference Time per Sample: 0.000041 seconds\n",
      "Min Inference Time per Sample: 0.016164 seconds\n",
      "Max Inference Time per Sample: 0.016305 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/dbmdz_bert-base-german-uncased_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:08<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for dbmdz/bert-base-german-uncased on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.016231 seconds\n",
      "STD Inference Time per Sample: 0.000041 seconds\n",
      "Min Inference Time per Sample: 0.016128 seconds\n",
      "Max Inference Time per Sample: 0.016281 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/dbmdz_bert-base-german-uncased_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:08<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for dbmdz/bert-base-german-uncased on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.016235 seconds\n",
      "STD Inference Time per Sample: 0.000037 seconds\n",
      "Min Inference Time per Sample: 0.016171 seconds\n",
      "Max Inference Time per Sample: 0.016332 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/dbmdz_bert-base-german-uncased_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:08<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for dbmdz/bert-base-german-uncased on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.016244 seconds\n",
      "STD Inference Time per Sample: 0.000033 seconds\n",
      "Min Inference Time per Sample: 0.016174 seconds\n",
      "Max Inference Time per Sample: 0.016301 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/dbmdz_bert-base-german-uncased_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:08<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for dbmdz/bert-base-german-uncased on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.016229 seconds\n",
      "STD Inference Time per Sample: 0.000035 seconds\n",
      "Min Inference Time per Sample: 0.016155 seconds\n",
      "Max Inference Time per Sample: 0.016296 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gelectra-large on cannabis ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/deepset_gelectra-large_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:28<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-large on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.056182 seconds\n",
      "STD Inference Time per Sample: 0.000071 seconds\n",
      "Min Inference Time per Sample: 0.056047 seconds\n",
      "Max Inference Time per Sample: 0.056336 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/deepset_gelectra-large_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:28<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-large on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.056194 seconds\n",
      "STD Inference Time per Sample: 0.000127 seconds\n",
      "Min Inference Time per Sample: 0.055873 seconds\n",
      "Max Inference Time per Sample: 0.056393 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/deepset_gelectra-large_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:28<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-large on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.056221 seconds\n",
      "STD Inference Time per Sample: 0.000102 seconds\n",
      "Min Inference Time per Sample: 0.055947 seconds\n",
      "Max Inference Time per Sample: 0.056358 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/deepset_gelectra-large_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:28<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-large on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.056226 seconds\n",
      "STD Inference Time per Sample: 0.000094 seconds\n",
      "Min Inference Time per Sample: 0.055997 seconds\n",
      "Max Inference Time per Sample: 0.056409 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/deepset_gelectra-large_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:28<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-large on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.056241 seconds\n",
      "STD Inference Time per Sample: 0.000080 seconds\n",
      "Min Inference Time per Sample: 0.056112 seconds\n",
      "Max Inference Time per Sample: 0.056393 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gelectra-base on cannabis ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/deepset_gelectra-base_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:08<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-base on cannabis: {'accuracy': 0.9861932938856016, 'precision': 0.9792284866468842, 'recall': 1.0, 'f1': 0.9895052473763118}\n",
      "Average Inference Time per Sample: 0.017221 seconds\n",
      "STD Inference Time per Sample: 0.000037 seconds\n",
      "Min Inference Time per Sample: 0.017144 seconds\n",
      "Max Inference Time per Sample: 0.017292 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/deepset_gelectra-base_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:08<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-base on cannabis: {'accuracy': 0.9861932938856016, 'precision': 0.9792284866468842, 'recall': 1.0, 'f1': 0.9895052473763118}\n",
      "Average Inference Time per Sample: 0.017220 seconds\n",
      "STD Inference Time per Sample: 0.000036 seconds\n",
      "Min Inference Time per Sample: 0.017165 seconds\n",
      "Max Inference Time per Sample: 0.017276 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/deepset_gelectra-base_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:08<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-base on cannabis: {'accuracy': 0.9861932938856016, 'precision': 0.9792284866468842, 'recall': 1.0, 'f1': 0.9895052473763118}\n",
      "Average Inference Time per Sample: 0.017232 seconds\n",
      "STD Inference Time per Sample: 0.000101 seconds\n",
      "Min Inference Time per Sample: 0.017166 seconds\n",
      "Max Inference Time per Sample: 0.017600 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/deepset_gelectra-base_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:08<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-base on cannabis: {'accuracy': 0.9861932938856016, 'precision': 0.9792284866468842, 'recall': 1.0, 'f1': 0.9895052473763118}\n",
      "Average Inference Time per Sample: 0.017196 seconds\n",
      "STD Inference Time per Sample: 0.000037 seconds\n",
      "Min Inference Time per Sample: 0.017121 seconds\n",
      "Max Inference Time per Sample: 0.017248 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/deepset_gelectra-base_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:08<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-base on cannabis: {'accuracy': 0.9861932938856016, 'precision': 0.9792284866468842, 'recall': 1.0, 'f1': 0.9895052473763118}\n",
      "Average Inference Time per Sample: 0.017192 seconds\n",
      "STD Inference Time per Sample: 0.000034 seconds\n",
      "Min Inference Time per Sample: 0.017101 seconds\n",
      "Max Inference Time per Sample: 0.017233 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gbert-large on cannabis ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/deepset_gbert-large_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:28<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-large on cannabis: {'accuracy': 0.9861932938856016, 'precision': 0.9969230769230769, 'recall': 0.9818181818181818, 'f1': 0.9893129770992366}\n",
      "Average Inference Time per Sample: 0.056184 seconds\n",
      "STD Inference Time per Sample: 0.000094 seconds\n",
      "Min Inference Time per Sample: 0.056049 seconds\n",
      "Max Inference Time per Sample: 0.056447 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/deepset_gbert-large_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:28<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-large on cannabis: {'accuracy': 0.9861932938856016, 'precision': 0.9969230769230769, 'recall': 0.9818181818181818, 'f1': 0.9893129770992366}\n",
      "Average Inference Time per Sample: 0.056229 seconds\n",
      "STD Inference Time per Sample: 0.000100 seconds\n",
      "Min Inference Time per Sample: 0.056020 seconds\n",
      "Max Inference Time per Sample: 0.056433 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/deepset_gbert-large_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:28<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-large on cannabis: {'accuracy': 0.9861932938856016, 'precision': 0.9969230769230769, 'recall': 0.9818181818181818, 'f1': 0.9893129770992366}\n",
      "Average Inference Time per Sample: 0.056221 seconds\n",
      "STD Inference Time per Sample: 0.000076 seconds\n",
      "Min Inference Time per Sample: 0.056009 seconds\n",
      "Max Inference Time per Sample: 0.056345 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/deepset_gbert-large_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:28<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-large on cannabis: {'accuracy': 0.9861932938856016, 'precision': 0.9969230769230769, 'recall': 0.9818181818181818, 'f1': 0.9893129770992366}\n",
      "Average Inference Time per Sample: 0.056236 seconds\n",
      "STD Inference Time per Sample: 0.000114 seconds\n",
      "Min Inference Time per Sample: 0.055932 seconds\n",
      "Max Inference Time per Sample: 0.056414 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/deepset_gbert-large_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:28<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-large on cannabis: {'accuracy': 0.9861932938856016, 'precision': 0.9969230769230769, 'recall': 0.9818181818181818, 'f1': 0.9893129770992366}\n",
      "Average Inference Time per Sample: 0.056248 seconds\n",
      "STD Inference Time per Sample: 0.000096 seconds\n",
      "Min Inference Time per Sample: 0.055918 seconds\n",
      "Max Inference Time per Sample: 0.056365 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gbert-base on cannabis ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/deepset_gbert-base_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:08<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-base on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.017234 seconds\n",
      "STD Inference Time per Sample: 0.000027 seconds\n",
      "Min Inference Time per Sample: 0.017186 seconds\n",
      "Max Inference Time per Sample: 0.017275 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/deepset_gbert-base_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:08<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-base on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.017228 seconds\n",
      "STD Inference Time per Sample: 0.000036 seconds\n",
      "Min Inference Time per Sample: 0.017178 seconds\n",
      "Max Inference Time per Sample: 0.017299 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/deepset_gbert-base_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:08<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-base on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.017219 seconds\n",
      "STD Inference Time per Sample: 0.000050 seconds\n",
      "Min Inference Time per Sample: 0.017084 seconds\n",
      "Max Inference Time per Sample: 0.017303 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/deepset_gbert-base_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:08<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-base on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.017217 seconds\n",
      "STD Inference Time per Sample: 0.000035 seconds\n",
      "Min Inference Time per Sample: 0.017110 seconds\n",
      "Max Inference Time per Sample: 0.017257 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/deepset_gbert-base_cannabis_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:08<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-base on cannabis: {'accuracy': 0.9960552268244576, 'precision': 0.9939759036144579, 'recall': 1.0, 'f1': 0.9969788519637462}\n",
      "Average Inference Time per Sample: 0.017205 seconds\n",
      "STD Inference Time per Sample: 0.000034 seconds\n",
      "Min Inference Time per Sample: 0.017156 seconds\n",
      "Max Inference Time per Sample: 0.017260 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model distilbert/distilbert-base-multilingual-cased on kinder ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/distilbert_distilbert-base-multilingual-cased_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for distilbert/distilbert-base-multilingual-cased on kinder: {'accuracy': 0.9968354430379747, 'precision': 1.0, 'recall': 0.9950980392156863, 'f1': 0.9975429975429976}\n",
      "Average Inference Time per Sample: 0.008627 seconds\n",
      "STD Inference Time per Sample: 0.000028 seconds\n",
      "Min Inference Time per Sample: 0.008581 seconds\n",
      "Max Inference Time per Sample: 0.008684 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/distilbert_distilbert-base-multilingual-cased_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for distilbert/distilbert-base-multilingual-cased on kinder: {'accuracy': 0.9968354430379747, 'precision': 1.0, 'recall': 0.9950980392156863, 'f1': 0.9975429975429976}\n",
      "Average Inference Time per Sample: 0.008618 seconds\n",
      "STD Inference Time per Sample: 0.000024 seconds\n",
      "Min Inference Time per Sample: 0.008583 seconds\n",
      "Max Inference Time per Sample: 0.008666 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/distilbert_distilbert-base-multilingual-cased_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for distilbert/distilbert-base-multilingual-cased on kinder: {'accuracy': 0.9968354430379747, 'precision': 1.0, 'recall': 0.9950980392156863, 'f1': 0.9975429975429976}\n",
      "Average Inference Time per Sample: 0.008615 seconds\n",
      "STD Inference Time per Sample: 0.000022 seconds\n",
      "Min Inference Time per Sample: 0.008582 seconds\n",
      "Max Inference Time per Sample: 0.008660 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/distilbert_distilbert-base-multilingual-cased_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for distilbert/distilbert-base-multilingual-cased on kinder: {'accuracy': 0.9968354430379747, 'precision': 1.0, 'recall': 0.9950980392156863, 'f1': 0.9975429975429976}\n",
      "Average Inference Time per Sample: 0.008623 seconds\n",
      "STD Inference Time per Sample: 0.000025 seconds\n",
      "Min Inference Time per Sample: 0.008588 seconds\n",
      "Max Inference Time per Sample: 0.008673 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/distilbert_distilbert-base-multilingual-cased_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for distilbert/distilbert-base-multilingual-cased on kinder: {'accuracy': 0.9968354430379747, 'precision': 1.0, 'recall': 0.9950980392156863, 'f1': 0.9975429975429976}\n",
      "Average Inference Time per Sample: 0.008625 seconds\n",
      "STD Inference Time per Sample: 0.000015 seconds\n",
      "Min Inference Time per Sample: 0.008599 seconds\n",
      "Max Inference Time per Sample: 0.008644 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model google-bert/bert-base-multilingual-cased on kinder ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/google-bert_bert-base-multilingual-cased_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for google-bert/bert-base-multilingual-cased on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.017130 seconds\n",
      "STD Inference Time per Sample: 0.000047 seconds\n",
      "Min Inference Time per Sample: 0.017066 seconds\n",
      "Max Inference Time per Sample: 0.017206 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/google-bert_bert-base-multilingual-cased_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for google-bert/bert-base-multilingual-cased on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.017148 seconds\n",
      "STD Inference Time per Sample: 0.000047 seconds\n",
      "Min Inference Time per Sample: 0.017051 seconds\n",
      "Max Inference Time per Sample: 0.017213 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/google-bert_bert-base-multilingual-cased_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for google-bert/bert-base-multilingual-cased on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.017165 seconds\n",
      "STD Inference Time per Sample: 0.000039 seconds\n",
      "Min Inference Time per Sample: 0.017107 seconds\n",
      "Max Inference Time per Sample: 0.017254 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/google-bert_bert-base-multilingual-cased_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for google-bert/bert-base-multilingual-cased on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.017152 seconds\n",
      "STD Inference Time per Sample: 0.000033 seconds\n",
      "Min Inference Time per Sample: 0.017123 seconds\n",
      "Max Inference Time per Sample: 0.017226 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/google-bert_bert-base-multilingual-cased_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for google-bert/bert-base-multilingual-cased on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.017141 seconds\n",
      "STD Inference Time per Sample: 0.000046 seconds\n",
      "Min Inference Time per Sample: 0.017047 seconds\n",
      "Max Inference Time per Sample: 0.017207 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model FacebookAI/xlm-roberta-base on kinder ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-base_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-base on kinder: {'accuracy': 0.9936708860759493, 'precision': 0.9950980392156863, 'recall': 0.9950980392156863, 'f1': 0.9950980392156863}\n",
      "Average Inference Time per Sample: 0.016365 seconds\n",
      "STD Inference Time per Sample: 0.000042 seconds\n",
      "Min Inference Time per Sample: 0.016296 seconds\n",
      "Max Inference Time per Sample: 0.016448 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-base_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-base on kinder: {'accuracy': 0.9936708860759493, 'precision': 0.9950980392156863, 'recall': 0.9950980392156863, 'f1': 0.9950980392156863}\n",
      "Average Inference Time per Sample: 0.016352 seconds\n",
      "STD Inference Time per Sample: 0.000028 seconds\n",
      "Min Inference Time per Sample: 0.016291 seconds\n",
      "Max Inference Time per Sample: 0.016391 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-base_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-base on kinder: {'accuracy': 0.9936708860759493, 'precision': 0.9950980392156863, 'recall': 0.9950980392156863, 'f1': 0.9950980392156863}\n",
      "Average Inference Time per Sample: 0.016387 seconds\n",
      "STD Inference Time per Sample: 0.000061 seconds\n",
      "Min Inference Time per Sample: 0.016314 seconds\n",
      "Max Inference Time per Sample: 0.016544 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-base_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-base on kinder: {'accuracy': 0.9936708860759493, 'precision': 0.9950980392156863, 'recall': 0.9950980392156863, 'f1': 0.9950980392156863}\n",
      "Average Inference Time per Sample: 0.016376 seconds\n",
      "STD Inference Time per Sample: 0.000017 seconds\n",
      "Min Inference Time per Sample: 0.016335 seconds\n",
      "Max Inference Time per Sample: 0.016402 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-base_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-base on kinder: {'accuracy': 0.9936708860759493, 'precision': 0.9950980392156863, 'recall': 0.9950980392156863, 'f1': 0.9950980392156863}\n",
      "Average Inference Time per Sample: 0.016347 seconds\n",
      "STD Inference Time per Sample: 0.000019 seconds\n",
      "Min Inference Time per Sample: 0.016319 seconds\n",
      "Max Inference Time per Sample: 0.016373 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model FacebookAI/xlm-roberta-large on kinder ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-large_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:16<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-large on kinder: {'accuracy': 0.9968354430379747, 'precision': 1.0, 'recall': 0.9950980392156863, 'f1': 0.9975429975429976}\n",
      "Average Inference Time per Sample: 0.053147 seconds\n",
      "STD Inference Time per Sample: 0.000167 seconds\n",
      "Min Inference Time per Sample: 0.052726 seconds\n",
      "Max Inference Time per Sample: 0.053374 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-large_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:16<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-large on kinder: {'accuracy': 0.9968354430379747, 'precision': 1.0, 'recall': 0.9950980392156863, 'f1': 0.9975429975429976}\n",
      "Average Inference Time per Sample: 0.053173 seconds\n",
      "STD Inference Time per Sample: 0.000185 seconds\n",
      "Min Inference Time per Sample: 0.052653 seconds\n",
      "Max Inference Time per Sample: 0.053308 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-large_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:16<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-large on kinder: {'accuracy': 0.9968354430379747, 'precision': 1.0, 'recall': 0.9950980392156863, 'f1': 0.9975429975429976}\n",
      "Average Inference Time per Sample: 0.053197 seconds\n",
      "STD Inference Time per Sample: 0.000097 seconds\n",
      "Min Inference Time per Sample: 0.052973 seconds\n",
      "Max Inference Time per Sample: 0.053311 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-large_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:16<00:00,  1.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-large on kinder: {'accuracy': 0.9968354430379747, 'precision': 1.0, 'recall': 0.9950980392156863, 'f1': 0.9975429975429976}\n",
      "Average Inference Time per Sample: 0.053268 seconds\n",
      "STD Inference Time per Sample: 0.000122 seconds\n",
      "Min Inference Time per Sample: 0.052971 seconds\n",
      "Max Inference Time per Sample: 0.053443 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-large_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:16<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-large on kinder: {'accuracy': 0.9968354430379747, 'precision': 1.0, 'recall': 0.9950980392156863, 'f1': 0.9975429975429976}\n",
      "Average Inference Time per Sample: 0.053164 seconds\n",
      "STD Inference Time per Sample: 0.000121 seconds\n",
      "Min Inference Time per Sample: 0.052862 seconds\n",
      "Max Inference Time per Sample: 0.053277 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model dbmdz/bert-base-german-uncased on kinder ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/dbmdz_bert-base-german-uncased_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for dbmdz/bert-base-german-uncased on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.016527 seconds\n",
      "STD Inference Time per Sample: 0.000027 seconds\n",
      "Min Inference Time per Sample: 0.016474 seconds\n",
      "Max Inference Time per Sample: 0.016572 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/dbmdz_bert-base-german-uncased_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for dbmdz/bert-base-german-uncased on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.016546 seconds\n",
      "STD Inference Time per Sample: 0.000036 seconds\n",
      "Min Inference Time per Sample: 0.016451 seconds\n",
      "Max Inference Time per Sample: 0.016593 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/dbmdz_bert-base-german-uncased_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for dbmdz/bert-base-german-uncased on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.016563 seconds\n",
      "STD Inference Time per Sample: 0.000049 seconds\n",
      "Min Inference Time per Sample: 0.016439 seconds\n",
      "Max Inference Time per Sample: 0.016624 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/dbmdz_bert-base-german-uncased_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for dbmdz/bert-base-german-uncased on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.016548 seconds\n",
      "STD Inference Time per Sample: 0.000037 seconds\n",
      "Min Inference Time per Sample: 0.016462 seconds\n",
      "Max Inference Time per Sample: 0.016605 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/dbmdz_bert-base-german-uncased_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for dbmdz/bert-base-german-uncased on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.016552 seconds\n",
      "STD Inference Time per Sample: 0.000033 seconds\n",
      "Min Inference Time per Sample: 0.016495 seconds\n",
      "Max Inference Time per Sample: 0.016615 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gelectra-large on kinder ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/deepset_gelectra-large_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-large on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.054903 seconds\n",
      "STD Inference Time per Sample: 0.000090 seconds\n",
      "Min Inference Time per Sample: 0.054718 seconds\n",
      "Max Inference Time per Sample: 0.055068 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/deepset_gelectra-large_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-large on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.054920 seconds\n",
      "STD Inference Time per Sample: 0.000135 seconds\n",
      "Min Inference Time per Sample: 0.054655 seconds\n",
      "Max Inference Time per Sample: 0.055151 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/deepset_gelectra-large_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-large on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.054913 seconds\n",
      "STD Inference Time per Sample: 0.000098 seconds\n",
      "Min Inference Time per Sample: 0.054635 seconds\n",
      "Max Inference Time per Sample: 0.054999 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/deepset_gelectra-large_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-large on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.054969 seconds\n",
      "STD Inference Time per Sample: 0.000114 seconds\n",
      "Min Inference Time per Sample: 0.054844 seconds\n",
      "Max Inference Time per Sample: 0.055274 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/deepset_gelectra-large_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-large on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.054920 seconds\n",
      "STD Inference Time per Sample: 0.000113 seconds\n",
      "Min Inference Time per Sample: 0.054696 seconds\n",
      "Max Inference Time per Sample: 0.055072 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gelectra-base on kinder ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/deepset_gelectra-base_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-base on kinder: {'accuracy': 0.990506329113924, 'precision': 0.9950738916256158, 'recall': 0.9901960784313726, 'f1': 0.9926289926289926}\n",
      "Average Inference Time per Sample: 0.016805 seconds\n",
      "STD Inference Time per Sample: 0.000044 seconds\n",
      "Min Inference Time per Sample: 0.016728 seconds\n",
      "Max Inference Time per Sample: 0.016857 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/deepset_gelectra-base_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-base on kinder: {'accuracy': 0.990506329113924, 'precision': 0.9950738916256158, 'recall': 0.9901960784313726, 'f1': 0.9926289926289926}\n",
      "Average Inference Time per Sample: 0.016814 seconds\n",
      "STD Inference Time per Sample: 0.000037 seconds\n",
      "Min Inference Time per Sample: 0.016744 seconds\n",
      "Max Inference Time per Sample: 0.016862 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/deepset_gelectra-base_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-base on kinder: {'accuracy': 0.990506329113924, 'precision': 0.9950738916256158, 'recall': 0.9901960784313726, 'f1': 0.9926289926289926}\n",
      "Average Inference Time per Sample: 0.016789 seconds\n",
      "STD Inference Time per Sample: 0.000049 seconds\n",
      "Min Inference Time per Sample: 0.016697 seconds\n",
      "Max Inference Time per Sample: 0.016864 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/deepset_gelectra-base_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-base on kinder: {'accuracy': 0.990506329113924, 'precision': 0.9950738916256158, 'recall': 0.9901960784313726, 'f1': 0.9926289926289926}\n",
      "Average Inference Time per Sample: 0.016797 seconds\n",
      "STD Inference Time per Sample: 0.000026 seconds\n",
      "Min Inference Time per Sample: 0.016739 seconds\n",
      "Max Inference Time per Sample: 0.016834 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/deepset_gelectra-base_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-base on kinder: {'accuracy': 0.990506329113924, 'precision': 0.9950738916256158, 'recall': 0.9901960784313726, 'f1': 0.9926289926289926}\n",
      "Average Inference Time per Sample: 0.016793 seconds\n",
      "STD Inference Time per Sample: 0.000034 seconds\n",
      "Min Inference Time per Sample: 0.016741 seconds\n",
      "Max Inference Time per Sample: 0.016841 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gbert-large on kinder ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/deepset_gbert-large_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-large on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.054848 seconds\n",
      "STD Inference Time per Sample: 0.000139 seconds\n",
      "Min Inference Time per Sample: 0.054532 seconds\n",
      "Max Inference Time per Sample: 0.055019 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/deepset_gbert-large_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-large on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.054886 seconds\n",
      "STD Inference Time per Sample: 0.000140 seconds\n",
      "Min Inference Time per Sample: 0.054572 seconds\n",
      "Max Inference Time per Sample: 0.055064 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/deepset_gbert-large_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-large on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.054933 seconds\n",
      "STD Inference Time per Sample: 0.000110 seconds\n",
      "Min Inference Time per Sample: 0.054677 seconds\n",
      "Max Inference Time per Sample: 0.055064 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/deepset_gbert-large_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-large on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.055001 seconds\n",
      "STD Inference Time per Sample: 0.000062 seconds\n",
      "Min Inference Time per Sample: 0.054918 seconds\n",
      "Max Inference Time per Sample: 0.055135 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/deepset_gbert-large_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-large on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.054960 seconds\n",
      "STD Inference Time per Sample: 0.000120 seconds\n",
      "Min Inference Time per Sample: 0.054738 seconds\n",
      "Max Inference Time per Sample: 0.055194 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gbert-base on kinder ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/deepset_gbert-base_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-base on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.016833 seconds\n",
      "STD Inference Time per Sample: 0.000040 seconds\n",
      "Min Inference Time per Sample: 0.016766 seconds\n",
      "Max Inference Time per Sample: 0.016903 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/deepset_gbert-base_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-base on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.016837 seconds\n",
      "STD Inference Time per Sample: 0.000040 seconds\n",
      "Min Inference Time per Sample: 0.016753 seconds\n",
      "Max Inference Time per Sample: 0.016887 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/deepset_gbert-base_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-base on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.016831 seconds\n",
      "STD Inference Time per Sample: 0.000047 seconds\n",
      "Min Inference Time per Sample: 0.016746 seconds\n",
      "Max Inference Time per Sample: 0.016901 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/deepset_gbert-base_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-base on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.016813 seconds\n",
      "STD Inference Time per Sample: 0.000055 seconds\n",
      "Min Inference Time per Sample: 0.016671 seconds\n",
      "Max Inference Time per Sample: 0.016876 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/deepset_gbert-base_kinder_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-base on kinder: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.016810 seconds\n",
      "STD Inference Time per Sample: 0.000044 seconds\n",
      "Min Inference Time per Sample: 0.016716 seconds\n",
      "Max Inference Time per Sample: 0.016866 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model distilbert/distilbert-base-multilingual-cased on energie ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/distilbert_distilbert-base-multilingual-cased_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for distilbert/distilbert-base-multilingual-cased on energie: {'accuracy': 0.9965457685664939, 'precision': 0.9924812030075187, 'recall': 1.0, 'f1': 0.9962264150943396}\n",
      "Average Inference Time per Sample: 0.008636 seconds\n",
      "STD Inference Time per Sample: 0.000071 seconds\n",
      "Min Inference Time per Sample: 0.008579 seconds\n",
      "Max Inference Time per Sample: 0.009580 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/distilbert_distilbert-base-multilingual-cased_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for distilbert/distilbert-base-multilingual-cased on energie: {'accuracy': 0.9965457685664939, 'precision': 0.9924812030075187, 'recall': 1.0, 'f1': 0.9962264150943396}\n",
      "Average Inference Time per Sample: 0.008625 seconds\n",
      "STD Inference Time per Sample: 0.000066 seconds\n",
      "Min Inference Time per Sample: 0.008578 seconds\n",
      "Max Inference Time per Sample: 0.009464 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/distilbert_distilbert-base-multilingual-cased_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for distilbert/distilbert-base-multilingual-cased on energie: {'accuracy': 0.9965457685664939, 'precision': 0.9924812030075187, 'recall': 1.0, 'f1': 0.9962264150943396}\n",
      "Average Inference Time per Sample: 0.008632 seconds\n",
      "STD Inference Time per Sample: 0.000063 seconds\n",
      "Min Inference Time per Sample: 0.008596 seconds\n",
      "Max Inference Time per Sample: 0.009461 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/distilbert_distilbert-base-multilingual-cased_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for distilbert/distilbert-base-multilingual-cased on energie: {'accuracy': 0.9965457685664939, 'precision': 0.9924812030075187, 'recall': 1.0, 'f1': 0.9962264150943396}\n",
      "Average Inference Time per Sample: 0.008631 seconds\n",
      "STD Inference Time per Sample: 0.000047 seconds\n",
      "Min Inference Time per Sample: 0.008579 seconds\n",
      "Max Inference Time per Sample: 0.009195 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/distilbert_distilbert-base-multilingual-cased_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:05<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for distilbert/distilbert-base-multilingual-cased on energie: {'accuracy': 0.9965457685664939, 'precision': 0.9924812030075187, 'recall': 1.0, 'f1': 0.9962264150943396}\n",
      "Average Inference Time per Sample: 0.008629 seconds\n",
      "STD Inference Time per Sample: 0.000059 seconds\n",
      "Min Inference Time per Sample: 0.008578 seconds\n",
      "Max Inference Time per Sample: 0.009368 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model google-bert/bert-base-multilingual-cased on energie ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/google-bert_bert-base-multilingual-cased_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:10<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for google-bert/bert-base-multilingual-cased on energie: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.017180 seconds\n",
      "STD Inference Time per Sample: 0.000124 seconds\n",
      "Min Inference Time per Sample: 0.017079 seconds\n",
      "Max Inference Time per Sample: 0.018794 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/google-bert_bert-base-multilingual-cased_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:10<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for google-bert/bert-base-multilingual-cased on energie: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.017189 seconds\n",
      "STD Inference Time per Sample: 0.000111 seconds\n",
      "Min Inference Time per Sample: 0.017081 seconds\n",
      "Max Inference Time per Sample: 0.018633 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/google-bert_bert-base-multilingual-cased_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:10<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for google-bert/bert-base-multilingual-cased on energie: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.017190 seconds\n",
      "STD Inference Time per Sample: 0.000108 seconds\n",
      "Min Inference Time per Sample: 0.017089 seconds\n",
      "Max Inference Time per Sample: 0.018593 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/google-bert_bert-base-multilingual-cased_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:10<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for google-bert/bert-base-multilingual-cased on energie: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.017185 seconds\n",
      "STD Inference Time per Sample: 0.000114 seconds\n",
      "Min Inference Time per Sample: 0.017047 seconds\n",
      "Max Inference Time per Sample: 0.018677 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/google-bert_bert-base-multilingual-cased_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:10<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for google-bert/bert-base-multilingual-cased on energie: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.017212 seconds\n",
      "STD Inference Time per Sample: 0.000105 seconds\n",
      "Min Inference Time per Sample: 0.017149 seconds\n",
      "Max Inference Time per Sample: 0.018620 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model FacebookAI/xlm-roberta-base on energie ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-base_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:08<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-base on energie: {'accuracy': 0.9913644214162349, 'precision': 0.9850187265917603, 'recall': 0.9962121212121212, 'f1': 0.9905838041431262}\n",
      "Average Inference Time per Sample: 0.014563 seconds\n",
      "STD Inference Time per Sample: 0.000114 seconds\n",
      "Min Inference Time per Sample: 0.014495 seconds\n",
      "Max Inference Time per Sample: 0.015749 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-base_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:08<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-base on energie: {'accuracy': 0.9913644214162349, 'precision': 0.9850187265917603, 'recall': 0.9962121212121212, 'f1': 0.9905838041431262}\n",
      "Average Inference Time per Sample: 0.014541 seconds\n",
      "STD Inference Time per Sample: 0.000101 seconds\n",
      "Min Inference Time per Sample: 0.014462 seconds\n",
      "Max Inference Time per Sample: 0.015872 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-base_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:08<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-base on energie: {'accuracy': 0.9913644214162349, 'precision': 0.9850187265917603, 'recall': 0.9962121212121212, 'f1': 0.9905838041431262}\n",
      "Average Inference Time per Sample: 0.014535 seconds\n",
      "STD Inference Time per Sample: 0.000105 seconds\n",
      "Min Inference Time per Sample: 0.014440 seconds\n",
      "Max Inference Time per Sample: 0.015928 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-base_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:08<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-base on energie: {'accuracy': 0.9913644214162349, 'precision': 0.9850187265917603, 'recall': 0.9962121212121212, 'f1': 0.9905838041431262}\n",
      "Average Inference Time per Sample: 0.014532 seconds\n",
      "STD Inference Time per Sample: 0.000107 seconds\n",
      "Min Inference Time per Sample: 0.014452 seconds\n",
      "Max Inference Time per Sample: 0.015932 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-base_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:08<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-base on energie: {'accuracy': 0.9913644214162349, 'precision': 0.9850187265917603, 'recall': 0.9962121212121212, 'f1': 0.9905838041431262}\n",
      "Average Inference Time per Sample: 0.014551 seconds\n",
      "STD Inference Time per Sample: 0.000113 seconds\n",
      "Min Inference Time per Sample: 0.014489 seconds\n",
      "Max Inference Time per Sample: 0.015755 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model FacebookAI/xlm-roberta-large on energie ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-large_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:27<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-large on energie: {'accuracy': 0.9965457685664939, 'precision': 0.9962121212121212, 'recall': 0.9962121212121212, 'f1': 0.9962121212121212}\n",
      "Average Inference Time per Sample: 0.047693 seconds\n",
      "STD Inference Time per Sample: 0.000372 seconds\n",
      "Min Inference Time per Sample: 0.047447 seconds\n",
      "Max Inference Time per Sample: 0.052635 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-large_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:27<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-large on energie: {'accuracy': 0.9965457685664939, 'precision': 0.9962121212121212, 'recall': 0.9962121212121212, 'f1': 0.9962121212121212}\n",
      "Average Inference Time per Sample: 0.047748 seconds\n",
      "STD Inference Time per Sample: 0.000302 seconds\n",
      "Min Inference Time per Sample: 0.047549 seconds\n",
      "Max Inference Time per Sample: 0.051735 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-large_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:27<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-large on energie: {'accuracy': 0.9965457685664939, 'precision': 0.9962121212121212, 'recall': 0.9962121212121212, 'f1': 0.9962121212121212}\n",
      "Average Inference Time per Sample: 0.047795 seconds\n",
      "STD Inference Time per Sample: 0.000282 seconds\n",
      "Min Inference Time per Sample: 0.047547 seconds\n",
      "Max Inference Time per Sample: 0.051416 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-large_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:27<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-large on energie: {'accuracy': 0.9965457685664939, 'precision': 0.9962121212121212, 'recall': 0.9962121212121212, 'f1': 0.9962121212121212}\n",
      "Average Inference Time per Sample: 0.047836 seconds\n",
      "STD Inference Time per Sample: 0.000320 seconds\n",
      "Min Inference Time per Sample: 0.047509 seconds\n",
      "Max Inference Time per Sample: 0.051868 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/FacebookAI_xlm-roberta-large_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:27<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-large on energie: {'accuracy': 0.9965457685664939, 'precision': 0.9962121212121212, 'recall': 0.9962121212121212, 'f1': 0.9962121212121212}\n",
      "Average Inference Time per Sample: 0.047798 seconds\n",
      "STD Inference Time per Sample: 0.000288 seconds\n",
      "Min Inference Time per Sample: 0.047608 seconds\n",
      "Max Inference Time per Sample: 0.051561 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model dbmdz/bert-base-german-uncased on energie ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/dbmdz_bert-base-german-uncased_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:07<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for dbmdz/bert-base-german-uncased on energie: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.013351 seconds\n",
      "STD Inference Time per Sample: 0.000131 seconds\n",
      "Min Inference Time per Sample: 0.013268 seconds\n",
      "Max Inference Time per Sample: 0.015127 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/dbmdz_bert-base-german-uncased_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:07<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for dbmdz/bert-base-german-uncased on energie: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.013348 seconds\n",
      "STD Inference Time per Sample: 0.000133 seconds\n",
      "Min Inference Time per Sample: 0.013235 seconds\n",
      "Max Inference Time per Sample: 0.015136 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/dbmdz_bert-base-german-uncased_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:07<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for dbmdz/bert-base-german-uncased on energie: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.013345 seconds\n",
      "STD Inference Time per Sample: 0.000132 seconds\n",
      "Min Inference Time per Sample: 0.013249 seconds\n",
      "Max Inference Time per Sample: 0.015122 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/dbmdz_bert-base-german-uncased_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:07<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for dbmdz/bert-base-german-uncased on energie: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.013343 seconds\n",
      "STD Inference Time per Sample: 0.000135 seconds\n",
      "Min Inference Time per Sample: 0.013256 seconds\n",
      "Max Inference Time per Sample: 0.015164 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/dbmdz_bert-base-german-uncased_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:07<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for dbmdz/bert-base-german-uncased on energie: {'accuracy': 1.0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0}\n",
      "Average Inference Time per Sample: 0.013338 seconds\n",
      "STD Inference Time per Sample: 0.000142 seconds\n",
      "Min Inference Time per Sample: 0.013256 seconds\n",
      "Max Inference Time per Sample: 0.015269 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gelectra-large on energie ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/deepset_gelectra-large_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:26<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-large on energie: {'accuracy': 0.998272884283247, 'precision': 1.0, 'recall': 0.9962121212121212, 'f1': 0.9981024667931688}\n",
      "Average Inference Time per Sample: 0.044784 seconds\n",
      "STD Inference Time per Sample: 0.000290 seconds\n",
      "Min Inference Time per Sample: 0.044417 seconds\n",
      "Max Inference Time per Sample: 0.048270 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/deepset_gelectra-large_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:26<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-large on energie: {'accuracy': 0.998272884283247, 'precision': 1.0, 'recall': 0.9962121212121212, 'f1': 0.9981024667931688}\n",
      "Average Inference Time per Sample: 0.044821 seconds\n",
      "STD Inference Time per Sample: 0.000341 seconds\n",
      "Min Inference Time per Sample: 0.044538 seconds\n",
      "Max Inference Time per Sample: 0.049001 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/deepset_gelectra-large_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:26<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-large on energie: {'accuracy': 0.998272884283247, 'precision': 1.0, 'recall': 0.9962121212121212, 'f1': 0.9981024667931688}\n",
      "Average Inference Time per Sample: 0.044834 seconds\n",
      "STD Inference Time per Sample: 0.000260 seconds\n",
      "Min Inference Time per Sample: 0.044424 seconds\n",
      "Max Inference Time per Sample: 0.047721 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/deepset_gelectra-large_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:26<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-large on energie: {'accuracy': 0.998272884283247, 'precision': 1.0, 'recall': 0.9962121212121212, 'f1': 0.9981024667931688}\n",
      "Average Inference Time per Sample: 0.044835 seconds\n",
      "STD Inference Time per Sample: 0.000248 seconds\n",
      "Min Inference Time per Sample: 0.044506 seconds\n",
      "Max Inference Time per Sample: 0.047629 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/deepset_gelectra-large_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:26<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-large on energie: {'accuracy': 0.998272884283247, 'precision': 1.0, 'recall': 0.9962121212121212, 'f1': 0.9981024667931688}\n",
      "Average Inference Time per Sample: 0.044802 seconds\n",
      "STD Inference Time per Sample: 0.000241 seconds\n",
      "Min Inference Time per Sample: 0.044488 seconds\n",
      "Max Inference Time per Sample: 0.047687 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gelectra-base on energie ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/deepset_gelectra-base_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:07<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-base on energie: {'accuracy': 0.9965457685664939, 'precision': 0.9962121212121212, 'recall': 0.9962121212121212, 'f1': 0.9962121212121212}\n",
      "Average Inference Time per Sample: 0.013696 seconds\n",
      "STD Inference Time per Sample: 0.000117 seconds\n",
      "Min Inference Time per Sample: 0.013618 seconds\n",
      "Max Inference Time per Sample: 0.015265 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/deepset_gelectra-base_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:07<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-base on energie: {'accuracy': 0.9965457685664939, 'precision': 0.9962121212121212, 'recall': 0.9962121212121212, 'f1': 0.9962121212121212}\n",
      "Average Inference Time per Sample: 0.013692 seconds\n",
      "STD Inference Time per Sample: 0.000114 seconds\n",
      "Min Inference Time per Sample: 0.013632 seconds\n",
      "Max Inference Time per Sample: 0.015218 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/deepset_gelectra-base_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:07<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-base on energie: {'accuracy': 0.9965457685664939, 'precision': 0.9962121212121212, 'recall': 0.9962121212121212, 'f1': 0.9962121212121212}\n",
      "Average Inference Time per Sample: 0.013684 seconds\n",
      "STD Inference Time per Sample: 0.000100 seconds\n",
      "Min Inference Time per Sample: 0.013615 seconds\n",
      "Max Inference Time per Sample: 0.015018 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/deepset_gelectra-base_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:07<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-base on energie: {'accuracy': 0.9965457685664939, 'precision': 0.9962121212121212, 'recall': 0.9962121212121212, 'f1': 0.9962121212121212}\n",
      "Average Inference Time per Sample: 0.013675 seconds\n",
      "STD Inference Time per Sample: 0.000120 seconds\n",
      "Min Inference Time per Sample: 0.013612 seconds\n",
      "Max Inference Time per Sample: 0.015254 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/deepset_gelectra-base_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:07<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-base on energie: {'accuracy': 0.9965457685664939, 'precision': 0.9962121212121212, 'recall': 0.9962121212121212, 'f1': 0.9962121212121212}\n",
      "Average Inference Time per Sample: 0.013666 seconds\n",
      "STD Inference Time per Sample: 0.000126 seconds\n",
      "Min Inference Time per Sample: 0.013608 seconds\n",
      "Max Inference Time per Sample: 0.015377 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gbert-large on energie ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/deepset_gbert-large_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:25<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-large on energie: {'accuracy': 0.9965457685664939, 'precision': 0.9924812030075187, 'recall': 1.0, 'f1': 0.9962264150943396}\n",
      "Average Inference Time per Sample: 0.044745 seconds\n",
      "STD Inference Time per Sample: 0.000269 seconds\n",
      "Min Inference Time per Sample: 0.044423 seconds\n",
      "Max Inference Time per Sample: 0.047825 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/deepset_gbert-large_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:26<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-large on energie: {'accuracy': 0.9965457685664939, 'precision': 0.9924812030075187, 'recall': 1.0, 'f1': 0.9962264150943396}\n",
      "Average Inference Time per Sample: 0.044796 seconds\n",
      "STD Inference Time per Sample: 0.000317 seconds\n",
      "Min Inference Time per Sample: 0.044449 seconds\n",
      "Max Inference Time per Sample: 0.048717 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/deepset_gbert-large_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:26<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-large on energie: {'accuracy': 0.9965457685664939, 'precision': 0.9924812030075187, 'recall': 1.0, 'f1': 0.9962264150943396}\n",
      "Average Inference Time per Sample: 0.044807 seconds\n",
      "STD Inference Time per Sample: 0.000256 seconds\n",
      "Min Inference Time per Sample: 0.044616 seconds\n",
      "Max Inference Time per Sample: 0.047965 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/deepset_gbert-large_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:25<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-large on energie: {'accuracy': 0.9965457685664939, 'precision': 0.9924812030075187, 'recall': 1.0, 'f1': 0.9962264150943396}\n",
      "Average Inference Time per Sample: 0.044780 seconds\n",
      "STD Inference Time per Sample: 0.000293 seconds\n",
      "Min Inference Time per Sample: 0.044521 seconds\n",
      "Max Inference Time per Sample: 0.048526 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/deepset_gbert-large_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:26<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-large on energie: {'accuracy': 0.9965457685664939, 'precision': 0.9924812030075187, 'recall': 1.0, 'f1': 0.9962264150943396}\n",
      "Average Inference Time per Sample: 0.044816 seconds\n",
      "STD Inference Time per Sample: 0.000261 seconds\n",
      "Min Inference Time per Sample: 0.044593 seconds\n",
      "Max Inference Time per Sample: 0.047863 seconds\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gbert-base on energie ###### \n",
      "\n",
      "\n",
      "Run 1/5\n",
      "Loading model from ../../models/deepset_gbert-base_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:08<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-base on energie: {'accuracy': 0.998272884283247, 'precision': 0.9962264150943396, 'recall': 1.0, 'f1': 0.998109640831758}\n",
      "Average Inference Time per Sample: 0.013707 seconds\n",
      "STD Inference Time per Sample: 0.000116 seconds\n",
      "Min Inference Time per Sample: 0.013615 seconds\n",
      "Max Inference Time per Sample: 0.015239 seconds\n",
      "Run 2/5\n",
      "Loading model from ../../models/deepset_gbert-base_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:07<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-base on energie: {'accuracy': 0.998272884283247, 'precision': 0.9962264150943396, 'recall': 1.0, 'f1': 0.998109640831758}\n",
      "Average Inference Time per Sample: 0.013715 seconds\n",
      "STD Inference Time per Sample: 0.000101 seconds\n",
      "Min Inference Time per Sample: 0.013672 seconds\n",
      "Max Inference Time per Sample: 0.015086 seconds\n",
      "Run 3/5\n",
      "Loading model from ../../models/deepset_gbert-base_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:08<00:00,  2.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-base on energie: {'accuracy': 0.998272884283247, 'precision': 0.9962264150943396, 'recall': 1.0, 'f1': 0.998109640831758}\n",
      "Average Inference Time per Sample: 0.013726 seconds\n",
      "STD Inference Time per Sample: 0.000113 seconds\n",
      "Min Inference Time per Sample: 0.013648 seconds\n",
      "Max Inference Time per Sample: 0.015219 seconds\n",
      "Run 4/5\n",
      "Loading model from ../../models/deepset_gbert-base_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:07<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-base on energie: {'accuracy': 0.998272884283247, 'precision': 0.9962264150943396, 'recall': 1.0, 'f1': 0.998109640831758}\n",
      "Average Inference Time per Sample: 0.013714 seconds\n",
      "STD Inference Time per Sample: 0.000116 seconds\n",
      "Min Inference Time per Sample: 0.013654 seconds\n",
      "Max Inference Time per Sample: 0.015278 seconds\n",
      "Run 5/5\n",
      "Loading model from ../../models/deepset_gbert-base_energie_model_url_and_content/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:08<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-base on energie: {'accuracy': 0.998272884283247, 'precision': 0.9962264150943396, 'recall': 1.0, 'f1': 0.998109640831758}\n",
      "Average Inference Time per Sample: 0.013711 seconds\n",
      "STD Inference Time per Sample: 0.000104 seconds\n",
      "Min Inference Time per Sample: 0.013627 seconds\n",
      "Max Inference Time per Sample: 0.015078 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for topic in TOPICS: # ----------------------------------------------------------------------\n",
    "\n",
    "    for model_name in MODELS: # -------------------------------------------------------------\n",
    "\n",
    "        print(f\"\\n\\n###### Evaluating model {model_name} on {topic} ###### \\n\\n\")\n",
    "            \n",
    "        if FEATURES == \"url\":\n",
    "            dataset = load_from_disk(\n",
    "                f\"../../{FOLDER_DATA}/tmp/processed_dataset_{topic}_buffed_{SAMPLING}{SUFFIX}\")\n",
    "\n",
    "            if SPLIT == \"holdout\":\n",
    "                dataset[\"holdout\"] = concatenate_datasets(\n",
    "                    [dataset[\"holdout\"], dataset[\"test\"]])\n",
    "            # Extract the path from the URL\n",
    "            dataset = dataset.map(extract_url_path, num_proc=8)\n",
    "        else:\n",
    "            dataset = load_from_disk(\n",
    "                f\"../../{FOLDER_DATA}/tmp/processed_dataset_{topic}_buffed_chunkified_{SAMPLING}{SUFFIX}_{MAX_CONTENT_LENGTH}\")\n",
    "\n",
    "            if SPLIT == \"holdout\":\n",
    "                dataset[\"holdout\"] = concatenate_datasets(\n",
    "                    [dataset[\"holdout\"], dataset[\"test\"]])\n",
    "                \n",
    "            # Extract the path from the URL\n",
    "            dataset = dataset.map(extract_url_path)\n",
    "        \n",
    "        for i in range(N):\n",
    "            print(f\"Run {i+1}/{N}\")\n",
    "            \n",
    "            # Load model and tokenizer\n",
    "            model_name_local = f\"../../{FOLDER_MODELS}/{model_name.replace('/','_')}_{topic}_model_{FEATURES}/\"\n",
    "            print(f\"Loading model from {model_name_local}\")\n",
    "            tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "            model = AutoModelForSequenceClassification.from_pretrained(model_name_local, num_labels=2, local_files_only=True)\n",
    "\n",
    "            # Move model to GPU if available\n",
    "            DEVICE = torch.device(f\"cuda:{CUDA_ID}\" if torch.cuda.is_available() else \"cpu\")\n",
    "            model.to(DEVICE)\n",
    "            \n",
    "            # Use the trained model to make predictions on the test set\n",
    "            preds, labels, probas, avg_time, std_time, min_time, max_time, runtimes = get_predictions(dataset, tokenizer, model, DEVICE, FEATURES, split=SPLIT)\n",
    "            metrics = calc_metrics(labels, preds)\n",
    "            \n",
    "            print(f\"Metrics for {model_name} on {topic}: {metrics}\")\n",
    "            print(f'Average Inference Time per Sample: {avg_time:.6f} seconds')\n",
    "            print(f'STD Inference Time per Sample: {std_time:.6f} seconds')\n",
    "            print(f'Min Inference Time per Sample: {min_time:.6f} seconds')\n",
    "            print(f'Max Inference Time per Sample: {max_time:.6f} seconds')\n",
    "            \n",
    "            # Update the eval_results dictionary\n",
    "            eval_results[model_name][topic].append({\n",
    "                'metrics': metrics,\n",
    "                'avg_time': avg_time,\n",
    "                'std_time': std_time,\n",
    "                'min_time': min_time,\n",
    "                'max_time': max_time\n",
    "            })\n",
    "            \n",
    "            # Clear GPU memory to avoid memory errors\n",
    "            del model, tokenizer\n",
    "            torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jschelb/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "german_stop_words = stopwords.words('german')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###### Evaluating SVM on cannabis ###### \n",
      "\n",
      "\n",
      "Loading dataset for cannabis from DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'chunk_id', 'url_path'],\n",
      "        num_rows: 3815\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'chunk_id', 'url_path'],\n",
      "        num_rows: 507\n",
      "    })\n",
      "    holdout: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'chunk_id', 'url_path'],\n",
      "        num_rows: 33702\n",
      "    })\n",
      "    extended: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'chunk_id', 'url_path'],\n",
      "        num_rows: 224737\n",
      "    })\n",
      "})\n",
      "Run 1/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001098 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001098 seconds\n",
      "Max Inference Time per Sample: 0.001098 seconds\n",
      "Run 2/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001110 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001110 seconds\n",
      "Max Inference Time per Sample: 0.001110 seconds\n",
      "Run 3/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001100 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001100 seconds\n",
      "Max Inference Time per Sample: 0.001100 seconds\n",
      "Run 4/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001104 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001104 seconds\n",
      "Max Inference Time per Sample: 0.001104 seconds\n",
      "Run 5/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001103 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001103 seconds\n",
      "Max Inference Time per Sample: 0.001103 seconds\n",
      "Run 1/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001101 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001101 seconds\n",
      "Max Inference Time per Sample: 0.001101 seconds\n",
      "Run 2/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001104 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001104 seconds\n",
      "Max Inference Time per Sample: 0.001104 seconds\n",
      "Run 3/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001097 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001097 seconds\n",
      "Max Inference Time per Sample: 0.001097 seconds\n",
      "Run 4/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001110 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001110 seconds\n",
      "Max Inference Time per Sample: 0.001110 seconds\n",
      "Run 5/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001096 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001096 seconds\n",
      "Max Inference Time per Sample: 0.001096 seconds\n",
      "Run 1/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001110 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001110 seconds\n",
      "Max Inference Time per Sample: 0.001110 seconds\n",
      "Run 2/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001100 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001100 seconds\n",
      "Max Inference Time per Sample: 0.001100 seconds\n",
      "Run 3/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001099 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001099 seconds\n",
      "Max Inference Time per Sample: 0.001099 seconds\n",
      "Run 4/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001100 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001100 seconds\n",
      "Max Inference Time per Sample: 0.001100 seconds\n",
      "Run 5/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001102 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001102 seconds\n",
      "Max Inference Time per Sample: 0.001102 seconds\n",
      "Run 1/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001108 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001108 seconds\n",
      "Max Inference Time per Sample: 0.001108 seconds\n",
      "Run 2/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001093 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001093 seconds\n",
      "Max Inference Time per Sample: 0.001093 seconds\n",
      "Run 3/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001105 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001105 seconds\n",
      "Max Inference Time per Sample: 0.001105 seconds\n",
      "Run 4/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001102 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001102 seconds\n",
      "Max Inference Time per Sample: 0.001102 seconds\n",
      "Run 5/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001101 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001101 seconds\n",
      "Max Inference Time per Sample: 0.001101 seconds\n",
      "Run 1/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001102 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001102 seconds\n",
      "Max Inference Time per Sample: 0.001102 seconds\n",
      "Run 2/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001099 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001099 seconds\n",
      "Max Inference Time per Sample: 0.001099 seconds\n",
      "Run 3/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001109 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001109 seconds\n",
      "Max Inference Time per Sample: 0.001109 seconds\n",
      "Run 4/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001097 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001097 seconds\n",
      "Max Inference Time per Sample: 0.001097 seconds\n",
      "Run 5/5\n",
      "Metrics for SVM on cannabis: {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}\n",
      "Average Inference Time per Sample: 0.001106 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001106 seconds\n",
      "Max Inference Time per Sample: 0.001106 seconds\n",
      "\n",
      "\n",
      "###### Evaluating SVM on kinder ###### \n",
      "\n",
      "\n",
      "Loading dataset for kinder from DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'chunk_id', 'url_path'],\n",
      "        num_rows: 3628\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'chunk_id', 'url_path'],\n",
      "        num_rows: 316\n",
      "    })\n",
      "    holdout: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'chunk_id', 'url_path'],\n",
      "        num_rows: 33730\n",
      "    })\n",
      "    extended: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'chunk_id', 'url_path'],\n",
      "        num_rows: 266322\n",
      "    })\n",
      "})\n",
      "Run 1/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001114 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001114 seconds\n",
      "Max Inference Time per Sample: 0.001114 seconds\n",
      "Run 2/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001137 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001137 seconds\n",
      "Max Inference Time per Sample: 0.001137 seconds\n",
      "Run 3/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001120 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001120 seconds\n",
      "Max Inference Time per Sample: 0.001120 seconds\n",
      "Run 4/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001127 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001127 seconds\n",
      "Max Inference Time per Sample: 0.001127 seconds\n",
      "Run 5/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001140 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001140 seconds\n",
      "Max Inference Time per Sample: 0.001140 seconds\n",
      "Run 1/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001123 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001123 seconds\n",
      "Max Inference Time per Sample: 0.001123 seconds\n",
      "Run 2/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001132 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001132 seconds\n",
      "Max Inference Time per Sample: 0.001132 seconds\n",
      "Run 3/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001134 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001134 seconds\n",
      "Max Inference Time per Sample: 0.001134 seconds\n",
      "Run 4/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001121 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001121 seconds\n",
      "Max Inference Time per Sample: 0.001121 seconds\n",
      "Run 5/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001147 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001147 seconds\n",
      "Max Inference Time per Sample: 0.001147 seconds\n",
      "Run 1/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001133 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001133 seconds\n",
      "Max Inference Time per Sample: 0.001133 seconds\n",
      "Run 2/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001124 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001124 seconds\n",
      "Max Inference Time per Sample: 0.001124 seconds\n",
      "Run 3/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001145 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001145 seconds\n",
      "Max Inference Time per Sample: 0.001145 seconds\n",
      "Run 4/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001125 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001125 seconds\n",
      "Max Inference Time per Sample: 0.001125 seconds\n",
      "Run 5/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001140 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001140 seconds\n",
      "Max Inference Time per Sample: 0.001140 seconds\n",
      "Run 1/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001133 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001133 seconds\n",
      "Max Inference Time per Sample: 0.001133 seconds\n",
      "Run 2/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001126 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001126 seconds\n",
      "Max Inference Time per Sample: 0.001126 seconds\n",
      "Run 3/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001139 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001139 seconds\n",
      "Max Inference Time per Sample: 0.001139 seconds\n",
      "Run 4/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001135 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001135 seconds\n",
      "Max Inference Time per Sample: 0.001135 seconds\n",
      "Run 5/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001122 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001122 seconds\n",
      "Max Inference Time per Sample: 0.001122 seconds\n",
      "Run 1/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001145 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001145 seconds\n",
      "Max Inference Time per Sample: 0.001145 seconds\n",
      "Run 2/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001132 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001132 seconds\n",
      "Max Inference Time per Sample: 0.001132 seconds\n",
      "Run 3/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001127 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001127 seconds\n",
      "Max Inference Time per Sample: 0.001127 seconds\n",
      "Run 4/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001141 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001141 seconds\n",
      "Max Inference Time per Sample: 0.001141 seconds\n",
      "Run 5/5\n",
      "Metrics for SVM on kinder: {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}\n",
      "Average Inference Time per Sample: 0.001133 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001133 seconds\n",
      "Max Inference Time per Sample: 0.001133 seconds\n",
      "\n",
      "\n",
      "###### Evaluating SVM on energie ###### \n",
      "\n",
      "\n",
      "Loading dataset for energie from DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'chunk_id', 'url_path'],\n",
      "        num_rows: 4227\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'chunk_id', 'url_path'],\n",
      "        num_rows: 579\n",
      "    })\n",
      "    holdout: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'chunk_id', 'url_path'],\n",
      "        num_rows: 39782\n",
      "    })\n",
      "    extended: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'chunk_id', 'url_path'],\n",
      "        num_rows: 229661\n",
      "    })\n",
      "})\n",
      "Run 1/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001218 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001218 seconds\n",
      "Max Inference Time per Sample: 0.001218 seconds\n",
      "Run 2/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001216 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001216 seconds\n",
      "Max Inference Time per Sample: 0.001216 seconds\n",
      "Run 3/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001228 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001228 seconds\n",
      "Max Inference Time per Sample: 0.001228 seconds\n",
      "Run 4/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001230 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001230 seconds\n",
      "Max Inference Time per Sample: 0.001230 seconds\n",
      "Run 5/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001222 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001222 seconds\n",
      "Max Inference Time per Sample: 0.001222 seconds\n",
      "Run 1/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001218 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001218 seconds\n",
      "Max Inference Time per Sample: 0.001218 seconds\n",
      "Run 2/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001230 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001230 seconds\n",
      "Max Inference Time per Sample: 0.001230 seconds\n",
      "Run 3/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001228 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001228 seconds\n",
      "Max Inference Time per Sample: 0.001228 seconds\n",
      "Run 4/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001222 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001222 seconds\n",
      "Max Inference Time per Sample: 0.001222 seconds\n",
      "Run 5/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001224 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001224 seconds\n",
      "Max Inference Time per Sample: 0.001224 seconds\n",
      "Run 1/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001228 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001228 seconds\n",
      "Max Inference Time per Sample: 0.001228 seconds\n",
      "Run 2/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001222 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001222 seconds\n",
      "Max Inference Time per Sample: 0.001222 seconds\n",
      "Run 3/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001221 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001221 seconds\n",
      "Max Inference Time per Sample: 0.001221 seconds\n",
      "Run 4/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001228 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001228 seconds\n",
      "Max Inference Time per Sample: 0.001228 seconds\n",
      "Run 5/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001225 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001225 seconds\n",
      "Max Inference Time per Sample: 0.001225 seconds\n",
      "Run 1/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001212 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001212 seconds\n",
      "Max Inference Time per Sample: 0.001212 seconds\n",
      "Run 2/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001214 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001214 seconds\n",
      "Max Inference Time per Sample: 0.001214 seconds\n",
      "Run 3/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001219 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001219 seconds\n",
      "Max Inference Time per Sample: 0.001219 seconds\n",
      "Run 4/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001220 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001220 seconds\n",
      "Max Inference Time per Sample: 0.001220 seconds\n",
      "Run 5/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001215 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001215 seconds\n",
      "Max Inference Time per Sample: 0.001215 seconds\n",
      "Run 1/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001224 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001224 seconds\n",
      "Max Inference Time per Sample: 0.001224 seconds\n",
      "Run 2/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001225 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001225 seconds\n",
      "Max Inference Time per Sample: 0.001225 seconds\n",
      "Run 3/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001213 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001213 seconds\n",
      "Max Inference Time per Sample: 0.001213 seconds\n",
      "Run 4/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001220 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001220 seconds\n",
      "Max Inference Time per Sample: 0.001220 seconds\n",
      "Run 5/5\n",
      "Metrics for SVM on energie: {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}\n",
      "Average Inference Time per Sample: 0.001220 seconds\n",
      "STD Inference Time per Sample: 0.000000 seconds\n",
      "Min Inference Time per Sample: 0.001220 seconds\n",
      "Max Inference Time per Sample: 0.001220 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "for topic in TOPICS:\n",
    "    print(f\"\\n\\n###### Evaluating SVM on {topic} ###### \\n\\n\")\n",
    "    \n",
    "    if FEATURES == \"url\":\n",
    "        dataset = load_from_disk(\n",
    "            f\"../../{FOLDER_DATA}/tmp/processed_dataset_{topic}_buffed_{SAMPLING}{SUFFIX}\")\n",
    "\n",
    "        if SPLIT == \"holdout\":\n",
    "            dataset[\"holdout\"] = concatenate_datasets(\n",
    "                [dataset[\"holdout\"], dataset[\"test\"]])\n",
    "        # Extract the path from the URL\n",
    "        dataset = dataset.map(extract_url_path, num_proc=8)\n",
    "    else:\n",
    "        dataset = load_from_disk(\n",
    "            f\"../../{FOLDER_DATA}/tmp/processed_dataset_{topic}_buffed_chunkified_{SAMPLING}{SUFFIX}_{MAX_CONTENT_LENGTH}\")\n",
    "\n",
    "        if SPLIT == \"holdout\":\n",
    "            dataset[\"holdout\"] = concatenate_datasets(\n",
    "                [dataset[\"holdout\"], dataset[\"test\"]])\n",
    "             \n",
    "        # Extract the path from the URL\n",
    "        dataset = dataset.map(extract_url_path)\n",
    "        \n",
    "        print(f\"Loading dataset for {topic} from {dataset}\")\n",
    "        \n",
    "        train_data = dataset['train']\n",
    "        test_data = dataset['test']\n",
    "\n",
    "        vectorizer = TfidfVectorizer(stop_words=german_stop_words, max_features=10000)\n",
    "\n",
    "        # Vectorize the training data\n",
    "        X_train = vectorizer.fit_transform(train_data['text'])\n",
    "\n",
    "        # Vectorize the test data using the same vectorizer\n",
    "        X_test = vectorizer.transform(test_data['text'])\n",
    "\n",
    "        y_train = np.array(train_data['label'])\n",
    "        y_test = np.array(test_data['label'])\n",
    "\n",
    "        # Initialize and train the SVM classifier\n",
    "        svm_classifier = SVC()\n",
    "\n",
    "        # Train the classifier\n",
    "        svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "    \n",
    "    for i in range(N):\n",
    "       for i in range(N):\n",
    "        print(f\"Run {i+1}/{N}\")\n",
    "    \n",
    "        # Measure the total time for predicting the entire test set\n",
    "        start_time = time.time()\n",
    "        predictions = svm_classifier.predict(X_test)\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Calculate average time per sample\n",
    "        total_time = end_time - start_time\n",
    "        num_samples = X_test.shape[0]\n",
    "        avg_time_per_sample = total_time / num_samples\n",
    "        runtimes = [avg_time_per_sample] * num_samples\n",
    "        std_time = np.std(runtimes)\n",
    "        min_time = np.min(runtimes)\n",
    "        max_time = np.max(runtimes)\n",
    "        \n",
    "        # Collecting metrics\n",
    "        metrics = classification_report(y_test, predictions, output_dict=True)\n",
    "\n",
    "        print(f\"Metrics for SVM on {topic}: {metrics}\")\n",
    "        print(f'Average Inference Time per Sample: {avg_time_per_sample:.6f} seconds')\n",
    "        print(f'STD Inference Time per Sample: {std_time:.6f} seconds')\n",
    "        print(f'Min Inference Time per Sample: {min_time:.6f} seconds')\n",
    "        print(f'Max Inference Time per Sample: {max_time:.6f} seconds')\n",
    "\n",
    "        # Update eval_results\n",
    "        eval_results['svm_classifier'][topic].append({\n",
    "            'metrics': metrics,\n",
    "            'avg_time': avg_time_per_sample,\n",
    "            'std_time': std_time,\n",
    "            'min_time': min_time,\n",
    "            'max_time': max_time\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x7fb1d350f370>, {'svm_classifier': defaultdict(<class 'list'>, {'cannabis': [{'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0017493927972556571, 'std_time': 0.0004228871436871009, 'min_time': 0.0008242130279541016, 'max_time': 0.008214235305786133}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.001743138894526916, 'std_time': 0.0003132867741633453, 'min_time': 0.0008604526519775391, 'max_time': 0.002374887466430664}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0017273543619310127, 'std_time': 0.00031579770662851247, 'min_time': 0.0008451938629150391, 'max_time': 0.002465963363647461}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0017310270426071136, 'std_time': 0.0003131764553696322, 'min_time': 0.0008456707000732422, 'max_time': 0.002686023712158203}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0017324603756033693, 'std_time': 0.00031061097609718204, 'min_time': 0.0008151531219482422, 'max_time': 0.002389669418334961}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.00109803700117905, 'std_time': 0.0, 'min_time': 0.00109803700117905, 'max_time': 0.00109803700117905}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.001110112173317452, 'std_time': 0.0, 'min_time': 0.001110112173317452, 'max_time': 0.001110112173317452}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0010995672064184907, 'std_time': 0.0, 'min_time': 0.0010995672064184907, 'max_time': 0.0010995672064184907}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.001103582231720994, 'std_time': 0.0, 'min_time': 0.001103582231720994, 'max_time': 0.001103582231720994}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0011028016107322196, 'std_time': 4.336808689942018e-19, 'min_time': 0.0011028016107322196, 'max_time': 0.0011028016107322196}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0011013988442204643, 'std_time': 0.0, 'min_time': 0.0011013988442204643, 'max_time': 0.0011013988442204643}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0011038921288484653, 'std_time': 0.0, 'min_time': 0.0011038921288484653, 'max_time': 0.0011038921288484653}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0010968895823762733, 'std_time': 2.168404344971009e-19, 'min_time': 0.0010968895823762733, 'max_time': 0.0010968895823762733}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0011104098438511232, 'std_time': 4.336808689942018e-19, 'min_time': 0.0011104098438511232, 'max_time': 0.0011104098438511232}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0010961263607709836, 'std_time': 0.0, 'min_time': 0.0010961263607709836, 'max_time': 0.0010961263607709836}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0011095201240253637, 'std_time': 0.0, 'min_time': 0.0011095201240253637, 'max_time': 0.0011095201240253637}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0010996443280101528, 'std_time': 2.168404344971009e-19, 'min_time': 0.0010996443280101528, 'max_time': 0.0010996443280101528}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.001099373932185728, 'std_time': 2.168404344971009e-19, 'min_time': 0.001099373932185728, 'max_time': 0.001099373932185728}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0011004193059556348, 'std_time': 0.0, 'min_time': 0.0011004193059556348, 'max_time': 0.0011004193059556348}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0011019485706878602, 'std_time': 0.0, 'min_time': 0.0011019485706878602, 'max_time': 0.0011019485706878602}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.00110836188938961, 'std_time': 0.0, 'min_time': 0.00110836188938961, 'max_time': 0.00110836188938961}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0010932700403578418, 'std_time': 0.0, 'min_time': 0.0010932700403578418, 'max_time': 0.0010932700403578418}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0011053085327148438, 'std_time': 0.0, 'min_time': 0.0011053085327148438, 'max_time': 0.0011053085327148438}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0011021526607536, 'std_time': 0.0, 'min_time': 0.0011021526607536, 'max_time': 0.0011021526607536}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0011013240738968408, 'std_time': 0.0, 'min_time': 0.0011013240738968408, 'max_time': 0.0011013240738968408}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0011019819586940065, 'std_time': 2.168404344971009e-19, 'min_time': 0.0011019819586940065, 'max_time': 0.0011019819586940065}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0010988524209347937, 'std_time': 2.168404344971009e-19, 'min_time': 0.0010988524209347937, 'max_time': 0.0010988524209347937}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0011090061368321527, 'std_time': 0.0, 'min_time': 0.0011090061368321527, 'max_time': 0.0011090061368321527}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0010965495890179094, 'std_time': 2.168404344971009e-19, 'min_time': 0.0010965495890179094, 'max_time': 0.0010965495890179094}, {'metrics': {'0': {'precision': 0.7953488372093023, 'recall': 0.9661016949152542, 'f1-score': 0.8724489795918368, 'support': 177.0}, '1': {'precision': 0.9794520547945206, 'recall': 0.8666666666666667, 'f1-score': 0.9196141479099679, 'support': 330.0}, 'accuracy': 0.9013806706114399, 'macro avg': {'precision': 0.8874004460019114, 'recall': 0.9163841807909605, 'f1-score': 0.8960315637509023, 'support': 507.0}, 'weighted avg': {'precision': 0.9151793338624028, 'recall': 0.9013806706114399, 'f1-score': 0.9031482015740523, 'support': 507.0}}, 'avg_time': 0.0011056386507474459, 'std_time': 2.168404344971009e-19, 'min_time': 0.0011056386507474459, 'max_time': 0.0011056386507474459}], 'kinder': [{'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0017663844024078757, 'std_time': 0.00031251121724511867, 'min_time': 0.0008006095886230469, 'max_time': 0.0024302005767822266}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0017404028131992003, 'std_time': 0.00029578883271024186, 'min_time': 0.0008089542388916016, 'max_time': 0.002411365509033203}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0017438900621631478, 'std_time': 0.0002979393316302848, 'min_time': 0.0008032321929931641, 'max_time': 0.002373218536376953}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0017380525794210313, 'std_time': 0.0002946754267543613, 'min_time': 0.0008041858673095703, 'max_time': 0.0024662017822265625}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0017503975312921066, 'std_time': 0.00029598906245349564, 'min_time': 0.0008511543273925781, 'max_time': 0.002374410629272461}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0011144355882572222, 'std_time': 0.0, 'min_time': 0.0011144355882572222, 'max_time': 0.0011144355882572222}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0011367541325243214, 'std_time': 0.0, 'min_time': 0.0011367541325243214, 'max_time': 0.0011367541325243214}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0011204201963883411, 'std_time': 0.0, 'min_time': 0.0011204201963883411, 'max_time': 0.0011204201963883411}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0011273826224894464, 'std_time': 2.168404344971009e-19, 'min_time': 0.0011273826224894464, 'max_time': 0.0011273826224894464}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0011395223533050924, 'std_time': 0.0, 'min_time': 0.0011395223533050924, 'max_time': 0.0011395223533050924}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0011226316041584256, 'std_time': 0.0, 'min_time': 0.0011226316041584256, 'max_time': 0.0011226316041584256}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0011315013788923433, 'std_time': 4.336808689942018e-19, 'min_time': 0.0011315013788923433, 'max_time': 0.0011315013788923433}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.001134339767166331, 'std_time': 0.0, 'min_time': 0.001134339767166331, 'max_time': 0.001134339767166331}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.00112120863757556, 'std_time': 2.168404344971009e-19, 'min_time': 0.00112120863757556, 'max_time': 0.00112120863757556}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0011473977113071877, 'std_time': 2.168404344971009e-19, 'min_time': 0.0011473977113071877, 'max_time': 0.0011473977113071877}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0011331944525996341, 'std_time': 4.336808689942018e-19, 'min_time': 0.0011331944525996341, 'max_time': 0.0011331944525996341}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0011237218410153932, 'std_time': 0.0, 'min_time': 0.0011237218410153932, 'max_time': 0.0011237218410153932}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0011448724360405645, 'std_time': 0.0, 'min_time': 0.0011448724360405645, 'max_time': 0.0011448724360405645}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0011253281484676313, 'std_time': 0.0, 'min_time': 0.0011253281484676313, 'max_time': 0.0011253281484676313}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0011396596703348281, 'std_time': 2.168404344971009e-19, 'min_time': 0.0011396596703348281, 'max_time': 0.0011396596703348281}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0011333936377416684, 'std_time': 0.0, 'min_time': 0.0011333936377416684, 'max_time': 0.0011333936377416684}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0011257438720027103, 'std_time': 4.336808689942018e-19, 'min_time': 0.0011257438720027103, 'max_time': 0.0011257438720027103}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0011388191693945777, 'std_time': 0.0, 'min_time': 0.0011388191693945777, 'max_time': 0.0011388191693945777}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0011350180529340914, 'std_time': 4.336808689942018e-19, 'min_time': 0.0011350180529340914, 'max_time': 0.0011350180529340914}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0011223479162288618, 'std_time': 0.0, 'min_time': 0.0011223479162288618, 'max_time': 0.0011223479162288618}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.001144946375979653, 'std_time': 0.0, 'min_time': 0.001144946375979653, 'max_time': 0.001144946375979653}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0011318854138820985, 'std_time': 2.168404344971009e-19, 'min_time': 0.0011318854138820985, 'max_time': 0.0011318854138820985}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0011272958562343934, 'std_time': 2.168404344971009e-19, 'min_time': 0.0011272958562343934, 'max_time': 0.0011272958562343934}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0011406382427939885, 'std_time': 0.0, 'min_time': 0.0011406382427939885, 'max_time': 0.0011406382427939885}, {'metrics': {'0': {'precision': 0.9008264462809917, 'recall': 0.9732142857142857, 'f1-score': 0.9356223175965666, 'support': 112.0}, '1': {'precision': 0.9846153846153847, 'recall': 0.9411764705882353, 'f1-score': 0.9624060150375939, 'support': 204.0}, 'accuracy': 0.9525316455696202, 'macro avg': {'precision': 0.9427209154481881, 'recall': 0.9571953781512605, 'f1-score': 0.9490141663170802, 'support': 316.0}, 'weighted avg': {'precision': 0.9549180393829416, 'recall': 0.9525316455696202, 'f1-score': 0.9529130589825463, 'support': 316.0}}, 'avg_time': 0.0011332351950150501, 'std_time': 0.0, 'min_time': 0.0011332351950150501, 'max_time': 0.0011332351950150501}], 'energie': [{'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.0018984192599492576, 'std_time': 0.0003361873898704596, 'min_time': 0.0008685588836669922, 'max_time': 0.0026183128356933594}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.001218136934006976, 'std_time': 0.0, 'min_time': 0.001218136934006976, 'max_time': 0.001218136934006976}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.0012157601601925127, 'std_time': 2.168404344971009e-19, 'min_time': 0.0012157601601925127, 'max_time': 0.0012157601601925127}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.001228226692977141, 'std_time': 0.0, 'min_time': 0.001228226692977141, 'max_time': 0.001228226692977141}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.0012297766196295388, 'std_time': 0.0, 'min_time': 0.0012297766196295388, 'max_time': 0.0012297766196295388}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.0012220385161088537, 'std_time': 0.0, 'min_time': 0.0012220385161088537, 'max_time': 0.0012220385161088537}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.0012177000391668607, 'std_time': 4.336808689942018e-19, 'min_time': 0.0012177000391668607, 'max_time': 0.0012177000391668607}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.0012297218533583463, 'std_time': 0.0, 'min_time': 0.0012297218533583463, 'max_time': 0.0012297218533583463}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.001228416521932177, 'std_time': 0.0, 'min_time': 0.001228416521932177, 'max_time': 0.001228416521932177}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.0012217712731764931, 'std_time': 2.168404344971009e-19, 'min_time': 0.0012217712731764931, 'max_time': 0.0012217712731764931}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.0012236172671145108, 'std_time': 0.0, 'min_time': 0.0012236172671145108, 'max_time': 0.0012236172671145108}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.0012281896330943792, 'std_time': 2.168404344971009e-19, 'min_time': 0.0012281896330943792, 'max_time': 0.0012281896330943792}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.0012222855819939331, 'std_time': 2.168404344971009e-19, 'min_time': 0.0012222855819939331, 'max_time': 0.0012222855819939331}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.0012205260611156932, 'std_time': 2.168404344971009e-19, 'min_time': 0.0012205260611156932, 'max_time': 0.0012205260611156932}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.0012276180873468955, 'std_time': 4.336808689942018e-19, 'min_time': 0.0012276180873468955, 'max_time': 0.0012276180873468955}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.0012254327895933688, 'std_time': 4.336808689942018e-19, 'min_time': 0.0012254327895933688, 'max_time': 0.0012254327895933688}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.0012116329245822623, 'std_time': 0.0, 'min_time': 0.0012116329245822623, 'max_time': 0.0012116329245822623}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.0012139084013838431, 'std_time': 0.0, 'min_time': 0.0012139084013838431, 'max_time': 0.0012139084013838431}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.0012185935941178975, 'std_time': 0.0, 'min_time': 0.0012185935941178975, 'max_time': 0.0012185935941178975}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.0012200479886280645, 'std_time': 2.168404344971009e-19, 'min_time': 0.0012200479886280645, 'max_time': 0.0012200479886280645}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.0012145540668968503, 'std_time': 0.0, 'min_time': 0.0012145540668968503, 'max_time': 0.0012145540668968503}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.0012238165669284748, 'std_time': 0.0, 'min_time': 0.0012238165669284748, 'max_time': 0.0012238165669284748}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.0012254381426875455, 'std_time': 0.0, 'min_time': 0.0012254381426875455, 'max_time': 0.0012254381426875455}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.0012127476035004453, 'std_time': 0.0, 'min_time': 0.0012127476035004453, 'max_time': 0.0012127476035004453}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.0012202633477245589, 'std_time': 2.168404344971009e-19, 'min_time': 0.0012202633477245589, 'max_time': 0.0012202633477245589}, {'metrics': {'0': {'precision': 0.954983922829582, 'recall': 0.9428571428571428, 'f1-score': 0.9488817891373802, 'support': 315.0}, '1': {'precision': 0.9328358208955224, 'recall': 0.946969696969697, 'f1-score': 0.9398496240601504, 'support': 264.0}, 'accuracy': 0.9447322970639033, 'macro avg': {'precision': 0.9439098718625523, 'recall': 0.9449134199134199, 'f1-score': 0.9443657065987653, 'support': 579.0}, 'weighted avg': {'precision': 0.9448853064036896, 'recall': 0.9447322970639033, 'f1-score': 0.9447634962524256, 'support': 579.0}}, 'avg_time': 0.0012200533417222412, 'std_time': 0.0, 'min_time': 0.0012200533417222412, 'max_time': 0.0012200533417222412}]})})\n"
     ]
    }
   ],
   "source": [
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Chunk Level Predictions and Output Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from tabulate import tabulate\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path to save the dictionary\n",
    "file_path =f\"eval_runtime_{FEATURES}_{SPLIT}_chunks.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save the dictionary to disk as JSON\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[43mfile_path\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      3\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(eval_results, file)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'file_path' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the dictionary to disk as JSON\n",
    "with open(file_path, \"w\") as file:\n",
    "    json.dump(eval_results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, \"r\") as file:\n",
    "    eval_results = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table>\n",
      "<thead>\n",
      "<tr><th>Model         </th><th style=\"text-align: right;\">  cannabis Acc.</th><th style=\"text-align: right;\">  cannabis Prec.</th><th style=\"text-align: right;\">  cannabis Rec.</th><th style=\"text-align: right;\">  cannabis F1</th><th style=\"text-align: right;\">  cannabis Avg. Time</th><th style=\"text-align: right;\">  cannabis STD Time</th><th style=\"text-align: right;\">  kinder Acc.</th><th style=\"text-align: right;\">  kinder Prec.</th><th style=\"text-align: right;\">  kinder Rec.</th><th style=\"text-align: right;\">  kinder F1</th><th style=\"text-align: right;\">  kinder Avg. Time</th><th style=\"text-align: right;\">  kinder STD Time</th><th style=\"text-align: right;\">  energie Acc.</th><th style=\"text-align: right;\">  energie Prec.</th><th style=\"text-align: right;\">  energie Rec.</th><th style=\"text-align: right;\">  energie F1</th><th style=\"text-align: right;\">  energie Avg. Time</th><th style=\"text-align: right;\">  energie STD Time</th></tr>\n",
      "</thead>\n",
      "<tbody>\n",
      "<tr><td>svm_classifier</td><td style=\"text-align: right;\">          0.901</td><td style=\"text-align: right;\">           0.000</td><td style=\"text-align: right;\">          0.000</td><td style=\"text-align: right;\">        0.000</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">              0.000</td><td style=\"text-align: right;\">        0.953</td><td style=\"text-align: right;\">         0.000</td><td style=\"text-align: right;\">        0.000</td><td style=\"text-align: right;\">      0.000</td><td style=\"text-align: right;\">             0.001</td><td style=\"text-align: right;\">            0.000</td><td style=\"text-align: right;\">         0.945</td><td style=\"text-align: right;\">          0.000</td><td style=\"text-align: right;\">         0.000</td><td style=\"text-align: right;\">       0.000</td><td style=\"text-align: right;\">              0.001</td><td style=\"text-align: right;\">             0.000</td></tr>\n",
      "</tbody>\n",
      "</table>\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "\n",
    "# Function to compute average metrics and runtime statistics\n",
    "def compute_average_metrics(eval_results):\n",
    "    averaged_results = defaultdict(dict)\n",
    "    \n",
    "    for model, topics_metrics in eval_results.items():\n",
    "        for topic, runs in topics_metrics.items():\n",
    "            avg_metrics = defaultdict(list)\n",
    "            for run in runs:\n",
    "                metrics = run.get('metrics', {})\n",
    "                for key, value in metrics.items():\n",
    "                    if isinstance(value, (int, float)):  # Ensure the value is numeric\n",
    "                        avg_metrics[key].append(value)\n",
    "                avg_metrics['avg_time'].append(run.get('avg_time', 0))\n",
    "                avg_metrics['std_time'].append(run.get('std_time', 0))\n",
    "                avg_metrics['min_time'].append(run.get('min_time', 0))\n",
    "                avg_metrics['max_time'].append(run.get('max_time', 0))\n",
    "            \n",
    "            # Calculate means only if there are values to avoid empty list issues\n",
    "            averaged_results[model][topic] = {metric: np.mean(values) for metric, values in avg_metrics.items() if len(values) > 0 and isinstance(values[0], (int, float))}\n",
    "            averaged_results[model][topic].update({\n",
    "                'avg_time_std': np.std(avg_metrics['avg_time']) if len(avg_metrics['avg_time']) > 0 else 0,\n",
    "                'std_time_std': np.std(avg_metrics['std_time']) if len(avg_metrics['std_time']) > 0 else 0,\n",
    "                'min_time_std': np.std(avg_metrics['min_time']) if len(avg_metrics['min_time']) > 0 else 0,\n",
    "                'max_time_std': np.std(avg_metrics['max_time']) if len(avg_metrics['max_time']) > 0 else 0,\n",
    "            })\n",
    "    \n",
    "    return averaged_results\n",
    "\n",
    "# Compute average metrics\n",
    "averaged_eval_results = compute_average_metrics(eval_results)\n",
    "\n",
    "# Identify all topics (assuming all models are evaluated on the same topics)\n",
    "topics = list(next(iter(averaged_eval_results.values())).keys())\n",
    "\n",
    "# Prepare headers for the table: each topic will have six metrics\n",
    "headers = [\"Model\"] + [f\"{topic} {metric}\" for topic in topics for metric in [\"Acc.\", \"Prec.\", \"Rec.\", \"F1\", \"Avg. Time\", \"STD Time\"]]\n",
    "\n",
    "# Prepare rows: one row per model, containing metrics for each topic\n",
    "rows = []\n",
    "for model, topics_metrics in averaged_eval_results.items():\n",
    "    row = [model]  # Start with the model name\n",
    "    for topic in topics:\n",
    "        metrics = topics_metrics.get(topic, {})\n",
    "        row.extend([\n",
    "            metrics.get('accuracy', 0.0),\n",
    "            metrics.get('precision', 0.0),\n",
    "            metrics.get('recall', 0.0),\n",
    "            metrics.get('f1-score', 0.0),  # Assuming the key for F1 score is 'f1-score'\n",
    "            metrics.get('avg_time', 0.0),\n",
    "            metrics.get('std_time', 0.0)\n",
    "        ])\n",
    "    rows.append(row)\n",
    "\n",
    "# Generate the HTML table\n",
    "table_html = tabulate(rows, headers=headers, tablefmt=\"html\", showindex=\"never\", floatfmt=\".3f\")\n",
    "\n",
    "print(table_html)  # This will print the HTML table; in a real application, you might save this to an HTML file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Model         </th><th style=\"text-align: right;\">  cannabis Acc.</th><th style=\"text-align: right;\">  cannabis Prec.</th><th style=\"text-align: right;\">  cannabis Rec.</th><th style=\"text-align: right;\">  cannabis F1</th><th style=\"text-align: right;\">  cannabis Avg. Time</th><th style=\"text-align: right;\">  cannabis STD Time</th><th style=\"text-align: right;\">  kinder Acc.</th><th style=\"text-align: right;\">  kinder Prec.</th><th style=\"text-align: right;\">  kinder Rec.</th><th style=\"text-align: right;\">  kinder F1</th><th style=\"text-align: right;\">  kinder Avg. Time</th><th style=\"text-align: right;\">  kinder STD Time</th><th style=\"text-align: right;\">  energie Acc.</th><th style=\"text-align: right;\">  energie Prec.</th><th style=\"text-align: right;\">  energie Rec.</th><th style=\"text-align: right;\">  energie F1</th><th style=\"text-align: right;\">  energie Avg. Time</th><th style=\"text-align: right;\">  energie STD Time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>svm_classifier</td><td style=\"text-align: right;\">          0.901</td><td style=\"text-align: right;\">           0.000</td><td style=\"text-align: right;\">          0.000</td><td style=\"text-align: right;\">        0.000</td><td style=\"text-align: right;\">               0.001</td><td style=\"text-align: right;\">              0.000</td><td style=\"text-align: right;\">        0.953</td><td style=\"text-align: right;\">         0.000</td><td style=\"text-align: right;\">        0.000</td><td style=\"text-align: right;\">      0.000</td><td style=\"text-align: right;\">             0.001</td><td style=\"text-align: right;\">            0.000</td><td style=\"text-align: right;\">         0.945</td><td style=\"text-align: right;\">          0.000</td><td style=\"text-align: right;\">         0.000</td><td style=\"text-align: right;\">       0.000</td><td style=\"text-align: right;\">              0.001</td><td style=\"text-align: right;\">             0.000</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(table_html))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average metrics\n",
    "averaged_eval_results = compute_average_metrics(eval_results)\n",
    "\n",
    "# Prepare headers for the table\n",
    "headers = [\"Model\", \"Avg. F1 Score\", \"Avg. Runtime\", \"Runtime STD\"]\n",
    "\n",
    "# Prepare rows: one row per model, containing average F1 score and average runtime\n",
    "rows = []\n",
    "for model, topics_metrics in averaged_eval_results.items():\n",
    "    avg_f1_scores = []\n",
    "    avg_times = []\n",
    "    for topic, metrics in topics_metrics.items():\n",
    "        avg_f1_scores.append(metrics.get('f1', 0.0))\n",
    "        avg_times.append(metrics.get('avg_time', 0.0))\n",
    "    \n",
    "    avg_f1_score = np.mean(avg_f1_scores)\n",
    "    avg_runtime = np.mean(avg_times)\n",
    "    runtime_std = np.std(avg_times)\n",
    "    \n",
    "    row = [model, avg_f1_score, avg_runtime, runtime_std]\n",
    "    rows.append(row)\n",
    "\n",
    "# Generate the HTML table\n",
    "table_html = tabulate(rows, headers=headers, tablefmt=\"html\", showindex=\"never\", floatfmt=\".3f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Model                                        </th><th style=\"text-align: right;\">  Avg. F1 Score</th><th style=\"text-align: right;\">  Avg. Runtime</th><th style=\"text-align: right;\">  Runtime STD</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>distilbert/distilbert-base-multilingual-cased</td><td style=\"text-align: right;\">          0.997</td><td style=\"text-align: right;\">         0.008</td><td style=\"text-align: right;\">        0.000</td></tr>\n",
       "<tr><td>google-bert/bert-base-multilingual-cased     </td><td style=\"text-align: right;\">          0.999</td><td style=\"text-align: right;\">         0.017</td><td style=\"text-align: right;\">        0.001</td></tr>\n",
       "<tr><td>FacebookAI/xlm-roberta-base                  </td><td style=\"text-align: right;\">          0.994</td><td style=\"text-align: right;\">         0.016</td><td style=\"text-align: right;\">        0.001</td></tr>\n",
       "<tr><td>FacebookAI/xlm-roberta-large                 </td><td style=\"text-align: right;\">          0.997</td><td style=\"text-align: right;\">         0.051</td><td style=\"text-align: right;\">        0.002</td></tr>\n",
       "<tr><td>dbmdz/bert-base-german-uncased               </td><td style=\"text-align: right;\">          0.999</td><td style=\"text-align: right;\">         0.015</td><td style=\"text-align: right;\">        0.001</td></tr>\n",
       "<tr><td>deepset/gelectra-large                       </td><td style=\"text-align: right;\">          0.998</td><td style=\"text-align: right;\">         0.052</td><td style=\"text-align: right;\">        0.005</td></tr>\n",
       "<tr><td>deepset/gelectra-base                        </td><td style=\"text-align: right;\">          0.993</td><td style=\"text-align: right;\">         0.016</td><td style=\"text-align: right;\">        0.002</td></tr>\n",
       "<tr><td>deepset/gbert-large                          </td><td style=\"text-align: right;\">          0.995</td><td style=\"text-align: right;\">         0.052</td><td style=\"text-align: right;\">        0.005</td></tr>\n",
       "<tr><td>deepset/gbert-base                           </td><td style=\"text-align: right;\">          0.998</td><td style=\"text-align: right;\">         0.016</td><td style=\"text-align: right;\">        0.002</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(table_html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s2j-content-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
