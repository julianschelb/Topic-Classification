{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Multiple Classifiers Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import load_dataset, load_from_disk, concatenate_datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Random Seed for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a seed for random module\n",
    "random.seed(42)\n",
    "\n",
    "# Set a seed for numpy module\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set a seed for torch module\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING = \"random\" # \"random\", \"stratified\", \"clustered\", \"shared_domain\"\n",
    "SUFFIX = \"_extended\" #\"\", \"_holdout\", \"_extended\"\n",
    "SPLIT = \"extended\" # \"train\", \"test\", \"holdout\", \"extended\"\n",
    "MAX_CONTENT_LENGTH = 384 # 496, 192\n",
    "OVERLAP = 64\n",
    "FEATURES = \"url\" # \"url\", \"content\", \"url_and_content\"\n",
    "FOLDER_DATA = \"data\"\n",
    "FOLDER_MODELS = \"models_ccu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPICS = [\"cannabis\", \"kinder\", \"energie\"]\n",
    "#TOPICS = [\"cannabis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [#\"distilbert/distilbert-base-multilingual-cased\",\n",
    "          \"google-bert/bert-base-multilingual-cased\", \n",
    "          \"FacebookAI/xlm-roberta-base\", \n",
    "          \"FacebookAI/xlm-roberta-large\", \n",
    "          \"dbmdz/bert-base-german-uncased\", \n",
    "          \"deepset/gelectra-large\",\n",
    "          \"deepset/gelectra-base\",\n",
    "          \"deepset/gbert-large\",\n",
    "          \"deepset/gbert-base\",\n",
    "          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(labels, preds):\n",
    "    \"\"\"\n",
    "    Calculates the accuracy, precision, recall, and F1 score for the given labels and predictions and returns them in a dictionary.\n",
    "    \"\"\"\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'precision': precision_score(labels, preds, average='binary'),\n",
    "        'recall': recall_score(labels, preds, average='binary'),\n",
    "        'f1': f1_score(labels, preds, average='binary'),\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def majority_voting(answers):\n",
    "    \"\"\"Apply majority voting to a list of arbitrary classification answers.\"\"\"\n",
    "    count = Counter(answers)\n",
    "    most_common = count.most_common()  # Get all common answers sorted by frequency\n",
    "\n",
    "    if not most_common:\n",
    "        return 0 # Handle empty input scenario\n",
    "\n",
    "    # Check for ties at the highest count\n",
    "    max_votes = most_common[0][1]\n",
    "    tied_classes = [cls for cls, votes in most_common if votes == max_votes]\n",
    "\n",
    "    if len(tied_classes) > 1:\n",
    "        return max(tied_classes)  # Return the maximum class label in case of a tie\n",
    "    return tied_classes[0]  # Return the class with the most votes\n",
    "\n",
    "majority_voting([1, 1, 2, 2, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Baseline Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import load_dataset, load_from_disk, concatenate_datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###### Evaluating on cannabis ###### \n",
      "\n",
      "\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'url_path'],\n",
      "        num_rows: 410\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'url_path'],\n",
      "        num_rows: 46\n",
      "    })\n",
      "    holdout: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'url_path'],\n",
      "        num_rows: 3448\n",
      "    })\n",
      "    extended: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'url_path', 'preds'],\n",
      "        num_rows: 44432\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/44432 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44432/44432 [00:07<00:00, 5720.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for cannabis: {'accuracy': 0.994623777361133, 'precision': 0.10266159695817491, 'recall': 0.9310344827586207, 'f1': 0.18493150684931506}\n",
      "\n",
      "\n",
      "###### Evaluating on kinder ###### \n",
      "\n",
      "\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'url_path'],\n",
      "        num_rows: 384\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'url_path'],\n",
      "        num_rows: 44\n",
      "    })\n",
      "    holdout: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'url_path'],\n",
      "        num_rows: 3722\n",
      "    })\n",
      "    extended: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'url_path', 'preds'],\n",
      "        num_rows: 53253\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53253/53253 [00:09<00:00, 5911.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for kinder: {'accuracy': 0.915424583760003, 'precision': 0.008680169152014245, 'recall': 0.8666666666666667, 'f1': 0.017188188629352136}\n",
      "\n",
      "\n",
      "###### Evaluating on energie ###### \n",
      "\n",
      "\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'url_path'],\n",
      "        num_rows: 408\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'url_path'],\n",
      "        num_rows: 46\n",
      "    })\n",
      "    holdout: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'url_path'],\n",
      "        num_rows: 4164\n",
      "    })\n",
      "    extended: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'url_path', 'preds'],\n",
      "        num_rows: 45925\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45925/45925 [00:07<00:00, 5881.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for energie: {'accuracy': 0.9073489384866631, 'precision': 0.00584932147870847, 'recall': 0.8064516129032258, 'f1': 0.011614401858304297}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "eval_results_pages = defaultdict(dict)\n",
    "predictions_per_topic_baseline = defaultdict(dict)\n",
    "\n",
    "for topic in TOPICS: # ----------------------------------------------------------------------\n",
    "\n",
    "    print(f\"\\n\\n###### Evaluating on {topic} ###### \\n\\n\")\n",
    "    dataset = load_from_disk(f\"../../data_ccu/tmp/processed_dataset_{topic}_buffed_chunkified_{SAMPLING}{SUFFIX}_{MAX_CONTENT_LENGTH}_s_SVM_{FEATURES}_{SPLIT}\")\n",
    "    \n",
    "    print(dataset)\n",
    "    \n",
    "    # Group dataset examples by URL, with a fallback to domain\n",
    "    grouped_dataset = {}\n",
    "    for example in tqdm(dataset[SPLIT]):\n",
    "        url = example.get(\"view_url\") or example.get(\"domain\")\n",
    "        example_filtered = {k: example[k] for k in [\"text\", \"domain\", \"preds\", \"label\", \"category\", \"annotation_type\", \"lang\"]}\n",
    "        grouped_dataset.setdefault(url, []).append(example_filtered)\n",
    "        \n",
    "    # Extract labels\n",
    "    labels = []\n",
    "    for url, chunks in grouped_dataset.items():\n",
    "        preds = [chunk[\"label\"] for chunk in chunks]\n",
    "        labels.append(max(preds))\n",
    "        \n",
    "    # Merge chunk level predictions\n",
    "    predictions = []\n",
    "    for url, chunks in grouped_dataset.items():\n",
    "        preds = [chunk[\"preds\"] for chunk in chunks]\n",
    "        #pred = majority_voting([pred for pred in preds if pred > 0]) if max(preds) > 0 else 0\n",
    "        predictions.append(max(preds))\n",
    "\n",
    "    # Use the trained model to make predictions on the test set\n",
    "    metrics = calc_metrics(labels, predictions)\n",
    "    print(f\"Metrics for {topic}: {metrics}\")\n",
    "    \n",
    "    # Update the eval_results dictionary\n",
    "    eval_results_pages[topic] = metrics\n",
    "    \n",
    "    predictions_per_topic_baseline[topic] = {\"labels\": labels, \"predictions\": predictions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions_per_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Chi-squared value': 5.142857142857143, 'P-value': 0.02334220201289086, 'Significance': True, 'Interpretation': 'The difference between the models is statistically significant.'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "def compare_models(predictions_model, predictions_baseline, true_labels, alpha=0.05):\n",
    "    \"\"\"Compares a model's predictions with a baseline model's predictions using McNemar's test.\"\"\"\n",
    "    \n",
    "    # Calculate b and c for the contingency table\n",
    "    b = np.sum((predictions_model == true_labels) & (predictions_baseline != true_labels))\n",
    "    c = np.sum((predictions_model != true_labels) & (predictions_baseline == true_labels))\n",
    "\n",
    "    # Construct the contingency table\n",
    "    contingency_table = np.array([[0, b], [c, 0]])\n",
    "\n",
    "    # Perform McNemar's Test\n",
    "    result = mcnemar(contingency_table, exact=False, correction=True)\n",
    "\n",
    "    # Interpretation\n",
    "    significance = result.pvalue < alpha\n",
    "    interpretation = \"The difference between the models is statistically significant.\" if significance else \"The difference between the models is not statistically significant.\"\n",
    "\n",
    "    return {\n",
    "        \"Chi-squared value\": result.statistic,\n",
    "        \"P-value\": result.pvalue,\n",
    "        \"Significance\": significance,\n",
    "        \"Interpretation\": interpretation\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "predictions_model = np.array([0, 1, 0, 0, 1, 0, 1, 0, 1, 1])\n",
    "predictions_baseline = np.array([1, 0, 1, 0, 0, 0, 0, 0, 0, 0])\n",
    "true_labels = np.array([0, 1, 0, 0, 1, 0, 1, 0, 1, 1])\n",
    "\n",
    "result = compare_models(predictions_model, predictions_baseline, true_labels)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "###### Evaluating model google-bert/bert-base-multilingual-cased on cannabis ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44432/44432 [00:07<00:00, 5810.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for google-bert/bert-base-multilingual-cased on cannabis: {'accuracy': 0.9994352707312114, 'precision': 0.5384615384615384, 'recall': 0.9655172413793104, 'f1': 0.691358024691358}\n",
      "{'Chi-squared value': 177.64426877470356, 'P-value': 1.5841283620116657e-40, 'Significance': True, 'Interpretation': 'The difference between the models is statistically significant.'}\n",
      "\n",
      "\n",
      "###### Evaluating model FacebookAI/xlm-roberta-base on cannabis ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44432/44432 [00:07<00:00, 5686.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-base on cannabis: {'accuracy': 0.9988931306331744, 'precision': 0.3684210526315789, 'recall': 0.9655172413793104, 'f1': 0.5333333333333333}\n",
      "{'Chi-squared value': 124.8904593639576, 'P-value': 5.378316564684772e-29, 'Significance': True, 'Interpretation': 'The difference between the models is statistically significant.'}\n",
      "\n",
      "\n",
      "###### Evaluating model FacebookAI/xlm-roberta-large on cannabis ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44432/44432 [00:07<00:00, 5755.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-large on cannabis: {'accuracy': 0.9990738439991868, 'precision': 0.4117647058823529, 'recall': 0.9655172413793104, 'f1': 0.5773195876288659}\n",
      "{'Chi-squared value': 139.69454545454545, 'P-value': 3.104631760241412e-32, 'Significance': True, 'Interpretation': 'The difference between the models is statistically significant.'}\n",
      "\n",
      "\n",
      "###### Evaluating model dbmdz/bert-base-german-uncased on cannabis ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44432/44432 [00:07<00:00, 5785.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for dbmdz/bert-base-german-uncased on cannabis: {'accuracy': 0.9983284013643859, 'precision': 0.2727272727272727, 'recall': 0.9310344827586207, 'f1': 0.421875}\n",
      "{'Chi-squared value': 86.82679738562092, 'P-value': 1.1845360287123875e-20, 'Significance': True, 'Interpretation': 'The difference between the models is statistically significant.'}\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gelectra-large on cannabis ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44432/44432 [00:07<00:00, 5668.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-large on cannabis: {'accuracy': 0.999457859901963, 'precision': 0.5490196078431373, 'recall': 0.9655172413793104, 'f1': 0.7}\n",
      "{'Chi-squared value': 174.49615384615385, 'P-value': 7.713200274413404e-40, 'Significance': True, 'Interpretation': 'The difference between the models is statistically significant.'}\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gelectra-base on cannabis ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44432/44432 [00:07<00:00, 5771.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-base on cannabis: {'accuracy': 0.9960920734599833, 'precision': 0.06626506024096386, 'recall': 0.3793103448275862, 'f1': 0.11282051282051282}\n",
      "{'Chi-squared value': 10.694516971279374, 'P-value': 0.0010745352524984533, 'Significance': True, 'Interpretation': 'The difference between the models is statistically significant.'}\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gbert-large on cannabis ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44432/44432 [00:07<00:00, 5705.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-large on cannabis: {'accuracy': 0.9993675032189568, 'precision': 0.509090909090909, 'recall': 0.9655172413793104, 'f1': 0.6666666666666666}\n",
      "{'Chi-squared value': 169.30620155038758, 'P-value': 1.0488195193611374e-38, 'Significance': True, 'Interpretation': 'The difference between the models is statistically significant.'}\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gbert-base on cannabis ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44432/44432 [00:07<00:00, 5899.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-base on cannabis: {'accuracy': 0.9991642006821929, 'precision': 0.42, 'recall': 0.7241379310344828, 'f1': 0.5316455696202531}\n",
      "{'Chi-squared value': 150.9433962264151, 'P-value': 1.0783504830038695e-34, 'Significance': True, 'Interpretation': 'The difference between the models is statistically significant.'}\n",
      "\n",
      "\n",
      "###### Evaluating model google-bert/bert-base-multilingual-cased on kinder ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53253/53253 [00:09<00:00, 5613.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for google-bert/bert-base-multilingual-cased on kinder: {'accuracy': 0.9314673645086662, 'precision': 0.01149739939775527, 'recall': 0.9333333333333333, 'f1': 0.022714981070849107}\n",
      "{'Chi-squared value': 92.80283337665713, 'P-value': 5.7772386086477775e-22, 'Significance': True, 'Interpretation': 'The difference between the models is statistically significant.'}\n",
      "\n",
      "\n",
      "###### Evaluating model FacebookAI/xlm-roberta-base on kinder ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53253/53253 [00:09<00:00, 5801.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-base on kinder: {'accuracy': 0.9763340539310502, 'precision': 0.03263403263403263, 'recall': 0.9333333333333333, 'f1': 0.06306306306306306}\n",
      "{'Chi-squared value': 1907.2365889752127, 'P-value': 0.0, 'Significance': True, 'Interpretation': 'The difference between the models is statistically significant.'}\n",
      "\n",
      "\n",
      "###### Evaluating model FacebookAI/xlm-roberta-large on kinder ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53253/53253 [00:09<00:00, 5713.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-large on kinder: {'accuracy': 0.9452535366177419, 'precision': 0.014354066985645933, 'recall': 0.9333333333333333, 'f1': 0.0282733086502861}\n",
      "{'Chi-squared value': 341.08819875776396, 'P-value': 3.697271745071062e-76, 'Significance': True, 'Interpretation': 'The difference between the models is statistically significant.'}\n",
      "\n",
      "\n",
      "###### Evaluating model dbmdz/bert-base-german-uncased on kinder ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53253/53253 [00:09<00:00, 5742.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for dbmdz/bert-base-german-uncased on kinder: {'accuracy': 0.9476049607463876, 'precision': 0.014989293361884369, 'recall': 0.9333333333333333, 'f1': 0.029504741833508957}\n",
      "{'Chi-squared value': 402.23968675709693, 'P-value': 1.7921995373498607e-89, 'Significance': True, 'Interpretation': 'The difference between the models is statistically significant.'}\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gelectra-large on kinder ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53253/53253 [00:09<00:00, 5697.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-large on kinder: {'accuracy': 0.9309553608677513, 'precision': 0.01141304347826087, 'recall': 0.9333333333333333, 'f1': 0.022550335570469798}\n",
      "{'Chi-squared value': 86.3497225448445, 'P-value': 1.5076968099856985e-20, 'Significance': True, 'Interpretation': 'The difference between the models is statistically significant.'}\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gelectra-base on kinder ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53253/53253 [00:09<00:00, 5737.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-base on kinder: {'accuracy': 0.8637691053210452, 'precision': 0.0033393627382774455, 'recall': 0.5333333333333333, 'f1': 0.00663716814159292}\n",
      "{'Chi-squared value': 667.9936036036036, 'P-value': 2.7285893609902625e-147, 'Significance': True, 'Interpretation': 'The difference between the models is statistically significant.'}\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gbert-large on kinder ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53253/53253 [00:09<00:00, 5654.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-large on kinder: {'accuracy': 0.9376682974930785, 'precision': 0.012627781118460614, 'recall': 0.9333333333333333, 'f1': 0.024918421833283893}\n",
      "{'Chi-squared value': 184.3984427439925, 'P-value': 5.310363761280684e-42, 'Significance': True, 'Interpretation': 'The difference between the models is statistically significant.'}\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gbert-base on kinder ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53253/53253 [00:09<00:00, 5652.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-base on kinder: {'accuracy': 0.9175484507149088, 'precision': 0.009573740597219056, 'recall': 0.9333333333333333, 'f1': 0.01895306859205776}\n",
      "{'Chi-squared value': 1.4594882729211087, 'P-value': 0.22701155942299367, 'Significance': False, 'Interpretation': 'The difference between the models is not statistically significant.'}\n",
      "\n",
      "\n",
      "###### Evaluating model google-bert/bert-base-multilingual-cased on energie ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45925/45925 [00:07<00:00, 5751.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for google-bert/bert-base-multilingual-cased on energie: {'accuracy': 0.8711812738160044, 'precision': 0.0035431078117091276, 'recall': 0.6774193548387096, 'f1': 0.007049345417925478}\n",
      "{'Chi-squared value': 335.10884105557585, 'P-value': 7.414816598581238e-75, 'Significance': True, 'Interpretation': 'The difference between the models is statistically significant.'}\n",
      "\n",
      "\n",
      "###### Evaluating model FacebookAI/xlm-roberta-base on energie ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45925/45925 [00:07<00:00, 5777.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-base on energie: {'accuracy': 0.9364833968426782, 'precision': 0.0081799591002045, 'recall': 0.7741935483870968, 'f1': 0.016188870151770656}\n",
      "{'Chi-squared value': 291.70512402088775, 'P-value': 2.1136297615474224e-65, 'Significance': True, 'Interpretation': 'The difference between the models is statistically significant.'}\n",
      "\n",
      "\n",
      "###### Evaluating model FacebookAI/xlm-roberta-large on energie ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45925/45925 [00:08<00:00, 5656.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for FacebookAI/xlm-roberta-large on energie: {'accuracy': 0.9143168209036473, 'precision': 0.007070707070707071, 'recall': 0.9032258064516129, 'f1': 0.014031571034828364}\n",
      "{'Chi-squared value': 13.747770872737098, 'P-value': 0.00020906877802145257, 'Significance': True, 'Interpretation': 'The difference between the models is statistically significant.'}\n",
      "\n",
      "\n",
      "###### Evaluating model dbmdz/bert-base-german-uncased on energie ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45925/45925 [00:08<00:00, 5675.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for dbmdz/bert-base-german-uncased on energie: {'accuracy': 0.9039738704409364, 'precision': 0.0056446150372544595, 'recall': 0.8064516129032258, 'f1': 0.011210762331838564}\n",
      "{'Chi-squared value': 3.0339004733273636, 'P-value': 0.08154177683785487, 'Significance': False, 'Interpretation': 'The difference between the models is not statistically significant.'}\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gelectra-large on energie ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45925/45925 [00:08<00:00, 5632.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-large on energie: {'accuracy': 0.9832770821992379, 'precision': 0.030573248407643312, 'recall': 0.7741935483870968, 'f1': 0.058823529411764705}\n",
      "{'Chi-squared value': 2772.5749486652976, 'P-value': 0.0, 'Significance': True, 'Interpretation': 'The difference between the models is statistically significant.'}\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gelectra-base on energie ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45925/45925 [00:07<00:00, 5762.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gelectra-base on energie: {'accuracy': 0.9039085465432771, 'precision': 0.0027235587834770767, 'recall': 0.3870967741935484, 'f1': 0.005409060175794456}\n",
      "{'Chi-squared value': 3.4253752084491382, 'P-value': 0.06420165271935481, 'Significance': False, 'Interpretation': 'The difference between the models is not statistically significant.'}\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gbert-large on energie ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45925/45925 [00:08<00:00, 5702.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-large on energie: {'accuracy': 0.9229831246597714, 'precision': 0.007584269662921348, 'recall': 0.8709677419354839, 'f1': 0.015037593984962405}\n",
      "{'Chi-squared value': 73.52531464530892, 'P-value': 9.935373509181449e-18, 'Significance': True, 'Interpretation': 'The difference between the models is statistically significant.'}\n",
      "\n",
      "\n",
      "###### Evaluating model deepset/gbert-base on energie ###### \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45925/45925 [00:08<00:00, 5735.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for deepset/gbert-base on energie: {'accuracy': 0.9257267283614589, 'precision': 0.007575757575757576, 'recall': 0.8387096774193549, 'f1': 0.015015882183078255}\n",
      "{'Chi-squared value': 103.80499561787906, 'P-value': 2.232415660573675e-24, 'Significance': True, 'Interpretation': 'The difference between the models is statistically significant.'}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "eval_results_pages = defaultdict(dict)\n",
    "eval_results_significance = defaultdict(dict)\n",
    "\n",
    "for topic in TOPICS: # ----------------------------------------------------------------------\n",
    "    for model_name in MODELS: # -------------------------------------------------------------\n",
    "\n",
    "        print(f\"\\n\\n###### Evaluating model {model_name} on {topic} ###### \\n\\n\")\n",
    "        dataset = load_from_disk(f\"../../data/tmp/processed_dataset_{topic}_buffed_chunkified_{SAMPLING}{SUFFIX}_{MAX_CONTENT_LENGTH}_s_{model_name.split('/')[1]}_{FEATURES}_{SPLIT}/\")\n",
    "        \n",
    "        #print(dataset)\n",
    "        \n",
    "        # Group dataset examples by URL, with a fallback to domain\n",
    "        grouped_dataset = {}\n",
    "        for example in tqdm(dataset[SPLIT]):\n",
    "            url = example.get(\"view_url\") or example.get(\"domain\")\n",
    "            example_filtered = {k: example[k] for k in [\"text\", \"domain\", \"preds\", \"label\", \"category\", \"annotation_type\", \"lang\"]}\n",
    "            grouped_dataset.setdefault(url, []).append(example_filtered)\n",
    "            \n",
    "        # Extract labels\n",
    "        labels = []\n",
    "        for url, chunks in grouped_dataset.items():\n",
    "            preds = [chunk[\"label\"] for chunk in chunks]\n",
    "            labels.append(max(preds))\n",
    "            \n",
    "        # Merge chunk level predictions\n",
    "        predictions = []\n",
    "        for url, chunks in grouped_dataset.items():\n",
    "            preds = [chunk[\"preds\"] for chunk in chunks]\n",
    "            predictions.append(max(preds))\n",
    "    \n",
    "        # Use the trained model to make predictions on the test set\n",
    "        metrics = calc_metrics(labels, predictions)\n",
    "        print(f\"Metrics for {model_name} on {topic}: {metrics}\")\n",
    "        \n",
    "        # Update the eval_results dictionary\n",
    "        eval_results_pages[model_name][topic] = metrics\n",
    "        \n",
    "        predictions_model = np.array(predictions)\n",
    "        predictions_baseline = np.array(predictions_per_topic_baseline[topic][\"predictions\"])\n",
    "        true_labels = np.array(labels)\n",
    "\n",
    "        result = compare_models(predictions_model, predictions_baseline, true_labels)\n",
    "        print(result)\n",
    "        eval_results_significance[model_name][topic] = result\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'google-bert/bert-base-multilingual-cased': {'cannabis': {'Chi-squared value': 177.64426877470356,\n",
       "               'P-value': 1.5841283620116657e-40,\n",
       "               'Significance': True,\n",
       "               'Interpretation': 'The difference between the models is statistically significant.'},\n",
       "              'kinder': {'Chi-squared value': 92.80283337665713,\n",
       "               'P-value': 5.7772386086477775e-22,\n",
       "               'Significance': True,\n",
       "               'Interpretation': 'The difference between the models is statistically significant.'},\n",
       "              'energie': {'Chi-squared value': 335.10884105557585,\n",
       "               'P-value': 7.414816598581238e-75,\n",
       "               'Significance': True,\n",
       "               'Interpretation': 'The difference between the models is statistically significant.'}},\n",
       "             'FacebookAI/xlm-roberta-base': {'cannabis': {'Chi-squared value': 124.8904593639576,\n",
       "               'P-value': 5.378316564684772e-29,\n",
       "               'Significance': True,\n",
       "               'Interpretation': 'The difference between the models is statistically significant.'},\n",
       "              'kinder': {'Chi-squared value': 1907.2365889752127,\n",
       "               'P-value': 0.0,\n",
       "               'Significance': True,\n",
       "               'Interpretation': 'The difference between the models is statistically significant.'},\n",
       "              'energie': {'Chi-squared value': 291.70512402088775,\n",
       "               'P-value': 2.1136297615474224e-65,\n",
       "               'Significance': True,\n",
       "               'Interpretation': 'The difference between the models is statistically significant.'}},\n",
       "             'FacebookAI/xlm-roberta-large': {'cannabis': {'Chi-squared value': 139.69454545454545,\n",
       "               'P-value': 3.104631760241412e-32,\n",
       "               'Significance': True,\n",
       "               'Interpretation': 'The difference between the models is statistically significant.'},\n",
       "              'kinder': {'Chi-squared value': 341.08819875776396,\n",
       "               'P-value': 3.697271745071062e-76,\n",
       "               'Significance': True,\n",
       "               'Interpretation': 'The difference between the models is statistically significant.'},\n",
       "              'energie': {'Chi-squared value': 13.747770872737098,\n",
       "               'P-value': 0.00020906877802145257,\n",
       "               'Significance': True,\n",
       "               'Interpretation': 'The difference between the models is statistically significant.'}},\n",
       "             'dbmdz/bert-base-german-uncased': {'cannabis': {'Chi-squared value': 86.82679738562092,\n",
       "               'P-value': 1.1845360287123875e-20,\n",
       "               'Significance': True,\n",
       "               'Interpretation': 'The difference between the models is statistically significant.'},\n",
       "              'kinder': {'Chi-squared value': 402.23968675709693,\n",
       "               'P-value': 1.7921995373498607e-89,\n",
       "               'Significance': True,\n",
       "               'Interpretation': 'The difference between the models is statistically significant.'},\n",
       "              'energie': {'Chi-squared value': 3.0339004733273636,\n",
       "               'P-value': 0.08154177683785487,\n",
       "               'Significance': False,\n",
       "               'Interpretation': 'The difference between the models is not statistically significant.'}},\n",
       "             'deepset/gelectra-large': {'cannabis': {'Chi-squared value': 174.49615384615385,\n",
       "               'P-value': 7.713200274413404e-40,\n",
       "               'Significance': True,\n",
       "               'Interpretation': 'The difference between the models is statistically significant.'},\n",
       "              'kinder': {'Chi-squared value': 86.3497225448445,\n",
       "               'P-value': 1.5076968099856985e-20,\n",
       "               'Significance': True,\n",
       "               'Interpretation': 'The difference between the models is statistically significant.'},\n",
       "              'energie': {'Chi-squared value': 2772.5749486652976,\n",
       "               'P-value': 0.0,\n",
       "               'Significance': True,\n",
       "               'Interpretation': 'The difference between the models is statistically significant.'}},\n",
       "             'deepset/gelectra-base': {'cannabis': {'Chi-squared value': 10.694516971279374,\n",
       "               'P-value': 0.0010745352524984533,\n",
       "               'Significance': True,\n",
       "               'Interpretation': 'The difference between the models is statistically significant.'},\n",
       "              'kinder': {'Chi-squared value': 667.9936036036036,\n",
       "               'P-value': 2.7285893609902625e-147,\n",
       "               'Significance': True,\n",
       "               'Interpretation': 'The difference between the models is statistically significant.'},\n",
       "              'energie': {'Chi-squared value': 3.4253752084491382,\n",
       "               'P-value': 0.06420165271935481,\n",
       "               'Significance': False,\n",
       "               'Interpretation': 'The difference between the models is not statistically significant.'}},\n",
       "             'deepset/gbert-large': {'cannabis': {'Chi-squared value': 169.30620155038758,\n",
       "               'P-value': 1.0488195193611374e-38,\n",
       "               'Significance': True,\n",
       "               'Interpretation': 'The difference between the models is statistically significant.'},\n",
       "              'kinder': {'Chi-squared value': 184.3984427439925,\n",
       "               'P-value': 5.310363761280684e-42,\n",
       "               'Significance': True,\n",
       "               'Interpretation': 'The difference between the models is statistically significant.'},\n",
       "              'energie': {'Chi-squared value': 73.52531464530892,\n",
       "               'P-value': 9.935373509181449e-18,\n",
       "               'Significance': True,\n",
       "               'Interpretation': 'The difference between the models is statistically significant.'}},\n",
       "             'deepset/gbert-base': {'cannabis': {'Chi-squared value': 150.9433962264151,\n",
       "               'P-value': 1.0783504830038695e-34,\n",
       "               'Significance': True,\n",
       "               'Interpretation': 'The difference between the models is statistically significant.'},\n",
       "              'kinder': {'Chi-squared value': 1.4594882729211087,\n",
       "               'P-value': 0.22701155942299367,\n",
       "               'Significance': False,\n",
       "               'Interpretation': 'The difference between the models is not statistically significant.'},\n",
       "              'energie': {'Chi-squared value': 103.80499561787906,\n",
       "               'P-value': 2.232415660573675e-24,\n",
       "               'Significance': True,\n",
       "               'Interpretation': 'The difference between the models is statistically significant.'}}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results_significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>Model                                   </th><th style=\"text-align: right;\">  cannabis P-value</th><th style=\"text-align: right;\">  cannabis Significance</th><th style=\"text-align: right;\">  kinder P-value</th><th style=\"text-align: right;\">  kinder Significance</th><th style=\"text-align: right;\">  energie P-value</th><th style=\"text-align: right;\">  energie Significance</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>google-bert/bert-base-multilingual-cased</td><td style=\"text-align: right;\">       1.58413e-40</td><td style=\"text-align: right;\">                      1</td><td style=\"text-align: right;\">    5.77724e-22 </td><td style=\"text-align: right;\">                    1</td><td style=\"text-align: right;\">      7.41482e-75</td><td style=\"text-align: right;\">                     1</td></tr>\n",
       "<tr><td>FacebookAI/xlm-roberta-base             </td><td style=\"text-align: right;\">       5.37832e-29</td><td style=\"text-align: right;\">                      1</td><td style=\"text-align: right;\">    0           </td><td style=\"text-align: right;\">                    1</td><td style=\"text-align: right;\">      2.11363e-65</td><td style=\"text-align: right;\">                     1</td></tr>\n",
       "<tr><td>FacebookAI/xlm-roberta-large            </td><td style=\"text-align: right;\">       3.10463e-32</td><td style=\"text-align: right;\">                      1</td><td style=\"text-align: right;\">    3.69727e-76 </td><td style=\"text-align: right;\">                    1</td><td style=\"text-align: right;\">      0.000209069</td><td style=\"text-align: right;\">                     1</td></tr>\n",
       "<tr><td>dbmdz/bert-base-german-uncased          </td><td style=\"text-align: right;\">       1.18454e-20</td><td style=\"text-align: right;\">                      1</td><td style=\"text-align: right;\">    1.7922e-89  </td><td style=\"text-align: right;\">                    1</td><td style=\"text-align: right;\">      0.0815418  </td><td style=\"text-align: right;\">                     0</td></tr>\n",
       "<tr><td>deepset/gelectra-large                  </td><td style=\"text-align: right;\">       7.7132e-40 </td><td style=\"text-align: right;\">                      1</td><td style=\"text-align: right;\">    1.5077e-20  </td><td style=\"text-align: right;\">                    1</td><td style=\"text-align: right;\">      0          </td><td style=\"text-align: right;\">                     1</td></tr>\n",
       "<tr><td>deepset/gelectra-base                   </td><td style=\"text-align: right;\">       0.00107454 </td><td style=\"text-align: right;\">                      1</td><td style=\"text-align: right;\">    2.72859e-147</td><td style=\"text-align: right;\">                    1</td><td style=\"text-align: right;\">      0.0642017  </td><td style=\"text-align: right;\">                     0</td></tr>\n",
       "<tr><td>deepset/gbert-large                     </td><td style=\"text-align: right;\">       1.04882e-38</td><td style=\"text-align: right;\">                      1</td><td style=\"text-align: right;\">    5.31036e-42 </td><td style=\"text-align: right;\">                    1</td><td style=\"text-align: right;\">      9.93537e-18</td><td style=\"text-align: right;\">                     1</td></tr>\n",
       "<tr><td>deepset/gbert-base                      </td><td style=\"text-align: right;\">       1.07835e-34</td><td style=\"text-align: right;\">                      1</td><td style=\"text-align: right;\">    0.227012    </td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">      2.23242e-24</td><td style=\"text-align: right;\">                     1</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "'<table>\\n<thead>\\n<tr><th>Model                                   </th><th style=\"text-align: right;\">  cannabis P-value</th><th style=\"text-align: right;\">  cannabis Significance</th><th style=\"text-align: right;\">  kinder P-value</th><th style=\"text-align: right;\">  kinder Significance</th><th style=\"text-align: right;\">  energie P-value</th><th style=\"text-align: right;\">  energie Significance</th></tr>\\n</thead>\\n<tbody>\\n<tr><td>google-bert/bert-base-multilingual-cased</td><td style=\"text-align: right;\">       1.58413e-40</td><td style=\"text-align: right;\">                      1</td><td style=\"text-align: right;\">    5.77724e-22 </td><td style=\"text-align: right;\">                    1</td><td style=\"text-align: right;\">      7.41482e-75</td><td style=\"text-align: right;\">                     1</td></tr>\\n<tr><td>FacebookAI/xlm-roberta-base             </td><td style=\"text-align: right;\">       5.37832e-29</td><td style=\"text-align: right;\">                      1</td><td style=\"text-align: right;\">    0           </td><td style=\"text-align: right;\">                    1</td><td style=\"text-align: right;\">      2.11363e-65</td><td style=\"text-align: right;\">                     1</td></tr>\\n<tr><td>FacebookAI/xlm-roberta-large            </td><td style=\"text-align: right;\">       3.10463e-32</td><td style=\"text-align: right;\">                      1</td><td style=\"text-align: right;\">    3.69727e-76 </td><td style=\"text-align: right;\">                    1</td><td style=\"text-align: right;\">      0.000209069</td><td style=\"text-align: right;\">                     1</td></tr>\\n<tr><td>dbmdz/bert-base-german-uncased          </td><td style=\"text-align: right;\">       1.18454e-20</td><td style=\"text-align: right;\">                      1</td><td style=\"text-align: right;\">    1.7922e-89  </td><td style=\"text-align: right;\">                    1</td><td style=\"text-align: right;\">      0.0815418  </td><td style=\"text-align: right;\">                     0</td></tr>\\n<tr><td>deepset/gelectra-large                  </td><td style=\"text-align: right;\">       7.7132e-40 </td><td style=\"text-align: right;\">                      1</td><td style=\"text-align: right;\">    1.5077e-20  </td><td style=\"text-align: right;\">                    1</td><td style=\"text-align: right;\">      0          </td><td style=\"text-align: right;\">                     1</td></tr>\\n<tr><td>deepset/gelectra-base                   </td><td style=\"text-align: right;\">       0.00107454 </td><td style=\"text-align: right;\">                      1</td><td style=\"text-align: right;\">    2.72859e-147</td><td style=\"text-align: right;\">                    1</td><td style=\"text-align: right;\">      0.0642017  </td><td style=\"text-align: right;\">                     0</td></tr>\\n<tr><td>deepset/gbert-large                     </td><td style=\"text-align: right;\">       1.04882e-38</td><td style=\"text-align: right;\">                      1</td><td style=\"text-align: right;\">    5.31036e-42 </td><td style=\"text-align: right;\">                    1</td><td style=\"text-align: right;\">      9.93537e-18</td><td style=\"text-align: right;\">                     1</td></tr>\\n<tr><td>deepset/gbert-base                      </td><td style=\"text-align: right;\">       1.07835e-34</td><td style=\"text-align: right;\">                      1</td><td style=\"text-align: right;\">    0.227012    </td><td style=\"text-align: right;\">                    0</td><td style=\"text-align: right;\">      2.23242e-24</td><td style=\"text-align: right;\">                     1</td></tr>\\n</tbody>\\n</table>'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "# Identify all topics (assuming all models are evaluated on the same topics)\n",
    "topics = list(next(iter(eval_results_significance.values())).keys())\n",
    "\n",
    "# Prepare headers for the table: each topic will have two metrics\n",
    "headers = [\"Model\"] + [f\"{topic} {metric}\" for topic in topics for metric in [\"P-value\", \"Significance\"]]\n",
    "\n",
    "# Prepare rows: one row per model, containing metrics for each topic\n",
    "rows = []\n",
    "for model, topics_metrics in eval_results_significance.items():\n",
    "    row = [model]  # Start with the model name\n",
    "    for topic in topics:\n",
    "        metrics = topics_metrics.get(topic, {})\n",
    "        row.extend([metrics.get('P-value', 0.0), metrics.get('Significance', False)])\n",
    "    rows.append(row)\n",
    "\n",
    "# Generate the HTML table\n",
    "table_html = tabulate(rows, headers=headers, tablefmt=\"html\", showindex=\"never\")\n",
    "\n",
    "# Print the HTML table (for display purposes, you might want to actually render this in an HTML document)\n",
    "display(table_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path to save the dictionary\n",
    "file_path = f\"eval_results_{FEATURES}_{SPLIT}_pages_significance.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "def convert_numpy_types(obj):\n",
    "    \"\"\"Convert numpy types to native Python types.\"\"\"\n",
    "    if isinstance(obj, np.integer):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, np.floating):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, np.bool_):\n",
    "        return bool(obj)\n",
    "    elif isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: convert_numpy_types(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [convert_numpy_types(i) for i in obj]\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "# Convert the entire dictionary\n",
    "eval_results_significance = convert_numpy_types(eval_results_significance)\n",
    "\n",
    "with open(file_path, \"w\") as file:\n",
    "    json.dump(eval_results_significance, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s2j-content-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
