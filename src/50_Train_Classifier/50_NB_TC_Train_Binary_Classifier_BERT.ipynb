{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Classifier: BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"energie\" #\"energie\" #\"kinder\" \"cannabis\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(f\"../../data/tmp/processed_dataset_{topic}_buffed_chunkified_random_384\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_holdout = load_from_disk(f\"../../data/tmp/processed_dataset_{topic}_buffed_chunkified_random_holdout\")\n",
    "\n",
    "# #Shuffle the dataset\n",
    "# dataset_holdout = dataset_holdout.shuffle(seed=42)\n",
    "\n",
    "# #Sample 6_000 random examples\n",
    "# num_samples = 5_000\n",
    "# dataset_holdout = dataset_holdout.select(range(num_samples))\n",
    "\n",
    "# from datasets import concatenate_datasets\n",
    "# dataset[\"train\"] = concatenate_datasets([dataset[\"train\"], dataset_holdout])\n",
    "# dataset[\"train\"] = dataset[\"train\"].shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 100 random indices from the training dataset\n",
    "#random_indices = random.sample(range(len(dataset['train'])), 100)\n",
    "\n",
    "# Select 100 examples from the training dataset\n",
    "#dataset['train'] = dataset['train'].select(random_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'chunk_id'],\n",
      "        num_rows: 3398\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'chunk_id'],\n",
      "        num_rows: 478\n",
      "    })\n",
      "})\n",
      "{'_id': '64a0946d749484eec855d4bb', 'batch_id': 16, 'domain': 't-online.de', 'view_url': 'email.t-online.de/em#f=INBOX&m=15411876806784410&method=showReadmail', 'lang': 'de', 'text': '. Bundesliga Zweikampf der Woche Fußball Champions League FC Bayern Newsticker Formel 1 Was macht …', 'text_length': 99, 'word_count': 16, 'topic': 'energie', 'category': 'other', 'good_for_training': 'True', 'good_for_augmentation': 'True', 'annotation_type': '06.news-wo-title', 'is_topic': False, 'label': 0, 'token_count': 21, 'chunk_id': 1}\n"
     ]
    }
   ],
   "source": [
    "# Explore the dataset\n",
    "print(dataset)\n",
    "print(dataset['train'][1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"deepset/gbert-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/478 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 478/478 [00:00<00:00, 2569.41 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-large and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained model for sequence classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\"accuracy\": accuracy_score(p.label_ids, preds)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,             # number of training epochs\n",
    "    weight_decay=0.01,  # Weight decay if we apply some form of weight regularization.\n",
    "    logging_dir='./logs',  # Directory where the training logs will be stored.\n",
    "    logging_strategy=\"steps\",  # The logging strategy determines when to log\n",
    "    logging_steps=100,  # Number of steps between logging of training loss.\n",
    "    evaluation_strategy=\"steps\",  # Evaluation is done\n",
    "    eval_steps=100,  # Number of steps between evaluations.\n",
    "    load_best_model_at_end=True,  # load the best model at the end of training.\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    lr_scheduler_type='linear',  # The scheduler type to use, e.g., 'linear', 'cosine'\n",
    "    warmup_ratio=0.1  # Proportion of training to perform linear learning rate warmup for.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([1.0241, 0.9770])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Calculate class weights inversely proportional to class frequencies\n",
    "labels = tokenized_datasets[\"train\"]['label']\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(labels), y=labels)\n",
    "\n",
    "# Convert class weights to a tensor\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float)\n",
    "print(\"Class weights:\", class_weights_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        # compute custom loss\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "# Create a Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2125 41:50 < 02:37, 0.80 it/s, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.525700</td>\n",
       "      <td>0.349846</td>\n",
       "      <td>0.853556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.304700</td>\n",
       "      <td>0.111291</td>\n",
       "      <td>0.970711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.267200</td>\n",
       "      <td>0.096688</td>\n",
       "      <td>0.972803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.279700</td>\n",
       "      <td>0.197961</td>\n",
       "      <td>0.945607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.199800</td>\n",
       "      <td>0.137178</td>\n",
       "      <td>0.972803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.152100</td>\n",
       "      <td>0.101087</td>\n",
       "      <td>0.983264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.173300</td>\n",
       "      <td>0.145805</td>\n",
       "      <td>0.976987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.177200</td>\n",
       "      <td>0.076826</td>\n",
       "      <td>0.981172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.123900</td>\n",
       "      <td>0.100465</td>\n",
       "      <td>0.976987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.162827</td>\n",
       "      <td>0.966527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.099786</td>\n",
       "      <td>0.983264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.077200</td>\n",
       "      <td>0.105079</td>\n",
       "      <td>0.983264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.051900</td>\n",
       "      <td>0.108163</td>\n",
       "      <td>0.981172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.054500</td>\n",
       "      <td>0.116677</td>\n",
       "      <td>0.979079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.083713</td>\n",
       "      <td>0.983264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.097327</td>\n",
       "      <td>0.985356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>0.086281</td>\n",
       "      <td>0.983264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.047100</td>\n",
       "      <td>0.084004</td>\n",
       "      <td>0.985356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.108135</td>\n",
       "      <td>0.981172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.120117</td>\n",
       "      <td>0.981172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2000, training_loss=0.13974343490600585, metrics={'train_runtime': 2513.3506, 'train_samples_per_second': 6.76, 'train_steps_per_second': 0.845, 'total_flos': 1.4903446362341376e+16, 'train_loss': 0.13974343490600585, 'epoch': 4.71})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'chunk_id', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3398\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'chunk_id', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 478\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41/60 00:14 < 00:07, 2.68 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.08371259272098541,\n",
       " 'eval_accuracy': 0.9832635983263598,\n",
       " 'eval_runtime': 22.3278,\n",
       " 'eval_samples_per_second': 21.408,\n",
       " 'eval_steps_per_second': 2.687,\n",
       " 'epoch': 4.71}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "trainer.evaluate(tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/bert_energie_model_buff/tokenizer_config.json',\n",
       " '../models/bert_energie_model_buff/special_tokens_map.json',\n",
       " '../models/bert_energie_model_buff/vocab.txt',\n",
       " '../models/bert_energie_model_buff/added_tokens.json',\n",
       " '../models/bert_energie_model_buff/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locsl_path = \"../models/bert_\" + topic + \"_model_buff\"\n",
    "trainer.save_model(locsl_path)\n",
    "tokenizer.save_pretrained(locsl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[CLS]. Folge 3 : Dämonen in Amsterdam ( S03 / E03 ) Kommissar Van der Valk [UNK] Das Erste UT 89 Min. Folge 3 : Dämonen in Amsterdam ( S03 / E03 ) - Hörfassung Kommissar Van der Valk [UNK] Das Erste UT AD 89 Min. Folge 3 : Magic in Amsterdam ( S03 / E03 ) ( OV ) Kommissar Van der Valk [UNK] Das Erste OV 89 Min. Folge 2 : Erlösung in Amsterdam ( S03 / E02 ) Kommissar Van der Valk [UNK] Das Erste UT 89 Min. Folge 2 : Erlösung in Amsterdam ( S03 / E02 ) - Hörfassung Kommissar Van der Valk [UNK] Das Erste UT AD 89 Min. Folge 2 : Redemption in Amsterdam ( S03 / E02 ) ( OV ) Kommissar Van der Valk [UNK] Das Erste OV 89 Min. Folge 1 : Freiheit in Amsterdam ( S03 / E01 ) Kommissar Van der Valk [UNK] Das Erste UT 89 Min. Folge 1 : Freiheit in Amsterdam ( S03 / E01 ) - Hörfassung Kommissar Van der Valk [UNK] Das Erste UT AD 89 Min. Folge 1 : Freedom in Amsterdam ( S03 / E01 ) ( OV ) Kommissar Van der Valk [UNK] Das Erste OV 89 Min. Folge 2 : Only in Amsterdam ( S01 / E02 ) ( OV ) Kommissar Van der Valk [UNK] Das Erste OV 90 Min. Folge 3 : Death in Amsterdam ( S01 / E03 ) ( OV ) Kommissar Van der Valk [UNK] Das Erste OV 90 Min [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "id = 1\n",
    "input_ids = tokenized_datasets[\"test\"][id][\"input_ids\"]\n",
    "label = tokenized_datasets[\"test\"][id][\"label\"]\n",
    "print(label)\n",
    "print(tokenizer.decode(input_ids))\n",
    "#print(input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.8294, -4.5701]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = model(input_ids = torch.tensor([input_ids], device='cuda')) \n",
    "print(output.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "probabilities = torch.nn.functional.softmax(output.logits, dim=1)\n",
    "predicted_class = torch.argmax(probabilities, dim=1)\n",
    "print(predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constructed Positive Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Your test example\n",
    "test_example = \"\"\"\n",
    "Verständnis zur Legalisierung von Cannabis\n",
    "\n",
    "Die Legalisierung von Cannabis, auch bekannt als Marihuana, ist ein Thema bedeutender Debatten und politischer Veränderungen in verschiedenen Ländern weltweit. Die Bewegung hin zur Legalisierung repräsentiert einen Wandel in der Wahrnehmung und Regulierung von Cannabis, von einer streng kontrollierten Substanz hin zu einer liberaler regulierten, oft sowohl für medizinische als auch für Freizeitzwecke.\n",
    "\n",
    "Historischer Kontext: Traditionell war Cannabis in den meisten Teilen der Welt illegal, klassifiziert neben vielen anderen kontrollierten Substanzen. Diese Klassifizierung erfolgte hauptsächlich aufgrund von Bedenken hinsichtlich seines Potenzials für Missbrauch, seiner psychoaktiven Effekte und möglicher Gesundheitsrisiken.\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize the text\n",
    "inputs = tokenizer(test_example, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Predict the class\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs.to('cuda'))    \n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "# Get the predicted class (the one with the highest probability)\n",
    "predicted_class = torch.argmax(predictions).item()\n",
    "\n",
    "# Print the predicted class\n",
    "print(\"Predicted class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Constructed Negative Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Your test example\n",
    "test_example = \"\"\"\n",
    "Die Faszination Süßer Katzen\n",
    "\n",
    "Katzen sind faszinierende und unglaublich beliebte Haustiere. Ihre Anmut, Unabhängigkeit und das spielerische Wesen machen sie zu einem Liebling vieler Menschen. Besonders süße Katzen haben eine besondere Anziehungskraft, die das Herz vieler Tierliebhaber erobert.\n",
    "\n",
    "Eleganz und Anmut: Katzen sind bekannt für ihre elegante und anmutige Art. Mit ihren geschmeidigen Bewegungen und dem majestätischen Gang ziehen sie die Aufmerksamkeit auf sich. Ihre Fähigkeit, sich leise und behände zu bewegen, verleiht ihnen eine fast mystische Aura.\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize the text\n",
    "inputs = tokenizer(test_example, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Predict the class\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs.to('cuda'))    \n",
    "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "# Get the predicted class (the one with the highest probability)\n",
    "predicted_class = torch.argmax(predictions).item()\n",
    "\n",
    "# Print the predicted class\n",
    "print(\"Predicted class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'token_count', 'chunk_id', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 478\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy on the test dataset \n",
    "preds = []\n",
    "labels = []\n",
    "for row in tokenized_datasets[\"test\"]:\n",
    "    inputs = tokenizer(row[\"text\"], return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs.to('cuda'))    \n",
    "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        predicted_class = torch.argmax(predictions).item()\n",
    "    \n",
    "    preds.append(predicted_class)\n",
    "    labels.append(row[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.33%\n",
      "Precision: 1.00\n",
      "Recall: 0.98\n",
      "F1 Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Assuming labels and preds are lists or arrays containing the true labels and predicted labels respectively\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "precision = precision_score(labels, preds)\n",
    "recall = recall_score(labels, preds)\n",
    "f1 = f1_score(labels, preds)\n",
    "\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "print(\"Precision: {:.2f}\".format(precision))\n",
    "print(\"Recall: {:.2f}\".format(recall))\n",
    "print(\"F1 Score: {:.2f}\".format(f1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: 94.92%\n",
    "Precision: 0.93\n",
    "Recall: 0.97\n",
    "F1 Score: 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming labels and preds are lists or arrays containing the true labels and predicted labels respectively\n",
    "cm = confusion_matrix(labels, preds)\n",
    "\n",
    "# Create a seaborn heatmap with annotations\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Oranges\", cbar=True)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Predicted labels\")\n",
    "plt.ylabel(\"True labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". Ausgehend von einem Mindestlohn von 12 Euro je Arbeitsstunde im Jahr 2023 beträgt die monatliche Entgeltgrenze 520 Euro. Die maximal zulässige Anzahl von Arbeitsstunden bei 520-Euro-Minijobbern liegt dauerhaft bei 43 Stunden pro Monat. Mindest-Ausbildungsvergütung steigt Für im Jahr 2023 begonnene Ausbildungsverhältnisse beträgt die monatliche Mindestausbildungsvergütung im ersten Jahr einer Berufsausbildung 620 Euro (2022: 585 Euro). Im zweiten und dritten Ausbildungsjahr steigt sie auf 732 Euro (2022: 690 Euro) bzw. 837 Euro (2022: 790 Euro) an. Höhere Ansätze für Unterkunft und Verpflegung Die Sachbezugswerte für Unterkunft und Verpflegung steigen. Der Gesamtsachbezugswert für Verpflegung wird von bisher 270 Euro auf 288 Euro im Monat erhöht. Er setzt sich zusammen aus 60 Euro für Frühstück sowie jeweils 114 Euro für Mittag- und Abendessen. Die Werte für eine Unterkunft (belegt mit einem Beschäftigten) steigen zum neuen Jahr ebenfalls von derzeit monatlich 241 Euro auf 265 Euro, bei Aufnahme in den Arbeitgeberhaushalt von 204,85 Euro auf 225,25 Euro. Höhere Beiträge zur gesetzlichen Sozialversicherung Der durchschnittliche Zusatzbeitrag in der gesetzlichen Krankenversicherung steigt von 1,3 auf 1,6 Prozent. Viele gesetzliche Krankenkassen werden ihre Zusatzbeiträge, die hälftig von Arbeitgeber und Arbeitnehmer zu tragen sind, mindestens in diesem Umfang erhöhen müssen. Der Beitragssatz zur Arbeitslosenversicherung, der ab dem Jahr 2020 aufgrund hoher Rücklagen der Bundesagentur für Arbeit befristet bis 31. Dezember 2022 auf 2,4 Prozent abgesenkt war, liegt ab 1\n",
      "True label: 1\n",
      "Predicted label: 0\n",
      "\n",
      ". Liga Motorsport Fußball-WM Olympia Großbritannien Blitzmeldung Spanien Kultur/Medien Leute Musik Fernsehen Kino Literatur Gesellschaft Großbritannien Bühne Kunst Gesundheit Gemischtes Gesundheit Unglücke Gesellschaft Polizeimeldung Kriminalität Leute Straßenverkehr Justiz Glücksspiel Lotto Wetter Jetzt kostenlos registrieren ! Verpassen Sie keine aktuellen Neuigkeiten mehr, registrieren Sie sich kostenlos zu unseren Diensten. Jetzt registrieren News & Nachrichten Wirtschaft Politik Sport Kultur & Medien Gemischtes Interessante Artikel SPD-Chefs fordern Freigabe von Cannabis US-Börsen treten auf der Stelle - Euro deutlich stärker Reisebranche verlangt finanziellen Ausgleich für Flugchaos Schwesig mahnt Grundgesetzänderung für Digitalpakt an Habeck nennt Bierhoff-Kritik an Özil \"bigott\" Erste deutsche Batteriezellenfabrik könnte nach NRW kommen SPD-Fraktionsvize zeigt sich empört über Autokonzerne DAX im Feiertagshandel schwach - Lufthansa sehr gefragt Emnid-Umfrage: Deutsche vertrauen Macron mehr als Merkel BAMF: Syrer erhalten geringeren Schutzstatus Soziale Medien Weitere Seiten Reise-und-Urlaubsziele.de Aktuelle-Auto-News.de Freizeit-Haus-und-Garten.de © 2023 | V&s=e | news-und-nachrichten.de Impressum Datenschutz AGB Kontakt\n",
      "True label: 0\n",
      "Predicted label: 1\n",
      "\n",
      ". Die Zertifizierung wurde im Bereich Zufriedenheit Ã¼ber den gesamten Prozess anhand besonders strenger Kriterien geprÃ¼ft. Das Zertifikat basiert auf einer reprÃ¤sentativen Kundenzufriedenheitsanalyse. Weitere Informationen erhalten Sie HIER . Zur Auszeichnung Die Nr. 1 inÂ Deutschland Die Financial Times und Statista haben Enpal aus 1.000 fÃ¼hrenden Unternehmen in Europa als das wachstumsstÃ¤rkste Unternehmen in Deutschland gekÃ¼rt. In der Energiebranche nimmt Enpal sogar europaweit den ersten Platz ein. Mehr Informationen finden Sie HIER . Zum Preis FOCUSÂ Wachstumschampion 2023 Aus Ã¼ber 12.000 Kandidaten haben FOCUS und Statista Enpal in der Kategorie \"Energie und Versorger\" als Wachstumschampion ausgezeichnet. Mehr Informationen dazu finden Sie HIER . FÃ¼r mehr Infos klicken Sie hier Zum Zertifikat TÃV geprÃ¼fte Kundenzufriedenheit: Gut Enpals Kundenzufriedenheit ist mit Note \"Gut\" durch den TÃV Saarland zertifiziert (SC45293). Die Zertifizierung wurde im Bereich Zufriedenheit Ã¼ber den gesamten Prozess anhand besonders strenger Kriterien geprÃ¼ft. Das Zertifikat basiert auf einer reprÃ¤sentativen Kundenzufriedenheitsanalyse. Weitere Informationen erhalten Sie HIER . Zum Preis WachstumsstÃ¤rkstes Unternehmen Deutschlands 2022 Die Financial Times und Statista haben Enpal als das wachstumsstÃ¤rkste Unternehmen in Deutschland gekÃ¼rt. Mehr Informationen dazu finden Sie hier . Zum Preis FOCUSÂ Wachstumschampion 2023 Aus Ã¼ber 12\n",
      "True label: 1\n",
      "Predicted label: 0\n",
      "\n",
      "Amrumbank West geht ab 2025 an 12 Großkunden Previous Next 1 2 RWE Supply & Trading schließt Stromlieferverträge ( Power Purchase Agreements, PPA ) über rund 1\n",
      "True label: 1\n",
      "Predicted label: 0\n",
      "\n",
      "Wetter DAX Telefonverzeichnisse Lotto Telekom Services Telekom Hilfe & Service Frag Magenta Kundencenter Freemail MagentaCloud Tarife & Produkte PUR-Abo Login Suchen E-Mail Login Politik Deutschland Ausland Corona-Krise Tagesanbruch Ukraine Regional Berlin Hamburg München Köln Frankfurt Alle Städte Sport Bundesliga 2\n",
      "True label: 1\n",
      "Predicted label: 0\n",
      "\n",
      ".. Loading... Shopping Anzeigen Loading... Loading... Loading... Loading... Loading... Loading... Loading... Loading... Loading... Loading... Loading... Loading..\n",
      "True label: 1\n",
      "Predicted label: 0\n",
      "\n",
      "... Loading... Loading... Loading... Neueste Artikel Interview | Ministerpräsident über Ampel-Politik \"Da kommt kein Mensch mehr mit\" Von Tim Kummert \"Natürlich nicht vorher gewusst\" Prigoschin-Aufstand: Kritik an BND wächst Haushaltsstreit im Kabinett Der Unerbittliche trifft die Felsenfeste Von Tim Kummert Streit über K-Frage in der Union Es sieht nicht gut aus für Friedrich Merz Demokratie-Check für Robert Sesselmann Darum geht es bei der Überprüfung des AfD-Landrates Thierse und sein erster Besuch im Westen \"Es roch vollkommen anders als auf DDR-Bahnhöfen\" \"Sie sind rechts\" Sender setzt Merz mit Höcke gleich – scharfe Kritik Scholz bei \"Maischberger\" \"Wir kriegen das hin\" Von Markus Brandstetter Kommt es noch vor der Sommerpause? Koalition erzielt Durchbruch beim Heizungsgesetz Kirchenaustritte auf neuem Höchststand Katholische Kirche verliert 2022 mehr als 500.000 Mitglieder Themen Bundestag Bündnis 90/Die Grünen CDU FDP Robert Habeck Twitter Themen A bis Z Politiker Annalena Baerbock Karl Lauterbach Markus Söder Olaf Scholz t-online folgen Das Unternehmen Ströer Digital Publishing Jobs & Karriere Presse Werben Kontakt Impressum Datenschutzhinweise Datenschutzhinweise (PUR) Datenschutz-Manager Jugendschutz Produkte & Services T-Online-Browser PUR-Abo Newsletter Podcasts Videos RSS-Feeds Alle Themen Netzwerk & Partner Das Telefonbuch watson.de giga.de desired.de kino\n",
      "True label: 1\n",
      "Predicted label: 0\n",
      "\n",
      ".de giga.de desired.de kino.de spieletipps.de familie.de statista.de stayfriends.de Telekom Telekom Produkte & Services Kundencenter Freemail Sicherheitspaket Vertragsverlängerung Festnetz Vertragsverlängerung Mobilfunk Hilfe & Service Frag Magenta Telekom Tarife DSL Telefonieren MagentaTV Mobilfunk-Tarife Datentarife Prepaid-Tarife Magenta EINS\n",
      "True label: 1\n",
      "Predicted label: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show some misclassified examples\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] != preds[i]:\n",
    "        print(tokenized_datasets[\"test\"][i][\"text\"])\n",
    "        print(\"True label:\", labels[i])\n",
    "        print(\"Predicted label:\", preds[i])\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s2j-content-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
