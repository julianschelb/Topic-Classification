{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Multiclass Classifier: BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jschelb/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForMaskedLM, TrainingArguments, Trainer\n",
    "from datasets import Dataset, load_dataset, load_from_disk, concatenate_datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\"cannabis\", \"energie\", \"kinder\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Map class-names to class-ids:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_class = {0: \"other\",1: \"cannabis\", 2: \"energie\", 3: \"kinder\"}\n",
    "class_to_id = {\"other\": 0, \"cannabis\": 1, \"energie\": 2, \"kinder\": 3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load dataset for each topic:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cannabis = load_from_disk(f\"../data/tmp/processed_dataset_cannabis_buffed_filtered\")\n",
    "dataset_energie = load_from_disk(f\"../data/tmp/processed_dataset_energie_buffed_filtered\")\n",
    "dataset_kinder = load_from_disk(f\"../data/tmp/processed_dataset_kinder_buffed_filtered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update dataset schema and class-label mappings:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ClassLabel, Features, Value, DatasetDict, concatenate_datasets, load_dataset\n",
    "import datasets\n",
    "\n",
    "# Define the new class label feature\n",
    "class_labels = ClassLabel(names=[\"other\", \"cannabis\", \"energie\", \"kinder\"])\n",
    "\n",
    "# Define the new features, including all existing ones plus the updated 'label'\n",
    "new_features = datasets.Features({\n",
    "    '_id': datasets.Value('string'),\n",
    "    'batch_id': datasets.Value('int64'),\n",
    "    'domain': datasets.Value('string'),\n",
    "    'view_url': datasets.Value('string'),\n",
    "    'lang': datasets.Value('string'),\n",
    "    'text': datasets.Value('string'),\n",
    "    'text_length': datasets.Value('int64'),\n",
    "    'word_count': datasets.Value('int64'),\n",
    "    'token_count': datasets.Value('int64'),\n",
    "    'topic': datasets.Value('string'),\n",
    "    'category': datasets.Value('string'),\n",
    "    'good_for_training': datasets.Value('string'),\n",
    "    'good_for_augmentation': datasets.Value('string'),\n",
    "    'annotation_type': datasets.Value('string'),\n",
    "    'is_topic': datasets.Value('int64'),\n",
    "    'label': class_labels # Updated ClassLabel feature\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cannabis = dataset_cannabis.map(lambda e: {'label': class_to_id['cannabis'] if e[\"label\"] == 1 else class_to_id['other']}, features=new_features)\n",
    "\n",
    "dataset_energie = dataset_energie.map(lambda e: {'label': class_to_id['energie'] if e[\"label\"] == 1 else class_to_id['other']}, features=new_features)\n",
    "\n",
    "dataset_kinder = dataset_kinder.map(lambda e: {'label': class_to_id['kinder'] if e[\"label\"] == 1 else class_to_id['other']}, features=new_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merge the three datasets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all datasets\n",
    "dataset_all_topics = concatenate_datasets([dataset_cannabis, dataset_energie, dataset_kinder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'token_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label'],\n",
       "    num_rows: 281303\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_all_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '999999',\n",
       " 'batch_id': 16,\n",
       " 'domain': '',\n",
       " 'view_url': 'mingle.respondi.de/',\n",
       " 'lang': '',\n",
       " 'text': '',\n",
       " 'text_length': 0,\n",
       " 'word_count': 0,\n",
       " 'token_count': 2,\n",
       " 'topic': 'cannabis',\n",
       " 'category': 'other',\n",
       " 'good_for_training': 'False',\n",
       " 'good_for_augmentation': 'True',\n",
       " 'annotation_type': 'domain_discarded',\n",
       " 'is_topic': 0,\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_all_topics[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter out annotations not good for training:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_all_topics_test = dataset_all_topics.filter(lambda example: example['good_for_training'] == \"False\")\n",
    "\n",
    "dataset_all_topics = dataset_all_topics.filter(lambda example: example['good_for_training'] == \"True\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separate negative and positive examples:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter positive and negative examples\n",
    "dataset_all_topics_pos = dataset_all_topics.filter(lambda example: example['label'] > 0, num_proc=16)\n",
    "dataset_all_topics_neg = dataset_all_topics.filter(lambda example: example['label'] == 0, num_proc=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get examples which are negative for all topics:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all view_url values from dataset_all_topics_pos\n",
    "pos_view_urls = set(dataset_all_topics_pos['view_url'])\n",
    "\n",
    "# Filter dataset_all_topics_neg to exclude any rows present in dataset_all_topics_pos\n",
    "dataset_all_topics_neg = dataset_all_topics_neg.filter(lambda example: example['view_url'] not in pos_view_urls, num_proc=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'token_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label'],\n",
       "    num_rows: 14489\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_all_topics_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deduplicate negative examples:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_urls = set()\n",
    "\n",
    "dataset_all_topics_neg = dataset_all_topics_neg.filter(lambda example: example['view_url'] not in seen_urls and not seen_urls.add(example['view_url']), num_proc=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversample Positive Exmaples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at FacebookAI/xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForMaskedLM.from_pretrained(MODEL_NAME).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2 GPUs!\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomly_replace_tokens(text, tokenizer, model, mask_probability=0.15):\n",
    "    \"\"\"Elegantly replace tokens one by one, each with full context.\"\"\"\n",
    "\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', add_special_tokens=True)\n",
    "    input_ids = inputs.input_ids.clone()\n",
    "    attention_mask = inputs.attention_mask\n",
    "\n",
    "    # Identify non-special tokens for potential masking\n",
    "    non_special_token_indices = [i for i, token_id in enumerate(input_ids[0])\n",
    "                                 if token_id not in (tokenizer.cls_token_id, tokenizer.sep_token_id, tokenizer.pad_token_id)]\n",
    "    \n",
    "    # Randomly select tokens for masking\n",
    "    num_tokens_to_mask = int(len(non_special_token_indices) * mask_probability)\n",
    "    tokens_to_mask = np.random.choice(non_special_token_indices, size=num_tokens_to_mask, replace=False)\n",
    "\n",
    "    for i in tokens_to_mask:\n",
    "        original_token_id = input_ids[0, i].item()  # Save the original token ID\n",
    "        masked_input_ids = input_ids.detach().clone()\n",
    "        masked_input_ids[0, i] = tokenizer.mask_token_id  # Mask the token\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(masked_input_ids, attention_mask=attention_mask)\n",
    "\n",
    "        predictions = outputs.logits[0, i]\n",
    "        predictions[original_token_id] = -float('Inf')  # Invalidate the original token\n",
    "        best_pred_idx = predictions.argmax(dim=-1).item()\n",
    "        input_ids[0, i] = best_pred_idx  # Replace with the best prediction\n",
    "\n",
    "    replaced_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "    return replaced_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: Das hier ist ein Test.\n",
      "Replaced text: Und hier ist ein Testbericht\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "text = \"Das hier ist ein Test.\"\n",
    "replaced_text = randomly_replace_tokens(text, tokenizer, model, mask_probability=0.35)\n",
    "print(\"Original text:\", text)\n",
    "print(\"Replaced text:\", replaced_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets, Dataset\n",
    "\n",
    "def oversample(dataset, label_column, tokenizer, model, mask_probability=0.35):\n",
    "    \"\"\"Oversample minority classes in a Hugging Face Dataset of text data.\n",
    "    \"\"\"\n",
    "    # Calculate class distributions and find the maximum count\n",
    "    class_counts = Counter(dataset['label'])\n",
    "    max_class_count = round(max(class_counts.values()) * 1.5) #TODO: Change back\n",
    "    \n",
    "    # Initialize a list to hold original and synthetic samples\n",
    "    oversampled_datasets = []\n",
    "    \n",
    "    # Process each class\n",
    "    for label, count in class_counts.items():\n",
    "        \n",
    "        class_indices = [i for i, x in enumerate(dataset[label_column]) if x == label]\n",
    "        class_dataset = dataset.select(class_indices)\n",
    "        \n",
    "        # Calculate how many new samples are needed\n",
    "        num_new_samples = max_class_count - count\n",
    "        \n",
    "        if num_new_samples > 0:\n",
    "            \n",
    "            # Randomly select samples to be duplicated and modified\n",
    "            indices_to_augment = np.random.choice(class_indices, size=num_new_samples, replace=True)\n",
    "            samples_to_augment = dataset.select(indices_to_augment)\n",
    "            \n",
    "            # Apply the randomly_replace_tokens function to generate new samples\n",
    "            augmented_dataset = samples_to_augment.map(\n",
    "                lambda example: {\"text\": randomly_replace_tokens(example['text'], tokenizer, model, mask_probability=mask_probability)},\n",
    "                batched=False\n",
    "            )\n",
    "            \n",
    "            # Append augmented dataset to the list\n",
    "            oversampled_datasets.append(augmented_dataset)\n",
    "        \n",
    "        # Always include the original dataset for this class\n",
    "        oversampled_datasets.append(class_dataset)\n",
    "    \n",
    "    # Concatenate all datasets into a new Dataset\n",
    "    return concatenate_datasets(oversampled_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class frequencies before: Counter({2: 248, 1: 224, 3: 212})\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of each label\n",
    "label_counts = Counter(dataset_all_topics_pos['label'])\n",
    "print(\"Class frequencies before:\", label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   5%|▌         | 8/148 [01:29<26:06, 11.19s/ examples]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset_all_topics_pos \u001b[38;5;241m=\u001b[39m \u001b[43moversample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_all_topics_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 29\u001b[0m, in \u001b[0;36moversample\u001b[0;34m(dataset, label_column, tokenizer, model, mask_probability)\u001b[0m\n\u001b[1;32m     26\u001b[0m samples_to_augment \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mselect(indices_to_augment)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Apply the randomly_replace_tokens function to generate new samples\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m augmented_dataset \u001b[38;5;241m=\u001b[39m \u001b[43msamples_to_augment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomly_replace_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_probability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_probability\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Append augmented dataset to the list\u001b[39;00m\n\u001b[1;32m     35\u001b[0m oversampled_datasets\u001b[38;5;241m.\u001b[39mappend(augmented_dataset)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/datasets/arrow_dataset.py:591\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    590\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 591\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/datasets/arrow_dataset.py:556\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    554\u001b[0m }\n\u001b[1;32m    555\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 556\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    558\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/datasets/arrow_dataset.py:3089\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3083\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mtqdm(\n\u001b[1;32m   3084\u001b[0m         disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mis_progress_bar_enabled(),\n\u001b[1;32m   3085\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3086\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3087\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3088\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3089\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m rank, done, content \u001b[38;5;129;01min\u001b[39;00m Dataset\u001b[38;5;241m.\u001b[39m_map_single(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3090\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m done:\n\u001b[1;32m   3091\u001b[0m                 shards_done \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/datasets/arrow_dataset.py:3442\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3440\u001b[0m _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3441\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[0;32m-> 3442\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m update_data:\n\u001b[1;32m   3444\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.8/envs/s2j-content-analysis/lib/python3.10/site-packages/datasets/arrow_dataset.py:3345\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3344\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3345\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3347\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3348\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3349\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[19], line 30\u001b[0m, in \u001b[0;36moversample.<locals>.<lambda>\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m     26\u001b[0m samples_to_augment \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mselect(indices_to_augment)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Apply the randomly_replace_tokens function to generate new samples\u001b[39;00m\n\u001b[1;32m     29\u001b[0m augmented_dataset \u001b[38;5;241m=\u001b[39m samples_to_augment\u001b[38;5;241m.\u001b[39mmap(\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m example: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mrandomly_replace_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_probability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_probability\u001b[49m\u001b[43m)\u001b[49m},\n\u001b[1;32m     31\u001b[0m     batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Append augmented dataset to the list\u001b[39;00m\n\u001b[1;32m     35\u001b[0m oversampled_datasets\u001b[38;5;241m.\u001b[39mappend(augmented_dataset)\n",
      "Cell \u001b[0;32mIn[17], line 26\u001b[0m, in \u001b[0;36mrandomly_replace_tokens\u001b[0;34m(text, tokenizer, model, mask_probability)\u001b[0m\n\u001b[1;32m     24\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlogits[\u001b[38;5;241m0\u001b[39m, i]\n\u001b[1;32m     25\u001b[0m     predictions[original_token_id] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInf\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Invalidate the original token\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     best_pred_idx \u001b[38;5;241m=\u001b[39m \u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     27\u001b[0m     input_ids[\u001b[38;5;241m0\u001b[39m, i] \u001b[38;5;241m=\u001b[39m best_pred_idx  \u001b[38;5;66;03m# Replace with the best prediction\u001b[39;00m\n\u001b[1;32m     29\u001b[0m replaced_text \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(input_ids[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset_all_topics_pos = oversample(dataset_all_topics_pos, 'label', tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class frequencies after: Counter({1: 372, 2: 372, 3: 372})\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of each label\n",
    "label_counts = Counter(dataset_all_topics_pos['label'])\n",
    "print(\"Class frequencies after:\", label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Negative Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct negative domains 1922\n",
      "Class frequencies: Counter({2: 248, 1: 224, 3: 212})\n",
      "Minimum class frequency: 212\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of distinct negative domains\", len(set(dataset_all_topics_neg[\"domain\"])))\n",
    "\n",
    "# Count the occurrences of each label\n",
    "label_counts = Counter(dataset_all_topics_pos['label'])\n",
    "print(\"Class frequencies:\", label_counts)\n",
    "\n",
    "# Find the minimum count\n",
    "min_count = min(label_counts.values())\n",
    "print(\"Minimum class frequency:\", min_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datasets import Dataset\n",
    "\n",
    "def sample_random_from_dataset(dataset, n=5):\n",
    "    \"\"\"Samples n random examples from the dataset and returns both the sampled and unsampled parts.\n",
    "    \"\"\"\n",
    "\n",
    "    # Select the sampled dataset\n",
    "    n = min(n, len(dataset))\n",
    "    random_indices = random.sample(range(len(dataset)), n)\n",
    "    sampled_dataset = dataset.select(random_indices)\n",
    "    \n",
    "    # Determine indices not included in the random sample to create the remainder dataset\n",
    "    all_indices = set(range(len(dataset)))\n",
    "    unsampled_indices = list(all_indices - set(random_indices))\n",
    "    remaining_dataset = dataset.select(unsampled_indices)\n",
    "    \n",
    "    return sampled_dataset, remaining_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_all_topics_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_all_topics_neg, dataset_all_topics_neg_test = sample_random_from_dataset(dataset_all_topics_neg, n = len(dataset_all_topics_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_all_topics = concatenate_datasets([dataset_all_topics_pos, dataset_all_topics_neg])\n",
    "dataset_all_topics_holdout = concatenate_datasets([dataset_all_topics_test, dataset_all_topics_neg_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter (num_proc=16): 100%|██████████| 279935/279935 [00:02<00:00, 135818.13 examples/s]\n"
     ]
    }
   ],
   "source": [
    "seen_urls = set()\n",
    "\n",
    "dataset_all_topics_holdout = dataset_all_topics_holdout.filter(lambda example: example['view_url'] not in seen_urls and not seen_urls.add(example['view_url']), num_proc=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Example for Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dataset_all_topics.train_test_split(test_size=0.05, shuffle=True)\n",
    "datasets[\"valid\"] = datasets[\"test\"]\n",
    "datasets[\"test\"] = dataset_all_topics_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 1299/1299 [00:00<00:00, 13930.93 examples/s]\n",
      "Saving the dataset (2/2 shards): 100%|██████████| 279399/279399 [00:06<00:00, 43103.42 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 69/69 [00:00<00:00, 3326.21 examples/s]\n"
     ]
    }
   ],
   "source": [
    "datasets.save_to_disk(f\"../data/tmp/processed_dataset_all_topics_multiclass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunkify Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"FacebookAI/xlm-roberta-base\"\n",
    "MAX_CONTENT_LENGTH = 384\n",
    "OVERLAP = 64\n",
    "\n",
    "# Load a pre-trained tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "def get_input_length(text):\n",
    "    \"\"\" Tokenize the input text and return the number of tokens \"\"\"\n",
    "    return len(tokenizer.encode(text, add_special_tokens=True, truncation=False, padding=False))\n",
    "\n",
    "print(get_input_length(\"Hello, my name is John Doe\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=MAX_CONTENT_LENGTH,\n",
    "    chunk_overlap=OVERLAP,\n",
    "    length_function=get_input_length,\n",
    "    separators = [\"\\n\\n\", \"\\n\", \".\", \"?\", \"!\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# text_splitter = CharacterTextSplitter(\n",
    "#     separator = \".\", # Split text by sentences\n",
    "#     chunk_size=MAX_CONTENT_LENGTH,\n",
    "#     chunk_overlap=OVERLAP,\n",
    "#     length_function=get_input_length,\n",
    "#     is_separator_regex=False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ausnahmen und Förderungen: Gilt Habecks Gesetz für mein Haus? So kommen Sie an den Klimabonus Ukrain\n"
     ]
    }
   ],
   "source": [
    "test_text = datasets['train'][1]['text']\n",
    "print(test_text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Chunks: 6\n",
      "First Chunk: Ausnahmen und Förderungen: Gilt Habecks Gesetz für mein Haus? So kommen Sie an den Klimabonus Ukraine-Krieg Politik Panorama Eintracht Frankfurt Meinung Kategorien Politik Krieg in Israel Ukraine-Krieg US-Wahl Panorama Eintracht Frankfurt Meinung Kommentare Gastbeiträge Kolumnen Wissen Wirtschaft Frax Gastwirtschaft Rhein-Main Landespolitik Darmstadt Wiesbaden Offenbach Main-Kinzig-Kreis Main-Taunus-Kreis Hochtaunus Kreis Groß-Gerau Hessen Sport Fußball Sport A-Z Kultur TV & Kino Gesellschaft Times mager Musik Literatur Theater Kunst Verbraucher Ratgeber Gesundheit Geld Karriere Auto Buchtipps Wohnen Reise Einfach Tasty Zukunft Anzeigen Stellenmarkt Trauer Webkiosk Abo & Service Abo kündigen Thema Produktempfehlung Über uns FR-Jobs Altenhilfe Projekte Schlappekicker Startseite Verbraucher Ausnahmen und Förderungen: Gilt Habecks Gesetz für mein Haus? So kommen Sie an den Klimabonus Stand: 26.04.2023, 05:08 Uhr Von: Moritz Bletzinger Kommentare Drucken Heizen soll klimafreundlich werden. Das neue Gebäudeenergiegesetz regelt den Rückbau von fossilen Heizungen. Der Bund lockt mit Förderungen. Frankfurt – Viel diskutiert und jetzt beschlossen: Das neue Gebäudeenergiegesetz (GEG). Am Mittwoch (19. April) hat das Bundeskabinett die Heiz-Pläne abgesegnet. Aber was bedeutet das für Eigentümer:innen? Das sind die neuen Pflichten, Fristen und Ausnahmen. Und so kommen Sie an den Klimabonus\n",
      "Length of text: 326\n"
     ]
    }
   ],
   "source": [
    "texts = text_splitter.split_text(test_text)\n",
    "print(\"Number of Chunks:\", len(texts)) \n",
    "print(\"First Chunk:\",texts[0])\n",
    "print(\"Length of text:\", get_input_length(texts[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expandRow(row, col_name):\n",
    "    \"\"\"\n",
    "    Generate prompts based on text chunks from the input row.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    # Split the text into chunks\n",
    "    text_chunks = text_splitter.split_text(row.get(col_name, \"\"))\n",
    "\n",
    "    # Generate prompts for each text chunk\n",
    "    for chunk_id, text_chunk in enumerate(text_chunks):\n",
    "        new_row = {\n",
    "            **row, 'chunk_id': chunk_id, 'text': text_chunk\n",
    "        }\n",
    "        rows.append(new_row)\n",
    "\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "def processDataset(dataset, num_processes, func, params=()):\n",
    "    \"\"\"Process a list of articles in parallel using a multiprocessing Pool.\"\"\"\n",
    "\n",
    "    # Creates a list of arguments for each call to func\n",
    "    # Uses starmap to pass multiple arguments to func\n",
    "    with Pool(processes=num_processes) as pool:\n",
    "        args = [(row,) + params for row in dataset]\n",
    "        dataset = list(pool.starmap(func, args))\n",
    "\n",
    "    # Flatten the resulting list of lists\n",
    "    # and convert it into a Dataset\n",
    "    dataset = [item for sublist in dataset for item in sublist]\n",
    "    dataset = Dataset.from_dict(\n",
    "        {key: [dic[key] for dic in dataset] for key in dataset[0]})\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'token_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label'],\n",
       "        num_rows: 2120\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'token_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label'],\n",
       "        num_rows: 278986\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'token_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label'],\n",
       "        num_rows: 112\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (647 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (619 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (579 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (592 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (766 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (528 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (562 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (946 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2165 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1519 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1013 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (687 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (705 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (569 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (666 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2089 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (646 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (694 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (741 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1924 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2717 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1224 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (681 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (657 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (726 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (670 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1376 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (904 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (974 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (998 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (636 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1263 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (722 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (956 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (953 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (830 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (956 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1683 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (719 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (585 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1065 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1294 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (552 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (607 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (602 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (598 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (566 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1368 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (558 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (820 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (820 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2343 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1610 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (855 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (680 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (848 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (612 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (591 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (620 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "num_processes = 24\n",
    "params = (\"text\",)\n",
    "\n",
    "for split in datasets:\n",
    "    datasets[split] = processDataset(datasets[split], num_processes, expandRow, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class frequencies: Counter({0: 8493, 2: 2652, 1: 2504, 3: 2179})\n"
     ]
    }
   ],
   "source": [
    "label_counts = Counter(datasets[\"train\"]['label'])\n",
    "print(\"Class frequencies:\", label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'token_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'chunk_id'],\n",
       "        num_rows: 15828\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'token_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'chunk_id'],\n",
       "        num_rows: 816025\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['_id', 'batch_id', 'domain', 'view_url', 'lang', 'text', 'text_length', 'word_count', 'token_count', 'topic', 'category', 'good_for_training', 'good_for_augmentation', 'annotation_type', 'is_topic', 'label', 'chunk_id'],\n",
       "        num_rows: 827\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Update text length:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/15828 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 15828/15828 [00:14<00:00, 1067.84 examples/s]\n",
      "Map: 100%|██████████| 816025/816025 [11:46<00:00, 1155.16 examples/s]\n",
      "Map: 100%|██████████| 827/827 [00:00<00:00, 1120.96 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def update_metrics(example):\n",
    "    example['text_length'] = len(example['text'])\n",
    "    example['word_count'] = len(example['text'].split())\n",
    "    example['token_count'] = get_input_length(example['text'])\n",
    "    return example\n",
    "\n",
    "datasets = datasets.map(update_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 'dummy_id_280',\n",
       " 'batch_id': 99999,\n",
       " 'domain': 'www.pv-magazine.de',\n",
       " 'view_url': 'https://www.pv-magazine.de/2022/12/22/europaeische-kommission-gibt-gruenes-licht-fuer-erneuerbare-energien-gesetz-2023/',\n",
       " 'lang': 'de',\n",
       " 'text': 'Europäische Kommission gibt grünes licht for Ernäuerbare -Elien-GeSETz 2023 – eNews magazine  Skip to Top Global Deutschland Spanien Frankreich Italien USA Großbritannien Lateina China Kanada Brasilien Schweiz Deutschland  Abstand  News Alle News Themen Events Marktübersichten Magazin Schauplatz Branchebuch Kontakt Werbung Europäische-Union gibt grünes licht für Erneuerbare-Elien- Gesetz Die europäische Kommission hatte Mittwoch zwei Novelle des Erneubaren-Energien-Gesetzesgenehmig Auch dem Windenergie -auf -See-GeSETz stimmte sie zu. Damit können die Gelder zum Ernährbare -Ausbau wie vor der Bundesregierung bis zum Vertragsbeschluss außer Kraft einsetzen. 22. Januar 2022, Ernst, Berlin Die EU-Union kann im EHEC 2023 einen hilfe zum Nachdenken finden. Zwei weitere Regeln die im diesem Jahr verabschiedet werden, gelten somit seit dem 1. Januar. Foto von Eurocavis TeilenUm einen Ausbau der neuerbaren Quelles zu erleichtern, hatte der Bundesregierung diesen Sommer drei neue Gesetzen verabschiedet, das erneubaren -Energien-Gesetz 2022(EEG 2022), und den Windenergie-Auf-See-Gesetz 2023 (WindSEG 2025)Die Europäische Kommission hat sie nun genehmigt Der Ausbau der erneuerbare Quellen ist von überragenden öffentlichen Interesse, sagen die UN-Partnerorganisationen Die Gesetze sollen erreichen sich dass auch in Deutschland bis 2025 der Anteil der unerneubare Quellen im Bruttostromverbrauch auf rund 20 Prozent erhöht',\n",
       " 'text_length': 1429,\n",
       " 'word_count': 185,\n",
       " 'token_count': 320,\n",
       " 'topic': 'energie',\n",
       " 'category': 'buff',\n",
       " 'good_for_training': 'True',\n",
       " 'good_for_augmentation': 'True',\n",
       " 'annotation_type': 'buff',\n",
       " 'is_topic': 1,\n",
       " 'label': 2,\n",
       " 'chunk_id': 0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract URL path:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'view_url': 'https://www.google.com/search?q=python+url+path',\n",
       " 'url_path': 'search?q=python+url+path'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import urlparse, urlunparse\n",
    "\n",
    "def extract_url_path(example):\n",
    "    view_url = example['view_url']\n",
    "    if \"://\" not in view_url:\n",
    "        view_url = \"http://\" + view_url  # Assume http if no protocol specified\n",
    "    parsed_url = urlparse(view_url)\n",
    "    new_url = urlunparse(('', '', parsed_url.path, parsed_url.params, parsed_url.query, parsed_url.fragment))\n",
    "    example['url_path'] = new_url.lstrip('/')  # Store the result in a new field\n",
    "    return example\n",
    "\n",
    "\n",
    "extract_url_path({\"view_url\": \"https://www.google.com/search?q=python+url+path\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 15828/15828 [00:03<00:00, 5015.11 examples/s]\n",
      "Map: 100%|██████████| 816025/816025 [02:39<00:00, 5130.75 examples/s]\n",
      "Map: 100%|██████████| 827/827 [00:00<00:00, 5625.42 examples/s]\n"
     ]
    }
   ],
   "source": [
    "datasets = datasets.map(extract_url_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Dataset to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 15828/15828 [00:00<00:00, 406205.87 examples/s]\n",
      "Saving the dataset (3/3 shards): 100%|██████████| 816025/816025 [00:01<00:00, 530009.87 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 827/827 [00:00<00:00, 117367.85 examples/s]\n"
     ]
    }
   ],
   "source": [
    "datasets.save_to_disk(f\"../data/tmp/processed_dataset_multiclass_chunkified_{MAX_CONTENT_LENGTH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s2j-content-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
