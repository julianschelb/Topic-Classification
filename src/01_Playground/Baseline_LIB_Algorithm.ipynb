{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Interpolation and Backoff (LIB) Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LIB algorithm classifies URLs into genres by decomposing character n-grams and combining their probabilities using linear interpolation and backoff. It operates within a naive Bayes framework, where probabilities of n-grams (sequences of n characters) are used to estimate the likelihood of a URL belonging to a particular genre.\n",
    "\n",
    "See: https://apps.dtic.mil/sti/pdfs/ADA599843.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training phase involves:\n",
    "\n",
    "1. Collecting a corpus of URLs and their associated genres.\n",
    "2. Extracting n-grams from these URLs.\n",
    "3. Calculating the frequency of each n-gram for each genre.\n",
    "4. Estimating the interpolation coefficients (Î») using methods like information gain.\n",
    "5. Storing these frequencies and coefficients to be used during the prediction phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Extract n-grams from a URL #################################\n",
    "\n",
    "def extract_ngrams(url, n):\n",
    "    \"\"\"Extracts n-grams of length n from the given URL.\"\"\"\n",
    "    return [url[i:i+n] for i in range(len(url) - n + 1)]\n",
    "\n",
    "################################# Calculate frequencies of n-grams #################################\n",
    "\n",
    "def calculate_ngram_frequencies(urls, genres, n_range):\n",
    "    \"\"\"Calculates the frequency of n-grams for each genre from the given URLs and genres.\"\"\"\n",
    "    \n",
    "    ngram_freq = defaultdict(lambda: defaultdict(int))\n",
    "    genre_counts = Counter(genres)\n",
    "    \n",
    "    for url, genre in zip(urls, genres):\n",
    "        for n in n_range:\n",
    "            ngrams = extract_ngrams(url, n)\n",
    "            for ngram in ngrams:\n",
    "                ngram_freq[genre][ngram] += 1\n",
    "    \n",
    "    return ngram_freq, genre_counts\n",
    "\n",
    "################################# Calculate the mutual information for n-grams #################################\n",
    "\n",
    "def calculate_mutual_information(ngram_freq, genre_counts):\n",
    "    \"\"\"Calculates mutual information for n-grams using their frequencies and genre counts.\"\"\"\n",
    "    \n",
    "    ngrams = list({ngram for genre in ngram_freq for ngram in ngram_freq[genre]})\n",
    "    X = np.zeros((len(ngram_freq), len(ngrams)))\n",
    "    y = list(genre_counts.keys())\n",
    "\n",
    "    for i, genre in enumerate(y):\n",
    "        for j, ngram in enumerate(ngrams):\n",
    "            X[i, j] = ngram_freq[genre][ngram]\n",
    "    \n",
    "    mi = mutual_info_classif(X, y, discrete_features=True)\n",
    "    return dict(zip(ngrams, mi))\n",
    "\n",
    "################################# Estimate the interpolation coefficients #################################\n",
    "\n",
    "def estimate_interpolation_coefficients(ngram_mi, n_range):\n",
    "    \"\"\"Estimates interpolation coefficients based on mutual information of n-grams.\"\"\"\n",
    "    \n",
    "    lambda_sum = sum(ngram_mi.values())\n",
    "    lambdas = {n: 0 for n in n_range}\n",
    "    \n",
    "    for ngram, mi in ngram_mi.items():\n",
    "        n = len(ngram)\n",
    "        lambdas[n] += mi / lambda_sum\n",
    "    \n",
    "    # Normalize the coefficients\n",
    "    total = sum(lambdas.values())\n",
    "    for n in lambdas:\n",
    "        lambdas[n] /= total\n",
    "    \n",
    "    return lambdas\n",
    "\n",
    "################################# Main training function #################################\n",
    "\n",
    "def train_genre_classifier(urls, genres, n_range=(2, 3, 4)):\n",
    "    \"\"\"\n",
    "    Trains the genre classifier by calculating n-gram frequencies, mutual information,\n",
    "    and interpolation coefficients from the given URLs and genres.\n",
    "    \"\"\"\n",
    "    # Calculate n-gram frequencies and genre counts\n",
    "    ngram_freq, genre_counts = calculate_ngram_frequencies(urls, genres, n_range)\n",
    "    \n",
    "    # Calculate mutual information for n-grams\n",
    "    ngram_mi = calculate_mutual_information(ngram_freq, genre_counts)\n",
    "    \n",
    "    # Estimate interpolation coefficients\n",
    "    lambdas = estimate_interpolation_coefficients(ngram_mi, n_range)\n",
    "    \n",
    "    return ngram_freq, genre_counts, lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-gram Frequencies: defaultdict(<function calculate_ngram_frequencies.<locals>.<lambda> at 0x7fc8fbb3a290>, {'blog': defaultdict(<class 'int'>, {'ww': 2, 'w.': 1, '.e': 1, 'ex': 1, 'xa': 1, 'am': 1, 'mp': 1, 'pl': 1, 'le': 1, 'eb': 1, 'bl': 1, 'lo': 1, 'og': 1, 'g.': 1, '.c': 1, 'co': 1, 'om': 1, 'm/': 1, '/p': 1, 'po': 1, 'os': 1, 'st': 1, 'www': 1, 'ww.': 1, 'w.e': 1, '.ex': 1, 'exa': 1, 'xam': 1, 'amp': 1, 'mpl': 1, 'ple': 1, 'leb': 1, 'ebl': 1, 'blo': 1, 'log': 1, 'og.': 1, 'g.c': 1, '.co': 1, 'com': 1, 'om/': 1, 'm/p': 1, '/po': 1, 'pos': 1, 'ost': 1, 'www.': 1, 'ww.e': 1, 'w.ex': 1, '.exa': 1, 'exam': 1, 'xamp': 1, 'ampl': 1, 'mple': 1, 'pleb': 1, 'lebl': 1, 'eblo': 1, 'blog': 1, 'log.': 1, 'og.c': 1, 'g.co': 1, '.com': 1, 'com/': 1, 'om/p': 1, 'm/po': 1, '/pos': 1, 'post': 1, 'i.o': 0, 'lewi': 0, 'rg': 0, 'pro': 0, 'e.c': 0, 'wik': 0, 'ki.': 0, 'prod': 0, 'i.': 0, '.org': 0, 'rod': 0, 'pa': 0, 'wiki': 0, 'shop': 0, 'ge': 0, 'oduc': 0, 'hop': 0, 'p.ex': 0, 'pag': 0, 'age': 0, 'ewi': 0, 'hop.': 0, 'org': 0, 'duc': 0, 'op.': 0, 'iki': 0, '/pag': 0, 'op': 0, 'rg/': 0, 'plew': 0, 'uc': 0, 'rg/p': 0, 'ct': 0, '/pa': 0, 'wi': 0, 'org/': 0, 'e.co': 0, '/pr': 0, 'op.e': 0, 'pr': 0, 'sho': 0, 'g/': 0, 'uct': 0, 'p.': 0, 'ki': 0, 'ik': 0, 'ki.o': 0, 'ple.': 0, 'rodu': 0, 'du': 0, 'p.e': 0, 'sh': 0, 'le.': 0, 'or': 0, 'odu': 0, 'ewik': 0, 'ro': 0, 'i.or': 0, 'page': 0, 'g/p': 0, 'm/pr': 0, '/pro': 0, 'g/pa': 0, '.o': 0, 'le.c': 0, 'od': 0, 'ew': 0, '.or': 0, 'iki.': 0, 'duct': 0, 'ho': 0, 'ag': 0, 'lew': 0, 'e.': 0}), 'wiki': defaultdict(<class 'int'>, {'ww': 2, 'w.': 1, '.e': 1, 'ex': 1, 'xa': 1, 'am': 1, 'mp': 1, 'pl': 1, 'le': 1, 'ew': 1, 'wi': 1, 'ik': 1, 'ki': 1, 'i.': 1, '.o': 1, 'or': 1, 'rg': 1, 'g/': 1, '/p': 1, 'pa': 1, 'ag': 1, 'ge': 1, 'www': 1, 'ww.': 1, 'w.e': 1, '.ex': 1, 'exa': 1, 'xam': 1, 'amp': 1, 'mpl': 1, 'ple': 1, 'lew': 1, 'ewi': 1, 'wik': 1, 'iki': 1, 'ki.': 1, 'i.o': 1, '.or': 1, 'org': 1, 'rg/': 1, 'g/p': 1, '/pa': 1, 'pag': 1, 'age': 1, 'www.': 1, 'ww.e': 1, 'w.ex': 1, '.exa': 1, 'exam': 1, 'xamp': 1, 'ampl': 1, 'mple': 1, 'plew': 1, 'lewi': 1, 'ewik': 1, 'wiki': 1, 'iki.': 1, 'ki.o': 1, 'i.or': 1, '.org': 1, 'org/': 1, 'rg/p': 1, 'g/pa': 1, '/pag': 1, 'page': 1, 'og.': 0, 'lebl': 0, 'om': 0, 'pro': 0, 'e.c': 0, 'log.': 0, 'prod': 0, 'eb': 0, 'lo': 0, 'rod': 0, '.com': 0, 'om/p': 0, 'og.c': 0, 'bl': 0, 'shop': 0, 'pos': 0, 'oduc': 0, 'hop': 0, 'p.ex': 0, 'leb': 0, 'log': 0, '.c': 0, 'hop.': 0, 'duc': 0, 'op.': 0, '/pos': 0, 'st': 0, 'm/': 0, 'eblo': 0, 'op': 0, 'os': 0, 'uc': 0, 'post': 0, 'ct': 0, 'pleb': 0, 'g.': 0, 'og': 0, 'e.co': 0, '/pr': 0, 'op.e': 0, 'pr': 0, 'sho': 0, '.co': 0, 'uct': 0, 'p.': 0, 'om/': 0, 'ost': 0, 'ple.': 0, 'rodu': 0, 'm/po': 0, 'du': 0, 'p.e': 0, 'blog': 0, 'sh': 0, 'le.': 0, 'co': 0, 'po': 0, 'com/': 0, 'g.c': 0, 'g.co': 0, 'ebl': 0, 'odu': 0, 'ro': 0, '/po': 0, 'm/pr': 0, '/pro': 0, 'le.c': 0, 'm/p': 0, 'od': 0, 'blo': 0, 'duct': 0, 'ho': 0, 'com': 0, 'e.': 0}), 'e-shop': defaultdict(<class 'int'>, {'sh': 1, 'ho': 1, 'op': 1, 'p.': 1, '.e': 1, 'ex': 1, 'xa': 1, 'am': 1, 'mp': 1, 'pl': 1, 'le': 1, 'e.': 1, '.c': 1, 'co': 1, 'om': 1, 'm/': 1, '/p': 1, 'pr': 1, 'ro': 1, 'od': 1, 'du': 1, 'uc': 1, 'ct': 1, 'sho': 1, 'hop': 1, 'op.': 1, 'p.e': 1, '.ex': 1, 'exa': 1, 'xam': 1, 'amp': 1, 'mpl': 1, 'ple': 1, 'le.': 1, 'e.c': 1, '.co': 1, 'com': 1, 'om/': 1, 'm/p': 1, '/pr': 1, 'pro': 1, 'rod': 1, 'odu': 1, 'duc': 1, 'uct': 1, 'shop': 1, 'hop.': 1, 'op.e': 1, 'p.ex': 1, '.exa': 1, 'exam': 1, 'xamp': 1, 'ampl': 1, 'mple': 1, 'ple.': 1, 'le.c': 1, 'e.co': 1, '.com': 1, 'com/': 1, 'om/p': 1, 'm/pr': 1, '/pro': 1, 'prod': 1, 'rodu': 1, 'oduc': 1, 'duct': 1, 'og.': 0, 'lebl': 0, 'i.o': 0, 'lewi': 0, 'rg': 0, 'wik': 0, 'log.': 0, 'ki.': 0, 'w.': 0, 'i.': 0, 'eb': 0, 'ww.': 0, 'lo': 0, '.org': 0, 'pa': 0, 'og.c': 0, 'bl': 0, 'wiki': 0, 'www': 0, 'ge': 0, 'pos': 0, 'leb': 0, 'pag': 0, 'age': 0, 'ewi': 0, 'log': 0, 'org': 0, '/pos': 0, 'iki': 0, 'st': 0, '/pag': 0, 'eblo': 0, 'rg/': 0, 'plew': 0, 'os': 0, 'rg/p': 0, 'post': 0, 'pleb': 0, 'www.': 0, 'g.': 0, '/pa': 0, 'og': 0, 'wi': 0, 'w.ex': 0, 'org/': 0, 'ww': 0, 'g/': 0, 'ki': 0, 'ik': 0, 'ki.o': 0, 'ost': 0, 'm/po': 0, 'blog': 0, 'po': 0, 'g.c': 0, 'g.co': 0, 'or': 0, 'ebl': 0, 'ewik': 0, '/po': 0, 'i.or': 0, 'page': 0, 'g/p': 0, 'ww.e': 0, 'g/pa': 0, '.o': 0, 'ew': 0, '.or': 0, 'iki.': 0, 'blo': 0, 'ag': 0, 'lew': 0, 'w.e': 0})})\n",
      "Genre Counts: Counter({'blog': 1, 'wiki': 1, 'e-shop': 1})\n",
      "Interpolation Coefficients: {2: 0.3083333333333334, 3: 0.3416666666666667, 4: 0.35}\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "urls = [\"www.exampleblog.com/post\", \"www.examplewiki.org/page\", \"shop.example.com/product\"]\n",
    "genres = [\"blog\", \"wiki\", \"e-shop\"]\n",
    "n_range = (2, 3, 4)\n",
    "\n",
    "ngram_freq, genre_counts, lambdas = train_genre_classifier(urls, genres, n_range)\n",
    "\n",
    "print(\"N-gram Frequencies:\", ngram_freq)\n",
    "print(\"Genre Counts:\", genre_counts)\n",
    "print(\"Interpolation Coefficients:\", lambdas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm uses pre-computed (trained) feature sets and probabilities to classify a new instance (URL). It involves:\n",
    "\n",
    "1. Extracting n-grams from the URL.\n",
    "2. Using these n-grams to calculate genre probabilities based on pre-learned frequencies and interpolation coefficients.\n",
    "3. Applying backoff to handle unseen n-grams by considering shorter n-grams.\n",
    "4. Normalizing the resulting probabilities and selecting the most probable genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################# Normalize the probabilities #################################\n",
    "\n",
    "def normalize_probs(probs):\n",
    "    \"\"\"Normalizes the probability dictionary so that the probabilities sum to 1.\"\"\"\n",
    "    total = sum(probs.values())\n",
    "    if total == 0:\n",
    "        return {k: 0 for k in probs}  # Return zero probabilities if total is zero\n",
    "    return {k: v / total for k, v in probs.items()}\n",
    "\n",
    "################################# Calculate the probability of an n-gram for a given genre #################################\n",
    "\n",
    "def calculate_ngram_prob(ngram, genre, ngram_freq, genre_counts, lambdas):\n",
    "    \"\"\"\n",
    "    Calculates the probability of an n-gram given a genre using pre-trained frequencies and interpolation coefficients.\n",
    "    \"\"\"\n",
    "    n = len(ngram)\n",
    "    lambda_n = lambdas.get(n, 0)\n",
    "    freq = ngram_freq[genre].get(ngram, 0)\n",
    "    total_ngrams = sum(ngram_freq[genre].values())\n",
    "    if total_ngrams == 0:\n",
    "        return 1e-10  # Return a small non-zero value if no n-grams are found\n",
    "    prob = (lambda_n * (freq / total_ngrams))\n",
    "    return prob\n",
    "\n",
    "################################# Extract n-grams from a URL #################################\n",
    "\n",
    "def extract_ngrams(url, n):\n",
    "    \"\"\"Extracts n-grams of length n from the given URL.\"\"\"\n",
    "    return [url[i:i+n] for i in range(len(url) - n + 1)]\n",
    "\n",
    "################################# Prediction function #################################\n",
    "\n",
    "def predict_genre(url, ngram_freq, genre_counts, lambdas, n_range=(2, 3, 4)):\n",
    "    \"\"\"\n",
    "    Predicts the genre of a given URL using pre-trained n-gram frequencies, genre counts, and interpolation coefficients.\n",
    "    \"\"\"\n",
    "    probs = {genre: np.log(count / sum(genre_counts.values())) if count > 0 else -np.inf for genre, count in genre_counts.items()}\n",
    "    Q = []\n",
    "    grams = set()\n",
    "    \n",
    "    for n in n_range:\n",
    "        Q.extend(extract_ngrams(url, n))\n",
    "    \n",
    "    while Q:\n",
    "        gram = Q.pop(0)\n",
    "        if any(gram in ngram_freq[genre] for genre in genre_counts):\n",
    "            grams.add(gram)\n",
    "        else:\n",
    "            if len(gram) > min(n_range):\n",
    "                Q.append(gram[:-1])\n",
    "    \n",
    "    if grams:\n",
    "        for genre in genre_counts:\n",
    "            for gram in grams:\n",
    "                ngram_prob = calculate_ngram_prob(gram, genre, ngram_freq, genre_counts, lambdas)\n",
    "                if ngram_prob > 0:\n",
    "                    probs[genre] += np.log(ngram_prob)\n",
    "    \n",
    "    probs = normalize_probs(probs)\n",
    "    predicted_genre = max(probs, key=probs.get)\n",
    "    \n",
    "    return predicted_genre, probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make Precitions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "        \n",
    "    # Cannabis-related URLs\n",
    "    \"bundesgesundheitsministerium.de/themen/cannabis/faq-cannabisgesetz\",\n",
    "    \"de.wikipedia.org/wiki/Cannabis_als_Medizin\",\n",
    "    \"cannabis-med.org/index.php?tpl=cannabis\",\n",
    "    \n",
    "    # Children-related URLs\n",
    "    \"paritaet-bw.de/was-ist-kindergrundsicherung\",\n",
    "    \"kindergesundheit-info.de/themen/entwicklung/alle-entwicklungsbereiche/\",\n",
    "    \"de.wikipedia.org/wiki/Kindergesundheit\",\n",
    "    \n",
    "    # Energy-related URLs\n",
    "    \"https://de.wikipedia.org/wiki/Erneuerbare-Energien-Gesetz\",\n",
    "    \"bmu.de/themen/energie/erneuerbare-energien\",\n",
    "    \"energiewende.de\",\n",
    "    \n",
    "    # Other URLs\n",
    "    \"https://en.wikipedia.org/wiki/Richard_Feynman\",\n",
    "    \"example.com\",\n",
    "    \"other-example.org\"\n",
    "]\n",
    "\n",
    "genres = [\"cannabis\", \"cannabis\", \"cannabis\", \"children\", \"children\", \"children\", \"energy\", \"energy\", \"energy\", \"other\", \"other\", \"other\"]\n",
    "n_range = (2, 3, 4)\n",
    "\n",
    "# Train the model\n",
    "ngram_freq, genre_counts, lambdas = train_genre_classifier(urls, genres, n_range)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Genre: cannabis\n",
      "Genre Probabilities: {'cannabis': 0.3968993080538406, 'children': 0.32905631661106044, 'energy': 0.17351466636779836, 'other': 0.1005297089673007}\n"
     ]
    }
   ],
   "source": [
    "# Predict the genre of a new URL\n",
    "new_url = \"tagesschau.de/wirtschaft/cannabis-legalisierung-volkswirtschaft-kosten-100.html\"\n",
    "predicted_genre, probabilities = predict_genre(new_url, ngram_freq, genre_counts, lambdas, n_range)\n",
    "\n",
    "print(\"Predicted Genre:\", predicted_genre)\n",
    "print(\"Genre Probabilities:\", probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Genre: cannabis\n",
      "Genre Probabilities: {'cannabis': 0.4574776708384911, 'children': 0.24060528606842502, 'energy': 0.23501095435987104, 'other': 0.06690608873321281}\n"
     ]
    }
   ],
   "source": [
    "# Predict the genre of a new URL\n",
    "new_url = \"bundesfinanzministerium.de/Content/DE/Glossareintraege/E/energie-umlage.html\"\n",
    "predicted_genre, probabilities = predict_genre(new_url, ngram_freq, genre_counts, lambdas, n_range)\n",
    "\n",
    "print(\"Predicted Genre:\", predicted_genre)\n",
    "print(\"Genre Probabilities:\", probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Genre: energy\n",
      "Genre Probabilities: {'cannabis': 0.21173155555456805, 'children': 0.30906088718925107, 'energy': 0.3647854729017985, 'other': 0.11442208435438236}\n"
     ]
    }
   ],
   "source": [
    "# Predict the genre of a new URL\n",
    "new_url = \"energy-knowledge.de/Content/DE/Glossareintraege/E/energie-umlage.html\"\n",
    "predicted_genre, probabilities = predict_genre(new_url, ngram_freq, genre_counts, lambdas, n_range)\n",
    "\n",
    "print(\"Predicted Genre:\", predicted_genre)\n",
    "print(\"Genre Probabilities:\", probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s2j-content-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
